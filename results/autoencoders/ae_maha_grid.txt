=========================================
2024-03-31 20:11:50,589 [trainer.py] => config: ./exps/FeCAM_cifar100.json
2024-03-31 20:11:50,589 [trainer.py] => prefix: train
2024-03-31 20:11:50,589 [trainer.py] => dataset: cifar100
2024-03-31 20:11:50,589 [trainer.py] => memory_size: 0
2024-03-31 20:11:50,589 [trainer.py] => shuffle: True
2024-03-31 20:11:50,589 [trainer.py] => init_cls: 50
2024-03-31 20:11:50,589 [trainer.py] => increment: 10
2024-03-31 20:11:50,589 [trainer.py] => model_name: fecam
2024-03-31 20:11:50,590 [trainer.py] => convnet_type: resnet18
2024-03-31 20:11:50,590 [trainer.py] => device: [device(type='cuda', index=0)]
2024-03-31 20:11:50,590 [trainer.py] => seed: 1993
2024-03-31 20:11:50,590 [trainer.py] => init_epochs: 200
2024-03-31 20:11:50,590 [trainer.py] => init_lr: 0.1
2024-03-31 20:11:50,590 [trainer.py] => init_weight_decay: 0.0005
2024-03-31 20:11:50,590 [trainer.py] => batch_size: 128
2024-03-31 20:11:50,590 [trainer.py] => num_workers: 8
2024-03-31 20:11:50,590 [trainer.py] => T: 5
2024-03-31 20:11:50,590 [trainer.py] => beta: 0.5
2024-03-31 20:11:50,590 [trainer.py] => alpha1: 1
2024-03-31 20:11:50,590 [trainer.py] => alpha2: 1
2024-03-31 20:11:50,590 [trainer.py] => ncm: False
2024-03-31 20:11:50,590 [trainer.py] => tukey: False
2024-03-31 20:11:50,590 [trainer.py] => diagonal: False
2024-03-31 20:11:50,590 [trainer.py] => per_class: True
2024-03-31 20:11:50,590 [trainer.py] => full_cov: True
2024-03-31 20:11:50,590 [trainer.py] => shrink: True
2024-03-31 20:11:50,590 [trainer.py] => norm_cov: False
2024-03-31 20:11:50,590 [trainer.py] => epochs: 2000
2024-03-31 20:11:50,590 [trainer.py] => vecnorm: False
2024-03-31 20:11:50,590 [trainer.py] => ae_type: ae
2024-03-31 20:11:50,590 [trainer.py] => ae_latent_dim: 32
2024-03-31 20:11:50,590 [trainer.py] => ae_n: 1
2024-03-31 20:11:50,590 [trainer.py] => wae_sigma: 10
2024-03-31 20:11:50,590 [trainer.py] => wae_C: 0.1
2024-03-31 20:11:50,590 [trainer.py] => ae_standarization: False
2024-03-31 20:11:50,590 [trainer.py] => ae_pca: False
2024-03-31 20:11:50,590 [trainer.py] => ae_pca_components: 500
2024-03-31 20:11:50,590 [trainer.py] => ae_clsf: maha-recon-cost
2024-03-31 20:11:50,590 [trainer.py] => maha_alpha: 0.01
2024-03-31 20:11:50,590 [trainer.py] => maha_beta: 0.01
Files already downloaded and verified
Files already downloaded and verified
2024-03-31 20:11:52,381 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-03-31 20:11:52,660 [fecam.py] => Learning on 0-50
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Processing class: 0
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0571804076
Epoch:   200  |  train loss: 0.0571804054
Epoch:   300  |  train loss: 0.0571804047
Epoch:   400  |  train loss: 0.0571804069
Epoch:   500  |  train loss: 0.0571804069
Epoch:   600  |  train loss: 0.0571804047
Epoch:   700  |  train loss: 0.0571804047
Epoch:   800  |  train loss: 0.0571804047
Epoch:   900  |  train loss: 0.0571804062
Epoch:  1000  |  train loss: 0.0571804017
Epoch:  1100  |  train loss: 0.0571804069
Epoch:  1200  |  train loss: 0.0571804062
Epoch:  1300  |  train loss: 0.0571804069
Epoch:  1400  |  train loss: 0.0571804076
Epoch:  1500  |  train loss: 0.0571804047
Epoch:  1600  |  train loss: 0.0571804047
Epoch:  1700  |  train loss: 0.0571804047
Epoch:  1800  |  train loss: 0.0571804069
Epoch:  1900  |  train loss: 0.0571804062
Epoch:  2000  |  train loss: 0.0571804032
Processing class: 1
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0566620670
Epoch:   200  |  train loss: 0.0566620648
Epoch:   300  |  train loss: 0.0566620670
Epoch:   400  |  train loss: 0.0566620678
Epoch:   500  |  train loss: 0.0566620670
Epoch:   600  |  train loss: 0.0566620626
Epoch:   700  |  train loss: 0.0566620678
Epoch:   800  |  train loss: 0.0566620655
Epoch:   900  |  train loss: 0.0566620685
Epoch:  1000  |  train loss: 0.0566620663
Epoch:  1100  |  train loss: 0.0566620670
Epoch:  1200  |  train loss: 0.0566620663
Epoch:  1300  |  train loss: 0.0566620670
Epoch:  1400  |  train loss: 0.0566620670
Epoch:  1500  |  train loss: 0.0566620640
Epoch:  1600  |  train loss: 0.0566620678
Epoch:  1700  |  train loss: 0.0566620663
Epoch:  1800  |  train loss: 0.0566620648
Epoch:  1900  |  train loss: 0.0566620700
Epoch:  2000  |  train loss: 0.0566620678
Processing class: 2
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0538499221
Epoch:   200  |  train loss: 0.0538499251
Epoch:   300  |  train loss: 0.0538499221
Epoch:   400  |  train loss: 0.0538499229
Epoch:   500  |  train loss: 0.0538499221
Epoch:   600  |  train loss: 0.0538499214
Epoch:   700  |  train loss: 0.0538499236
Epoch:   800  |  train loss: 0.0538499229
Epoch:   900  |  train loss: 0.0538499236
Epoch:  1000  |  train loss: 0.0538499221
Epoch:  1100  |  train loss: 0.0538499236
Epoch:  1200  |  train loss: 0.0538499258
Epoch:  1300  |  train loss: 0.0538499229
Epoch:  1400  |  train loss: 0.0538499244
Epoch:  1500  |  train loss: 0.0538499236
Epoch:  1600  |  train loss: 0.0538499229
Epoch:  1700  |  train loss: 0.0538499229
Epoch:  1800  |  train loss: 0.0538499214
Epoch:  1900  |  train loss: 0.0538499251
Epoch:  2000  |  train loss: 0.0538499229
Processing class: 3
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0572663933
Epoch:   200  |  train loss: 0.0572663911
Epoch:   300  |  train loss: 0.0572663963
Epoch:   400  |  train loss: 0.0572663963
Epoch:   500  |  train loss: 0.0572663948
Epoch:   600  |  train loss: 0.0572663940
Epoch:   700  |  train loss: 0.0572663940
Epoch:   800  |  train loss: 0.0572663940
Epoch:   900  |  train loss: 0.0572663948
Epoch:  1000  |  train loss: 0.0572663940
Epoch:  1100  |  train loss: 0.0572663940
Epoch:  1200  |  train loss: 0.0572663933
Epoch:  1300  |  train loss: 0.0572663940
Epoch:  1400  |  train loss: 0.0572663940
Epoch:  1500  |  train loss: 0.0572663940
Epoch:  1600  |  train loss: 0.0572663926
Epoch:  1700  |  train loss: 0.0572663940
Epoch:  1800  |  train loss: 0.0572663970
Epoch:  1900  |  train loss: 0.0572663918
Epoch:  2000  |  train loss: 0.0572663948
Processing class: 4
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564479984
Epoch:   200  |  train loss: 0.0564479999
Epoch:   300  |  train loss: 0.0564479969
Epoch:   400  |  train loss: 0.0564479977
Epoch:   500  |  train loss: 0.0564479955
Epoch:   600  |  train loss: 0.0564479977
Epoch:   700  |  train loss: 0.0564479977
Epoch:   800  |  train loss: 0.0564479969
Epoch:   900  |  train loss: 0.0564480014
Epoch:  1000  |  train loss: 0.0564479947
Epoch:  1100  |  train loss: 0.0564479977
Epoch:  1200  |  train loss: 0.0564479969
Epoch:  1300  |  train loss: 0.0564479984
Epoch:  1400  |  train loss: 0.0564479984
Epoch:  1500  |  train loss: 0.0564479984
Epoch:  1600  |  train loss: 0.0564479977
Epoch:  1700  |  train loss: 0.0564479992
Epoch:  1800  |  train loss: 0.0564480014
Epoch:  1900  |  train loss: 0.0564479962
Epoch:  2000  |  train loss: 0.0564479977
Processing class: 5
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 6
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0567961939
Epoch:   200  |  train loss: 0.0567961931
Epoch:   300  |  train loss: 0.0567961901
Epoch:   400  |  train loss: 0.0567961946
Epoch:   500  |  train loss: 0.0567961916
Epoch:   600  |  train loss: 0.0567961901
Epoch:   700  |  train loss: 0.0567961901
Epoch:   800  |  train loss: 0.0567961909
Epoch:   900  |  train loss: 0.0567961909
Epoch:  1000  |  train loss: 0.0567961909
Epoch:  1100  |  train loss: 0.0567961901
Epoch:  1200  |  train loss: 0.0567961916
Epoch:  1300  |  train loss: 0.0567961924
Epoch:  1400  |  train loss: 0.0567961931
Epoch:  1500  |  train loss: 0.0567961939
Epoch:  1600  |  train loss: 0.0567961946
Epoch:  1700  |  train loss: 0.0567961931
Epoch:  1800  |  train loss: 0.0567961901
Epoch:  1900  |  train loss: 0.0567961931
Epoch:  2000  |  train loss: 0.0567961909
Processing class: 7
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0571311295
Epoch:   200  |  train loss: 0.0571311295
Epoch:   300  |  train loss: 0.0571311288
Epoch:   400  |  train loss: 0.0571311310
Epoch:   500  |  train loss: 0.0571311325
Epoch:   600  |  train loss: 0.0571311332
Epoch:   700  |  train loss: 0.0571311310
Epoch:   800  |  train loss: 0.0571311288
Epoch:   900  |  train loss: 0.0571311280
Epoch:  1000  |  train loss: 0.0571311310
Epoch:  1100  |  train loss: 0.0571311288
Epoch:  1200  |  train loss: 0.0571311302
Epoch:  1300  |  train loss: 0.0571311310
Epoch:  1400  |  train loss: 0.0571311310
Epoch:  1500  |  train loss: 0.0571311317
Epoch:  1600  |  train loss: 0.0571311325
Epoch:  1700  |  train loss: 0.0571311288
Epoch:  1800  |  train loss: 0.0571311325
Epoch:  1900  |  train loss: 0.0571311295
Epoch:  2000  |  train loss: 0.0571311302
Processing class: 8
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0569675282
Epoch:   200  |  train loss: 0.0569675237
Epoch:   300  |  train loss: 0.0569675267
Epoch:   400  |  train loss: 0.0569675259
Epoch:   500  |  train loss: 0.0569675237
Epoch:   600  |  train loss: 0.0569675252
Epoch:   700  |  train loss: 0.0569675252
Epoch:   800  |  train loss: 0.0569675237
Epoch:   900  |  train loss: 0.0569675267
Epoch:  1000  |  train loss: 0.0569675282
Epoch:  1100  |  train loss: 0.0569675252
Epoch:  1200  |  train loss: 0.0569675237
Epoch:  1300  |  train loss: 0.0569675259
Epoch:  1400  |  train loss: 0.0569675252
Epoch:  1500  |  train loss: 0.0569675267
Epoch:  1600  |  train loss: 0.0569675282
Epoch:  1700  |  train loss: 0.0569675259
Epoch:  1800  |  train loss: 0.0569675252
Epoch:  1900  |  train loss: 0.0569675244
Epoch:  2000  |  train loss: 0.0569675252
Processing class: 9
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0546813704
Epoch:   200  |  train loss: 0.0546813719
Epoch:   300  |  train loss: 0.0546813734
Epoch:   400  |  train loss: 0.0546813741
Epoch:   500  |  train loss: 0.0546813719
Epoch:   600  |  train loss: 0.0546813719
Epoch:   700  |  train loss: 0.0546813741
Epoch:   800  |  train loss: 0.0546813734
Epoch:   900  |  train loss: 0.0546813697
Epoch:  1000  |  train loss: 0.0546813712
Epoch:  1100  |  train loss: 0.0546813704
Epoch:  1200  |  train loss: 0.0546813712
Epoch:  1300  |  train loss: 0.0546813726
Epoch:  1400  |  train loss: 0.0546813719
Epoch:  1500  |  train loss: 0.0546813719
Epoch:  1600  |  train loss: 0.0546813734
Epoch:  1700  |  train loss: 0.0546813704
Epoch:  1800  |  train loss: 0.0546813719
Epoch:  1900  |  train loss: 0.0546813756
Epoch:  2000  |  train loss: 0.0546813734
Processing class: 10
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0568029083
Epoch:   200  |  train loss: 0.0568029068
Epoch:   300  |  train loss: 0.0568029061
Epoch:   400  |  train loss: 0.0568029083
Epoch:   500  |  train loss: 0.0568029083
Epoch:   600  |  train loss: 0.0568029061
Epoch:   700  |  train loss: 0.0568029068
Epoch:   800  |  train loss: 0.0568029076
Epoch:   900  |  train loss: 0.0568029076
Epoch:  1000  |  train loss: 0.0568029098
Epoch:  1100  |  train loss: 0.0568029083
Epoch:  1200  |  train loss: 0.0568029083
Epoch:  1300  |  train loss: 0.0568029098
Epoch:  1400  |  train loss: 0.0568029076
Epoch:  1500  |  train loss: 0.0568029083
Epoch:  1600  |  train loss: 0.0568029068
Epoch:  1700  |  train loss: 0.0568029098
Epoch:  1800  |  train loss: 0.0568029076
Epoch:  1900  |  train loss: 0.0568029091
Epoch:  2000  |  train loss: 0.0568029061
Processing class: 11
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0572404183
Epoch:   200  |  train loss: 0.0572404183
Epoch:   300  |  train loss: 0.0572404169
Epoch:   400  |  train loss: 0.0572404176
Epoch:   500  |  train loss: 0.0572404176
Epoch:   600  |  train loss: 0.0572404191
Epoch:   700  |  train loss: 0.0572404198
Epoch:   800  |  train loss: 0.0572404183
Epoch:   900  |  train loss: 0.0572404176
Epoch:  1000  |  train loss: 0.0572404176
Epoch:  1100  |  train loss: 0.0572404169
Epoch:  1200  |  train loss: 0.0572404183
Epoch:  1300  |  train loss: 0.0572404169
Epoch:  1400  |  train loss: 0.0572404213
Epoch:  1500  |  train loss: 0.0572404213
Epoch:  1600  |  train loss: 0.0572404176
Epoch:  1700  |  train loss: 0.0572404191
Epoch:  1800  |  train loss: 0.0572404213
Epoch:  1900  |  train loss: 0.0572404206
Epoch:  2000  |  train loss: 0.0572404176
Processing class: 12
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0571175918
Epoch:   200  |  train loss: 0.0571175918
Epoch:   300  |  train loss: 0.0571175888
Epoch:   400  |  train loss: 0.0571175918
Epoch:   500  |  train loss: 0.0571175903
Epoch:   600  |  train loss: 0.0571175903
Epoch:   700  |  train loss: 0.0571175888
Epoch:   800  |  train loss: 0.0571175903
Epoch:   900  |  train loss: 0.0571175896
Epoch:  1000  |  train loss: 0.0571175896
Epoch:  1100  |  train loss: 0.0571175888
Epoch:  1200  |  train loss: 0.0571175896
Epoch:  1300  |  train loss: 0.0571175896
Epoch:  1400  |  train loss: 0.0571175873
Epoch:  1500  |  train loss: 0.0571175881
Epoch:  1600  |  train loss: 0.0571175888
Epoch:  1700  |  train loss: 0.0571175881
Epoch:  1800  |  train loss: 0.0571175888
Epoch:  1900  |  train loss: 0.0571175903
Epoch:  2000  |  train loss: 0.0571175911
Processing class: 13
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565329336
Epoch:   200  |  train loss: 0.0565329336
Epoch:   300  |  train loss: 0.0565329343
Epoch:   400  |  train loss: 0.0565329358
Epoch:   500  |  train loss: 0.0565329358
Epoch:   600  |  train loss: 0.0565329343
Epoch:   700  |  train loss: 0.0565329351
Epoch:   800  |  train loss: 0.0565329351
Epoch:   900  |  train loss: 0.0565329343
Epoch:  1000  |  train loss: 0.0565329373
Epoch:  1100  |  train loss: 0.0565329358
Epoch:  1200  |  train loss: 0.0565329343
Epoch:  1300  |  train loss: 0.0565329358
Epoch:  1400  |  train loss: 0.0565329328
Epoch:  1500  |  train loss: 0.0565329358
Epoch:  1600  |  train loss: 0.0565329336
Epoch:  1700  |  train loss: 0.0565329365
Epoch:  1800  |  train loss: 0.0565329351
Epoch:  1900  |  train loss: 0.0565329358
Epoch:  2000  |  train loss: 0.0565329358
Processing class: 14
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570782013
Epoch:   200  |  train loss: 0.0570782006
Epoch:   300  |  train loss: 0.0570782006
Epoch:   400  |  train loss: 0.0570781998
Epoch:   500  |  train loss: 0.0570781976
Epoch:   600  |  train loss: 0.0570781991
Epoch:   700  |  train loss: 0.0570782006
Epoch:   800  |  train loss: 0.0570782013
Epoch:   900  |  train loss: 0.0570781976
Epoch:  1000  |  train loss: 0.0570782028
Epoch:  1100  |  train loss: 0.0570782028
Epoch:  1200  |  train loss: 0.0570782006
Epoch:  1300  |  train loss: 0.0570782006
Epoch:  1400  |  train loss: 0.0570782043
Epoch:  1500  |  train loss: 0.0570782006
Epoch:  1600  |  train loss: 0.0570782006
Epoch:  1700  |  train loss: 0.0570782013
Epoch:  1800  |  train loss: 0.0570781998
Epoch:  1900  |  train loss: 0.0570782013
Epoch:  2000  |  train loss: 0.0570782006
Processing class: 15
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0560695089
Epoch:   200  |  train loss: 0.0560695089
Epoch:   300  |  train loss: 0.0560695074
Epoch:   400  |  train loss: 0.0560695089
Epoch:   500  |  train loss: 0.0560695097
Epoch:   600  |  train loss: 0.0560695089
Epoch:   700  |  train loss: 0.0560695074
Epoch:   800  |  train loss: 0.0560695089
Epoch:   900  |  train loss: 0.0560695112
Epoch:  1000  |  train loss: 0.0560695119
Epoch:  1100  |  train loss: 0.0560695097
Epoch:  1200  |  train loss: 0.0560695089
Epoch:  1300  |  train loss: 0.0560695112
Epoch:  1400  |  train loss: 0.0560695089
Epoch:  1500  |  train loss: 0.0560695112
Epoch:  1600  |  train loss: 0.0560695074
Epoch:  1700  |  train loss: 0.0560695112
Epoch:  1800  |  train loss: 0.0560695082
Epoch:  1900  |  train loss: 0.0560695089
Epoch:  2000  |  train loss: 0.0560695104
Processing class: 16
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570661321
Epoch:   200  |  train loss: 0.0570661336
Epoch:   300  |  train loss: 0.0570661351
Epoch:   400  |  train loss: 0.0570661351
Epoch:   500  |  train loss: 0.0570661344
Epoch:   600  |  train loss: 0.0570661359
Epoch:   700  |  train loss: 0.0570661321
Epoch:   800  |  train loss: 0.0570661336
Epoch:   900  |  train loss: 0.0570661314
Epoch:  1000  |  train loss: 0.0570661344
Epoch:  1100  |  train loss: 0.0570661314
Epoch:  1200  |  train loss: 0.0570661336
Epoch:  1300  |  train loss: 0.0570661299
Epoch:  1400  |  train loss: 0.0570661314
Epoch:  1500  |  train loss: 0.0570661336
Epoch:  1600  |  train loss: 0.0570661344
Epoch:  1700  |  train loss: 0.0570661321
Epoch:  1800  |  train loss: 0.0570661321
Epoch:  1900  |  train loss: 0.0570661336
Epoch:  2000  |  train loss: 0.0570661329
Processing class: 17
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 18
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0572517723
Epoch:   200  |  train loss: 0.0572517738
Epoch:   300  |  train loss: 0.0572517745
Epoch:   400  |  train loss: 0.0572517715
Epoch:   500  |  train loss: 0.0572517753
Epoch:   600  |  train loss: 0.0572517738
Epoch:   700  |  train loss: 0.0572517715
Epoch:   800  |  train loss: 0.0572517723
Epoch:   900  |  train loss: 0.0572517730
Epoch:  1000  |  train loss: 0.0572517723
Epoch:  1100  |  train loss: 0.0572517753
Epoch:  1200  |  train loss: 0.0572517723
Epoch:  1300  |  train loss: 0.0572517715
Epoch:  1400  |  train loss: 0.0572517753
Epoch:  1500  |  train loss: 0.0572517723
Epoch:  1600  |  train loss: 0.0572517738
Epoch:  1700  |  train loss: 0.0572517760
Epoch:  1800  |  train loss: 0.0572517738
Epoch:  1900  |  train loss: 0.0572517723
Epoch:  2000  |  train loss: 0.0572517730
Processing class: 19
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0529938973
Epoch:   200  |  train loss: 0.0529938966
Epoch:   300  |  train loss: 0.0529938966
Epoch:   400  |  train loss: 0.0529938981
Epoch:   500  |  train loss: 0.0529938973
Epoch:   600  |  train loss: 0.0529938966
Epoch:   700  |  train loss: 0.0529938966
Epoch:   800  |  train loss: 0.0529938966
Epoch:   900  |  train loss: 0.0529938944
Epoch:  1000  |  train loss: 0.0529938944
Epoch:  1100  |  train loss: 0.0529938944
Epoch:  1200  |  train loss: 0.0529938988
Epoch:  1300  |  train loss: 0.0529938959
Epoch:  1400  |  train loss: 0.0529938973
Epoch:  1500  |  train loss: 0.0529938944
Epoch:  1600  |  train loss: 0.0529938973
Epoch:  1700  |  train loss: 0.0529938944
Epoch:  1800  |  train loss: 0.0529938944
Epoch:  1900  |  train loss: 0.0529938966
Epoch:  2000  |  train loss: 0.0529938959
Processing class: 20
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0569265410
Epoch:   200  |  train loss: 0.0569265395
Epoch:   300  |  train loss: 0.0569265410
Epoch:   400  |  train loss: 0.0569265410
Epoch:   500  |  train loss: 0.0569265418
Epoch:   600  |  train loss: 0.0569265388
Epoch:   700  |  train loss: 0.0569265395
Epoch:   800  |  train loss: 0.0569265403
Epoch:   900  |  train loss: 0.0569265403
Epoch:  1000  |  train loss: 0.0569265403
Epoch:  1100  |  train loss: 0.0569265403
Epoch:  1200  |  train loss: 0.0569265425
Epoch:  1300  |  train loss: 0.0569265403
Epoch:  1400  |  train loss: 0.0569265418
Epoch:  1500  |  train loss: 0.0569265425
Epoch:  1600  |  train loss: 0.0569265418
Epoch:  1700  |  train loss: 0.0569265418
Epoch:  1800  |  train loss: 0.0569265410
Epoch:  1900  |  train loss: 0.0569265403
Epoch:  2000  |  train loss: 0.0569265410
Processing class: 21
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 22
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570067979
Epoch:   200  |  train loss: 0.0570067964
Epoch:   300  |  train loss: 0.0570067950
Epoch:   400  |  train loss: 0.0570067994
Epoch:   500  |  train loss: 0.0570068002
Epoch:   600  |  train loss: 0.0570067972
Epoch:   700  |  train loss: 0.0570067964
Epoch:   800  |  train loss: 0.0570067994
Epoch:   900  |  train loss: 0.0570068002
Epoch:  1000  |  train loss: 0.0570067979
Epoch:  1100  |  train loss: 0.0570067987
Epoch:  1200  |  train loss: 0.0570068002
Epoch:  1300  |  train loss: 0.0570067979
Epoch:  1400  |  train loss: 0.0570067987
Epoch:  1500  |  train loss: 0.0570067972
Epoch:  1600  |  train loss: 0.0570067979
Epoch:  1700  |  train loss: 0.0570068002
Epoch:  1800  |  train loss: 0.0570067964
Epoch:  1900  |  train loss: 0.0570067935
Epoch:  2000  |  train loss: 0.0570068002
Processing class: 23
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0574604467
Epoch:   200  |  train loss: 0.0574604481
Epoch:   300  |  train loss: 0.0574604467
Epoch:   400  |  train loss: 0.0574604474
Epoch:   500  |  train loss: 0.0574604489
Epoch:   600  |  train loss: 0.0574604481
Epoch:   700  |  train loss: 0.0574604481
Epoch:   800  |  train loss: 0.0574604474
Epoch:   900  |  train loss: 0.0574604489
Epoch:  1000  |  train loss: 0.0574604459
Epoch:  1100  |  train loss: 0.0574604467
Epoch:  1200  |  train loss: 0.0574604481
Epoch:  1300  |  train loss: 0.0574604459
Epoch:  1400  |  train loss: 0.0574604467
Epoch:  1500  |  train loss: 0.0574604459
Epoch:  1600  |  train loss: 0.0574604489
Epoch:  1700  |  train loss: 0.0574604481
Epoch:  1800  |  train loss: 0.0574604467
Epoch:  1900  |  train loss: 0.0574604452
Epoch:  2000  |  train loss: 0.0574604467
Processing class: 24
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565902069
Epoch:   200  |  train loss: 0.0565902084
Epoch:   300  |  train loss: 0.0565902084
Epoch:   400  |  train loss: 0.0565902084
Epoch:   500  |  train loss: 0.0565902099
Epoch:   600  |  train loss: 0.0565902092
Epoch:   700  |  train loss: 0.0565902084
Epoch:   800  |  train loss: 0.0565902099
Epoch:   900  |  train loss: 0.0565902084
Epoch:  1000  |  train loss: 0.0565902106
Epoch:  1100  |  train loss: 0.0565902084
Epoch:  1200  |  train loss: 0.0565902092
Epoch:  1300  |  train loss: 0.0565902099
Epoch:  1400  |  train loss: 0.0565902084
Epoch:  1500  |  train loss: 0.0565902092
Epoch:  1600  |  train loss: 0.0565902077
Epoch:  1700  |  train loss: 0.0565902092
Epoch:  1800  |  train loss: 0.0565902092
Epoch:  1900  |  train loss: 0.0565902092
Epoch:  2000  |  train loss: 0.0565902106
Processing class: 25
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0566742852
Epoch:   200  |  train loss: 0.0566742867
Epoch:   300  |  train loss: 0.0566742845
Epoch:   400  |  train loss: 0.0566742867
Epoch:   500  |  train loss: 0.0566742845
Epoch:   600  |  train loss: 0.0566742860
Epoch:   700  |  train loss: 0.0566742837
Epoch:   800  |  train loss: 0.0566742882
Epoch:   900  |  train loss: 0.0566742867
Epoch:  1000  |  train loss: 0.0566742860
Epoch:  1100  |  train loss: 0.0566742852
Epoch:  1200  |  train loss: 0.0566742852
Epoch:  1300  |  train loss: 0.0566742837
Epoch:  1400  |  train loss: 0.0566742837
Epoch:  1500  |  train loss: 0.0566742845
Epoch:  1600  |  train loss: 0.0566742860
Epoch:  1700  |  train loss: 0.0566742837
Epoch:  1800  |  train loss: 0.0566742830
Epoch:  1900  |  train loss: 0.0566742845
Epoch:  2000  |  train loss: 0.0566742837
Processing class: 26
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0572100930
Epoch:   200  |  train loss: 0.0572100960
Epoch:   300  |  train loss: 0.0572100945
Epoch:   400  |  train loss: 0.0572100915
Epoch:   500  |  train loss: 0.0572100930
Epoch:   600  |  train loss: 0.0572100937
Epoch:   700  |  train loss: 0.0572100930
Epoch:   800  |  train loss: 0.0572100930
Epoch:   900  |  train loss: 0.0572100937
Epoch:  1000  |  train loss: 0.0572100930
Epoch:  1100  |  train loss: 0.0572100937
Epoch:  1200  |  train loss: 0.0572100908
Epoch:  1300  |  train loss: 0.0572100937
Epoch:  1400  |  train loss: 0.0572100930
Epoch:  1500  |  train loss: 0.0572100937
Epoch:  1600  |  train loss: 0.0572100937
Epoch:  1700  |  train loss: 0.0572100922
Epoch:  1800  |  train loss: 0.0572100937
Epoch:  1900  |  train loss: 0.0572100937
Epoch:  2000  |  train loss: 0.0572100952
Processing class: 27
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0553532168
Epoch:   200  |  train loss: 0.0553532153
Epoch:   300  |  train loss: 0.0553532161
Epoch:   400  |  train loss: 0.0553532176
Epoch:   500  |  train loss: 0.0553532198
Epoch:   600  |  train loss: 0.0553532191
Epoch:   700  |  train loss: 0.0553532183
Epoch:   800  |  train loss: 0.0553532168
Epoch:   900  |  train loss: 0.0553532161
Epoch:  1000  |  train loss: 0.0553532206
Epoch:  1100  |  train loss: 0.0553532176
Epoch:  1200  |  train loss: 0.0553532176
Epoch:  1300  |  train loss: 0.0553532191
Epoch:  1400  |  train loss: 0.0553532191
Epoch:  1500  |  train loss: 0.0553532198
Epoch:  1600  |  train loss: 0.0553532176
Epoch:  1700  |  train loss: 0.0553532176
Epoch:  1800  |  train loss: 0.0553532183
Epoch:  1900  |  train loss: 0.0553532183
Epoch:  2000  |  train loss: 0.0553532161
Processing class: 28
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0574007623
Epoch:   200  |  train loss: 0.0574007653
Epoch:   300  |  train loss: 0.0574007645
Epoch:   400  |  train loss: 0.0574007660
Epoch:   500  |  train loss: 0.0574007660
Epoch:   600  |  train loss: 0.0574007645
Epoch:   700  |  train loss: 0.0574007653
Epoch:   800  |  train loss: 0.0574007645
Epoch:   900  |  train loss: 0.0574007638
Epoch:  1000  |  train loss: 0.0574007645
Epoch:  1100  |  train loss: 0.0574007653
Epoch:  1200  |  train loss: 0.0574007660
Epoch:  1300  |  train loss: 0.0574007668
Epoch:  1400  |  train loss: 0.0574007645
Epoch:  1500  |  train loss: 0.0574007638
Epoch:  1600  |  train loss: 0.0574007660
Epoch:  1700  |  train loss: 0.0574007653
Epoch:  1800  |  train loss: 0.0574007690
Epoch:  1900  |  train loss: 0.0574007675
Epoch:  2000  |  train loss: 0.0574007638
Processing class: 29
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0566025831
Epoch:   200  |  train loss: 0.0566025831
Epoch:   300  |  train loss: 0.0566025831
Epoch:   400  |  train loss: 0.0566025838
Epoch:   500  |  train loss: 0.0566025838
Epoch:   600  |  train loss: 0.0566025846
Epoch:   700  |  train loss: 0.0566025838
Epoch:   800  |  train loss: 0.0566025868
Epoch:   900  |  train loss: 0.0566025838
Epoch:  1000  |  train loss: 0.0566025846
Epoch:  1100  |  train loss: 0.0566025831
Epoch:  1200  |  train loss: 0.0566025816
Epoch:  1300  |  train loss: 0.0566025816
Epoch:  1400  |  train loss: 0.0566025823
Epoch:  1500  |  train loss: 0.0566025838
Epoch:  1600  |  train loss: 0.0566025838
Epoch:  1700  |  train loss: 0.0566025838
Epoch:  1800  |  train loss: 0.0566025831
Epoch:  1900  |  train loss: 0.0566025816
Epoch:  2000  |  train loss: 0.0566025831
Processing class: 30
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570332833
Epoch:   200  |  train loss: 0.0570332870
Epoch:   300  |  train loss: 0.0570332855
Epoch:   400  |  train loss: 0.0570332862
Epoch:   500  |  train loss: 0.0570332862
Epoch:   600  |  train loss: 0.0570332840
Epoch:   700  |  train loss: 0.0570332862
Epoch:   800  |  train loss: 0.0570332840
Epoch:   900  |  train loss: 0.0570332877
Epoch:  1000  |  train loss: 0.0570332825
Epoch:  1100  |  train loss: 0.0570332885
Epoch:  1200  |  train loss: 0.0570332855
Epoch:  1300  |  train loss: 0.0570332848
Epoch:  1400  |  train loss: 0.0570332855
Epoch:  1500  |  train loss: 0.0570332833
Epoch:  1600  |  train loss: 0.0570332840
Epoch:  1700  |  train loss: 0.0570332855
Epoch:  1800  |  train loss: 0.0570332840
Epoch:  1900  |  train loss: 0.0570332855
Epoch:  2000  |  train loss: 0.0570332840
Processing class: 31
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 32
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0568076082
Epoch:   200  |  train loss: 0.0568076067
Epoch:   300  |  train loss: 0.0568076119
Epoch:   400  |  train loss: 0.0568076089
Epoch:   500  |  train loss: 0.0568076082
Epoch:   600  |  train loss: 0.0568076089
Epoch:   700  |  train loss: 0.0568076074
Epoch:   800  |  train loss: 0.0568076089
Epoch:   900  |  train loss: 0.0568076082
Epoch:  1000  |  train loss: 0.0568076074
Epoch:  1100  |  train loss: 0.0568076089
Epoch:  1200  |  train loss: 0.0568076052
Epoch:  1300  |  train loss: 0.0568076104
Epoch:  1400  |  train loss: 0.0568076082
Epoch:  1500  |  train loss: 0.0568076104
Epoch:  1600  |  train loss: 0.0568076059
Epoch:  1700  |  train loss: 0.0568076104
Epoch:  1800  |  train loss: 0.0568076104
Epoch:  1900  |  train loss: 0.0568076052
Epoch:  2000  |  train loss: 0.0568076082
Processing class: 33
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 34
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0567425825
Epoch:   200  |  train loss: 0.0567425855
Epoch:   300  |  train loss: 0.0567425817
Epoch:   400  |  train loss: 0.0567425862
Epoch:   500  |  train loss: 0.0567425862
Epoch:   600  |  train loss: 0.0567425847
Epoch:   700  |  train loss: 0.0567425855
Epoch:   800  |  train loss: 0.0567425832
Epoch:   900  |  train loss: 0.0567425832
Epoch:  1000  |  train loss: 0.0567425862
Epoch:  1100  |  train loss: 0.0567425840
Epoch:  1200  |  train loss: 0.0567425869
Epoch:  1300  |  train loss: 0.0567425847
Epoch:  1400  |  train loss: 0.0567425810
Epoch:  1500  |  train loss: 0.0567425847
Epoch:  1600  |  train loss: 0.0567425855
Epoch:  1700  |  train loss: 0.0567425855
Epoch:  1800  |  train loss: 0.0567425855
Epoch:  1900  |  train loss: 0.0567425832
Epoch:  2000  |  train loss: 0.0567425840
Processing class: 35
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 36
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0567433409
Epoch:   200  |  train loss: 0.0567433394
Epoch:   300  |  train loss: 0.0567433380
Epoch:   400  |  train loss: 0.0567433394
Epoch:   500  |  train loss: 0.0567433372
Epoch:   600  |  train loss: 0.0567433402
Epoch:   700  |  train loss: 0.0567433365
Epoch:   800  |  train loss: 0.0567433372
Epoch:   900  |  train loss: 0.0567433380
Epoch:  1000  |  train loss: 0.0567433380
Epoch:  1100  |  train loss: 0.0567433365
Epoch:  1200  |  train loss: 0.0567433402
Epoch:  1300  |  train loss: 0.0567433387
Epoch:  1400  |  train loss: 0.0567433387
Epoch:  1500  |  train loss: 0.0567433387
Epoch:  1600  |  train loss: 0.0567433380
Epoch:  1700  |  train loss: 0.0567433387
Epoch:  1800  |  train loss: 0.0567433387
Epoch:  1900  |  train loss: 0.0567433402
Epoch:  2000  |  train loss: 0.0567433394
Processing class: 37
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0568574749
Epoch:   200  |  train loss: 0.0568574741
Epoch:   300  |  train loss: 0.0568574764
Epoch:   400  |  train loss: 0.0568574756
Epoch:   500  |  train loss: 0.0568574749
Epoch:   600  |  train loss: 0.0568574749
Epoch:   700  |  train loss: 0.0568574756
Epoch:   800  |  train loss: 0.0568574764
Epoch:   900  |  train loss: 0.0568574756
Epoch:  1000  |  train loss: 0.0568574756
Epoch:  1100  |  train loss: 0.0568574749
Epoch:  1200  |  train loss: 0.0568574749
Epoch:  1300  |  train loss: 0.0568574741
Epoch:  1400  |  train loss: 0.0568574756
Epoch:  1500  |  train loss: 0.0568574741
Epoch:  1600  |  train loss: 0.0568574771
Epoch:  1700  |  train loss: 0.0568574764
Epoch:  1800  |  train loss: 0.0568574741
Epoch:  1900  |  train loss: 0.0568574734
Epoch:  2000  |  train loss: 0.0568574786
Processing class: 38
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557683051
Epoch:   200  |  train loss: 0.0557683051
Epoch:   300  |  train loss: 0.0557683051
Epoch:   400  |  train loss: 0.0557683073
Epoch:   500  |  train loss: 0.0557683051
Epoch:   600  |  train loss: 0.0557683073
Epoch:   700  |  train loss: 0.0557683051
Epoch:   800  |  train loss: 0.0557683080
Epoch:   900  |  train loss: 0.0557683080
Epoch:  1000  |  train loss: 0.0557683073
Epoch:  1100  |  train loss: 0.0557683073
Epoch:  1200  |  train loss: 0.0557683021
Epoch:  1300  |  train loss: 0.0557683066
Epoch:  1400  |  train loss: 0.0557683073
Epoch:  1500  |  train loss: 0.0557683051
Epoch:  1600  |  train loss: 0.0557683073
Epoch:  1700  |  train loss: 0.0557683066
Epoch:  1800  |  train loss: 0.0557683080
Epoch:  1900  |  train loss: 0.0557683058
Epoch:  2000  |  train loss: 0.0557683066
Processing class: 39
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0566674367
Epoch:   200  |  train loss: 0.0566674352
Epoch:   300  |  train loss: 0.0566674344
Epoch:   400  |  train loss: 0.0566674367
Epoch:   500  |  train loss: 0.0566674359
Epoch:   600  |  train loss: 0.0566674374
Epoch:   700  |  train loss: 0.0566674374
Epoch:   800  |  train loss: 0.0566674359
Epoch:   900  |  train loss: 0.0566674359
Epoch:  1000  |  train loss: 0.0566674374
Epoch:  1100  |  train loss: 0.0566674381
Epoch:  1200  |  train loss: 0.0566674367
Epoch:  1300  |  train loss: 0.0566674367
Epoch:  1400  |  train loss: 0.0566674374
Epoch:  1500  |  train loss: 0.0566674374
Epoch:  1600  |  train loss: 0.0566674359
Epoch:  1700  |  train loss: 0.0566674367
Epoch:  1800  |  train loss: 0.0566674374
Epoch:  1900  |  train loss: 0.0566674374
Epoch:  2000  |  train loss: 0.0566674367
Processing class: 40
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0572902866
Epoch:   200  |  train loss: 0.0572902866
Epoch:   300  |  train loss: 0.0572902873
Epoch:   400  |  train loss: 0.0572902873
Epoch:   500  |  train loss: 0.0572902873
Epoch:   600  |  train loss: 0.0572902858
Epoch:   700  |  train loss: 0.0572902888
Epoch:   800  |  train loss: 0.0572902866
Epoch:   900  |  train loss: 0.0572902866
Epoch:  1000  |  train loss: 0.0572902866
Epoch:  1100  |  train loss: 0.0572902881
Epoch:  1200  |  train loss: 0.0572902866
Epoch:  1300  |  train loss: 0.0572902843
Epoch:  1400  |  train loss: 0.0572902888
Epoch:  1500  |  train loss: 0.0572902866
Epoch:  1600  |  train loss: 0.0572902881
Epoch:  1700  |  train loss: 0.0572902881
Epoch:  1800  |  train loss: 0.0572902843
Epoch:  1900  |  train loss: 0.0572902843
Epoch:  2000  |  train loss: 0.0572902866
Processing class: 41
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570486836
Epoch:   200  |  train loss: 0.0570486866
Epoch:   300  |  train loss: 0.0570486814
Epoch:   400  |  train loss: 0.0570486829
Epoch:   500  |  train loss: 0.0570486821
Epoch:   600  |  train loss: 0.0570486844
Epoch:   700  |  train loss: 0.0570486836
Epoch:   800  |  train loss: 0.0570486851
Epoch:   900  |  train loss: 0.0570486844
Epoch:  1000  |  train loss: 0.0570486844
Epoch:  1100  |  train loss: 0.0570486844
Epoch:  1200  |  train loss: 0.0570486844
Epoch:  1300  |  train loss: 0.0570486821
Epoch:  1400  |  train loss: 0.0570486836
Epoch:  1500  |  train loss: 0.0570486829
Epoch:  1600  |  train loss: 0.0570486836
Epoch:  1700  |  train loss: 0.0570486821
Epoch:  1800  |  train loss: 0.0570486866
Epoch:  1900  |  train loss: 0.0570486829
Epoch:  2000  |  train loss: 0.0570486844
Processing class: 42
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0561869651
Epoch:   200  |  train loss: 0.0561869651
Epoch:   300  |  train loss: 0.0561869636
Epoch:   400  |  train loss: 0.0561869688
Epoch:   500  |  train loss: 0.0561869666
Epoch:   600  |  train loss: 0.0561869681
Epoch:   700  |  train loss: 0.0561869681
Epoch:   800  |  train loss: 0.0561869666
Epoch:   900  |  train loss: 0.0561869666
Epoch:  1000  |  train loss: 0.0561869666
Epoch:  1100  |  train loss: 0.0561869673
Epoch:  1200  |  train loss: 0.0561869681
Epoch:  1300  |  train loss: 0.0561869666
Epoch:  1400  |  train loss: 0.0561869644
Epoch:  1500  |  train loss: 0.0561869644
Epoch:  1600  |  train loss: 0.0561869644
Epoch:  1700  |  train loss: 0.0561869651
Epoch:  1800  |  train loss: 0.0561869651
Epoch:  1900  |  train loss: 0.0561869644
Epoch:  2000  |  train loss: 0.0561869651
Processing class: 43
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570598736
Epoch:   200  |  train loss: 0.0570598766
Epoch:   300  |  train loss: 0.0570598729
Epoch:   400  |  train loss: 0.0570598759
Epoch:   500  |  train loss: 0.0570598759
Epoch:   600  |  train loss: 0.0570598751
Epoch:   700  |  train loss: 0.0570598736
Epoch:   800  |  train loss: 0.0570598751
Epoch:   900  |  train loss: 0.0570598729
Epoch:  1000  |  train loss: 0.0570598751
Epoch:  1100  |  train loss: 0.0570598729
Epoch:  1200  |  train loss: 0.0570598751
Epoch:  1300  |  train loss: 0.0570598751
Epoch:  1400  |  train loss: 0.0570598766
Epoch:  1500  |  train loss: 0.0570598751
Epoch:  1600  |  train loss: 0.0570598751
Epoch:  1700  |  train loss: 0.0570598729
Epoch:  1800  |  train loss: 0.0570598736
Epoch:  1900  |  train loss: 0.0570598751
Epoch:  2000  |  train loss: 0.0570598744
Processing class: 44
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0568415843
Epoch:   200  |  train loss: 0.0568415865
Epoch:   300  |  train loss: 0.0568415835
Epoch:   400  |  train loss: 0.0568415835
Epoch:   500  |  train loss: 0.0568415835
Epoch:   600  |  train loss: 0.0568415858
Epoch:   700  |  train loss: 0.0568415865
Epoch:   800  |  train loss: 0.0568415873
Epoch:   900  |  train loss: 0.0568415888
Epoch:  1000  |  train loss: 0.0568415888
Epoch:  1100  |  train loss: 0.0568415843
Epoch:  1200  |  train loss: 0.0568415858
Epoch:  1300  |  train loss: 0.0568415843
Epoch:  1400  |  train loss: 0.0568415835
Epoch:  1500  |  train loss: 0.0568415888
Epoch:  1600  |  train loss: 0.0568415858
Epoch:  1700  |  train loss: 0.0568415865
Epoch:  1800  |  train loss: 0.0568415843
Epoch:  1900  |  train loss: 0.0568415858
Epoch:  2000  |  train loss: 0.0568415858
Processing class: 45
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0570956118
Epoch:   200  |  train loss: 0.0570956104
Epoch:   300  |  train loss: 0.0570956118
Epoch:   400  |  train loss: 0.0570956089
Epoch:   500  |  train loss: 0.0570956141
Epoch:   600  |  train loss: 0.0570956118
Epoch:   700  |  train loss: 0.0570956104
Epoch:   800  |  train loss: 0.0570956104
Epoch:   900  |  train loss: 0.0570956104
Epoch:  1000  |  train loss: 0.0570956133
Epoch:  1100  |  train loss: 0.0570956118
Epoch:  1200  |  train loss: 0.0570956126
Epoch:  1300  |  train loss: 0.0570956148
Epoch:  1400  |  train loss: 0.0570956118
Epoch:  1500  |  train loss: 0.0570956126
Epoch:  1600  |  train loss: 0.0570956104
Epoch:  1700  |  train loss: 0.0570956111
Epoch:  1800  |  train loss: 0.0570956118
Epoch:  1900  |  train loss: 0.0570956111
Epoch:  2000  |  train loss: 0.0570956104
Processing class: 46
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0571123153
Epoch:   200  |  train loss: 0.0571123175
Epoch:   300  |  train loss: 0.0571123160
Epoch:   400  |  train loss: 0.0571123168
Epoch:   500  |  train loss: 0.0571123160
Epoch:   600  |  train loss: 0.0571123183
Epoch:   700  |  train loss: 0.0571123175
Epoch:   800  |  train loss: 0.0571123175
Epoch:   900  |  train loss: 0.0571123175
Epoch:  1000  |  train loss: 0.0571123160
Epoch:  1100  |  train loss: 0.0571123153
Epoch:  1200  |  train loss: 0.0571123160
Epoch:  1300  |  train loss: 0.0571123183
Epoch:  1400  |  train loss: 0.0571123183
Epoch:  1500  |  train loss: 0.0571123175
Epoch:  1600  |  train loss: 0.0571123160
Epoch:  1700  |  train loss: 0.0571123168
Epoch:  1800  |  train loss: 0.0571123175
Epoch:  1900  |  train loss: 0.0571123160
Epoch:  2000  |  train loss: 0.0571123160
Processing class: 47
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565713905
Epoch:   200  |  train loss: 0.0565713912
Epoch:   300  |  train loss: 0.0565713920
Epoch:   400  |  train loss: 0.0565713897
Epoch:   500  |  train loss: 0.0565713920
Epoch:   600  |  train loss: 0.0565713935
Epoch:   700  |  train loss: 0.0565713897
Epoch:   800  |  train loss: 0.0565713905
Epoch:   900  |  train loss: 0.0565713935
Epoch:  1000  |  train loss: 0.0565713942
Epoch:  1100  |  train loss: 0.0565713890
Epoch:  1200  |  train loss: 0.0565713912
Epoch:  1300  |  train loss: 0.0565713905
Epoch:  1400  |  train loss: 0.0565713897
Epoch:  1500  |  train loss: 0.0565713920
Epoch:  1600  |  train loss: 0.0565713942
Epoch:  1700  |  train loss: 0.0565713912
Epoch:  1800  |  train loss: 0.0565713920
Epoch:  1900  |  train loss: 0.0565713935
Epoch:  2000  |  train loss: 0.0565713905
Processing class: 48
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0569937289
Epoch:   200  |  train loss: 0.0569937296
Epoch:   300  |  train loss: 0.0569937311
Epoch:   400  |  train loss: 0.0569937304
Epoch:   500  |  train loss: 0.0569937319
Epoch:   600  |  train loss: 0.0569937311
Epoch:   700  |  train loss: 0.0569937319
Epoch:   800  |  train loss: 0.0569937289
Epoch:   900  |  train loss: 0.0569937304
Epoch:  1000  |  train loss: 0.0569937304
Epoch:  1100  |  train loss: 0.0569937319
Epoch:  1200  |  train loss: 0.0569937289
Epoch:  1300  |  train loss: 0.0569937326
Epoch:  1400  |  train loss: 0.0569937311
Epoch:  1500  |  train loss: 0.0569937319
Epoch:  1600  |  train loss: 0.0569937311
Epoch:  1700  |  train loss: 0.0569937304
Epoch:  1800  |  train loss: 0.0569937304
Epoch:  1900  |  train loss: 0.0569937311
Epoch:  2000  |  train loss: 0.0569937304
Processing class: 49
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Clasifying using reconstruction function cost
/home/z1165703/FeCAM/models/base.py:195: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data_point = torch.tensor(data_point).float().cuda()
2024-04-01 00:40:10,690 [trainer.py] => CNN: {'total': 83.44, '00-09': 87.7, '10-19': 79.6, '20-29': 84.9, '30-39': 81.0, '40-49': 84.0, 'old': 0, 'new': 83.44}
2024-04-01 00:40:10,691 [trainer.py] => No NME accuracy
2024-04-01 00:40:10,691 [trainer.py] => FeCAM: {'total': 70.96, '00-09': 78.1, '10-19': 64.7, '20-29': 73.8, '30-39': 66.3, '40-49': 71.9, 'old': 0, 'new': 70.96}
2024-04-01 00:40:10,691 [trainer.py] => CNN top1 curve: [83.44]
2024-04-01 00:40:10,691 [trainer.py] => CNN top5 curve: [96.5]
2024-04-01 00:40:10,691 [trainer.py] => FeCAM top1 curve: [70.96]
2024-04-01 00:40:10,691 [trainer.py] => FeCAM top5 curve: [86.38]

2024-04-01 00:40:10,695 [fecam.py] => Learning on 50-60
Processing class: 50
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0558654025
Epoch:   200  |  train loss: 0.0558654033
Epoch:   300  |  train loss: 0.0558653995
Epoch:   400  |  train loss: 0.0558654025
Epoch:   500  |  train loss: 0.0558654025
Epoch:   600  |  train loss: 0.0558654033
Epoch:   700  |  train loss: 0.0558654040
Epoch:   800  |  train loss: 0.0558654033
Epoch:   900  |  train loss: 0.0558654033
Epoch:  1000  |  train loss: 0.0558654033
Epoch:  1100  |  train loss: 0.0558654025
Epoch:  1200  |  train loss: 0.0558654040
Epoch:  1300  |  train loss: 0.0558654055
Epoch:  1400  |  train loss: 0.0558654040
Epoch:  1500  |  train loss: 0.0558654040
Epoch:  1600  |  train loss: 0.0558654048
Epoch:  1700  |  train loss: 0.0558654040
Epoch:  1800  |  train loss: 0.0558654048
Epoch:  1900  |  train loss: 0.0558654040
Epoch:  2000  |  train loss: 0.0558654010
Processing class: 51
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564991646
Epoch:   200  |  train loss: 0.0564991616
Epoch:   300  |  train loss: 0.0564991623
Epoch:   400  |  train loss: 0.0564991623
Epoch:   500  |  train loss: 0.0564991623
Epoch:   600  |  train loss: 0.0564991638
Epoch:   700  |  train loss: 0.0564991623
Epoch:   800  |  train loss: 0.0564991623
Epoch:   900  |  train loss: 0.0564991638
Epoch:  1000  |  train loss: 0.0564991616
Epoch:  1100  |  train loss: 0.0564991616
Epoch:  1200  |  train loss: 0.0564991601
Epoch:  1300  |  train loss: 0.0564991593
Epoch:  1400  |  train loss: 0.0564991616
Epoch:  1500  |  train loss: 0.0564991631
Epoch:  1600  |  train loss: 0.0564991638
Epoch:  1700  |  train loss: 0.0564991631
Epoch:  1800  |  train loss: 0.0564991646
Epoch:  1900  |  train loss: 0.0564991601
Epoch:  2000  |  train loss: 0.0564991593
Processing class: 52
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0561029628
Epoch:   200  |  train loss: 0.0561029628
Epoch:   300  |  train loss: 0.0561029613
Epoch:   400  |  train loss: 0.0561029598
Epoch:   500  |  train loss: 0.0561029620
Epoch:   600  |  train loss: 0.0561029643
Epoch:   700  |  train loss: 0.0561029628
Epoch:   800  |  train loss: 0.0561029628
Epoch:   900  |  train loss: 0.0561029628
Epoch:  1000  |  train loss: 0.0561029635
Epoch:  1100  |  train loss: 0.0561029613
Epoch:  1200  |  train loss: 0.0561029635
Epoch:  1300  |  train loss: 0.0561029620
Epoch:  1400  |  train loss: 0.0561029650
Epoch:  1500  |  train loss: 0.0561029643
Epoch:  1600  |  train loss: 0.0561029613
Epoch:  1700  |  train loss: 0.0561029613
Epoch:  1800  |  train loss: 0.0561029635
Epoch:  1900  |  train loss: 0.0561029650
Epoch:  2000  |  train loss: 0.0561029620
Processing class: 53
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557190709
Epoch:   200  |  train loss: 0.0557190701
Epoch:   300  |  train loss: 0.0557190701
Epoch:   400  |  train loss: 0.0557190709
Epoch:   500  |  train loss: 0.0557190709
Epoch:   600  |  train loss: 0.0557190664
Epoch:   700  |  train loss: 0.0557190701
Epoch:   800  |  train loss: 0.0557190709
Epoch:   900  |  train loss: 0.0557190716
Epoch:  1000  |  train loss: 0.0557190701
Epoch:  1100  |  train loss: 0.0557190731
Epoch:  1200  |  train loss: 0.0557190716
Epoch:  1300  |  train loss: 0.0557190716
Epoch:  1400  |  train loss: 0.0557190709
Epoch:  1500  |  train loss: 0.0557190709
Epoch:  1600  |  train loss: 0.0557190709
Epoch:  1700  |  train loss: 0.0557190701
Epoch:  1800  |  train loss: 0.0557190686
Epoch:  1900  |  train loss: 0.0557190701
Epoch:  2000  |  train loss: 0.0557190731
Processing class: 54
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0487826467
Epoch:   200  |  train loss: 0.0487826481
Epoch:   300  |  train loss: 0.0487826481
Epoch:   400  |  train loss: 0.0487826481
Epoch:   500  |  train loss: 0.0487826481
Epoch:   600  |  train loss: 0.0487826481
Epoch:   700  |  train loss: 0.0487826474
Epoch:   800  |  train loss: 0.0487826467
Epoch:   900  |  train loss: 0.0487826496
Epoch:  1000  |  train loss: 0.0487826504
Epoch:  1100  |  train loss: 0.0487826481
Epoch:  1200  |  train loss: 0.0487826496
Epoch:  1300  |  train loss: 0.0487826474
Epoch:  1400  |  train loss: 0.0487826489
Epoch:  1500  |  train loss: 0.0487826481
Epoch:  1600  |  train loss: 0.0487826489
Epoch:  1700  |  train loss: 0.0487826467
Epoch:  1800  |  train loss: 0.0487826474
Epoch:  1900  |  train loss: 0.0487826481
Epoch:  2000  |  train loss: 0.0487826489
Processing class: 55
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 56
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0563224100
Epoch:   200  |  train loss: 0.0563224077
Epoch:   300  |  train loss: 0.0563224070
Epoch:   400  |  train loss: 0.0563224062
Epoch:   500  |  train loss: 0.0563224100
Epoch:   600  |  train loss: 0.0563224092
Epoch:   700  |  train loss: 0.0563224085
Epoch:   800  |  train loss: 0.0563224055
Epoch:   900  |  train loss: 0.0563224077
Epoch:  1000  |  train loss: 0.0563224077
Epoch:  1100  |  train loss: 0.0563224085
Epoch:  1200  |  train loss: 0.0563224070
Epoch:  1300  |  train loss: 0.0563224070
Epoch:  1400  |  train loss: 0.0563224092
Epoch:  1500  |  train loss: 0.0563224070
Epoch:  1600  |  train loss: 0.0563224092
Epoch:  1700  |  train loss: 0.0563224077
Epoch:  1800  |  train loss: 0.0563224055
Epoch:  1900  |  train loss: 0.0563224092
Epoch:  2000  |  train loss: 0.0563224062
Processing class: 57
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0559499659
Epoch:   200  |  train loss: 0.0559499644
Epoch:   300  |  train loss: 0.0559499666
Epoch:   400  |  train loss: 0.0559499666
Epoch:   500  |  train loss: 0.0559499636
Epoch:   600  |  train loss: 0.0559499651
Epoch:   700  |  train loss: 0.0559499644
Epoch:   800  |  train loss: 0.0559499651
Epoch:   900  |  train loss: 0.0559499621
Epoch:  1000  |  train loss: 0.0559499659
Epoch:  1100  |  train loss: 0.0559499644
Epoch:  1200  |  train loss: 0.0559499666
Epoch:  1300  |  train loss: 0.0559499666
Epoch:  1400  |  train loss: 0.0559499644
Epoch:  1500  |  train loss: 0.0559499636
Epoch:  1600  |  train loss: 0.0559499644
Epoch:  1700  |  train loss: 0.0559499636
Epoch:  1800  |  train loss: 0.0559499659
Epoch:  1900  |  train loss: 0.0559499636
Epoch:  2000  |  train loss: 0.0559499659
Processing class: 58
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0553316727
Epoch:   200  |  train loss: 0.0553316772
Epoch:   300  |  train loss: 0.0553316750
Epoch:   400  |  train loss: 0.0553316750
Epoch:   500  |  train loss: 0.0553316757
Epoch:   600  |  train loss: 0.0553316735
Epoch:   700  |  train loss: 0.0553316757
Epoch:   800  |  train loss: 0.0553316727
Epoch:   900  |  train loss: 0.0553316757
Epoch:  1000  |  train loss: 0.0553316757
Epoch:  1100  |  train loss: 0.0553316757
Epoch:  1200  |  train loss: 0.0553316772
Epoch:  1300  |  train loss: 0.0553316750
Epoch:  1400  |  train loss: 0.0553316757
Epoch:  1500  |  train loss: 0.0553316765
Epoch:  1600  |  train loss: 0.0553316772
Epoch:  1700  |  train loss: 0.0553316772
Epoch:  1800  |  train loss: 0.0553316757
Epoch:  1900  |  train loss: 0.0553316742
Epoch:  2000  |  train loss: 0.0553316720
Processing class: 59
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0558093123
Epoch:   200  |  train loss: 0.0558093123
Epoch:   300  |  train loss: 0.0558093123
Epoch:   400  |  train loss: 0.0558093108
Epoch:   500  |  train loss: 0.0558093086
Epoch:   600  |  train loss: 0.0558093116
Epoch:   700  |  train loss: 0.0558093123
Epoch:   800  |  train loss: 0.0558093093
Epoch:   900  |  train loss: 0.0558093101
Epoch:  1000  |  train loss: 0.0558093138
Epoch:  1100  |  train loss: 0.0558093101
Epoch:  1200  |  train loss: 0.0558093116
Epoch:  1300  |  train loss: 0.0558093101
Epoch:  1400  |  train loss: 0.0558093101
Epoch:  1500  |  train loss: 0.0558093086
Epoch:  1600  |  train loss: 0.0558093123
Epoch:  1700  |  train loss: 0.0558093116
Epoch:  1800  |  train loss: 0.0558093116
Epoch:  1900  |  train loss: 0.0558093101
Epoch:  2000  |  train loss: 0.0558093093
Clasifying using reconstruction function cost
2024-04-01 01:37:39,688 [trainer.py] => CNN: {'total': 71.75, '00-09': 82.2, '10-19': 72.8, '20-29': 78.5, '30-39': 74.9, '40-49': 68.4, '50-59': 53.7, 'old': 75.36, 'new': 53.7}
2024-04-01 01:37:39,689 [trainer.py] => No NME accuracy
2024-04-01 01:37:39,689 [trainer.py] => FeCAM: {'total': 58.87, '00-09': 74.8, '10-19': 60.7, '20-29': 71.3, '30-39': 63.6, '40-49': 65.9, '50-59': 16.9, 'old': 67.26, 'new': 16.9}
2024-04-01 01:37:39,689 [trainer.py] => CNN top1 curve: [83.44, 71.75]
2024-04-01 01:37:39,689 [trainer.py] => CNN top5 curve: [96.5, 89.6]
2024-04-01 01:37:39,689 [trainer.py] => FeCAM top1 curve: [70.96, 58.87]
2024-04-01 01:37:39,689 [trainer.py] => FeCAM top5 curve: [86.38, 79.28]

2024-04-01 01:37:39,693 [fecam.py] => Learning on 60-70
Processing class: 60
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 61
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0496171370
Epoch:   200  |  train loss: 0.0496171348
Epoch:   300  |  train loss: 0.0496171355
Epoch:   400  |  train loss: 0.0496171348
Epoch:   500  |  train loss: 0.0496171340
Epoch:   600  |  train loss: 0.0496171363
Epoch:   700  |  train loss: 0.0496171393
Epoch:   800  |  train loss: 0.0496171363
Epoch:   900  |  train loss: 0.0496171363
Epoch:  1000  |  train loss: 0.0496171348
Epoch:  1100  |  train loss: 0.0496171370
Epoch:  1200  |  train loss: 0.0496171407
Epoch:  1300  |  train loss: 0.0496171348
Epoch:  1400  |  train loss: 0.0496171370
Epoch:  1500  |  train loss: 0.0496171348
Epoch:  1600  |  train loss: 0.0496171355
Epoch:  1700  |  train loss: 0.0496171355
Epoch:  1800  |  train loss: 0.0496171363
Epoch:  1900  |  train loss: 0.0496171333
Epoch:  2000  |  train loss: 0.0496171340
Processing class: 62
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564168639
Epoch:   200  |  train loss: 0.0564168602
Epoch:   300  |  train loss: 0.0564168632
Epoch:   400  |  train loss: 0.0564168654
Epoch:   500  |  train loss: 0.0564168625
Epoch:   600  |  train loss: 0.0564168610
Epoch:   700  |  train loss: 0.0564168617
Epoch:   800  |  train loss: 0.0564168632
Epoch:   900  |  train loss: 0.0564168617
Epoch:  1000  |  train loss: 0.0564168617
Epoch:  1100  |  train loss: 0.0564168632
Epoch:  1200  |  train loss: 0.0564168625
Epoch:  1300  |  train loss: 0.0564168632
Epoch:  1400  |  train loss: 0.0564168625
Epoch:  1500  |  train loss: 0.0564168625
Epoch:  1600  |  train loss: 0.0564168625
Epoch:  1700  |  train loss: 0.0564168639
Epoch:  1800  |  train loss: 0.0564168617
Epoch:  1900  |  train loss: 0.0564168610
Epoch:  2000  |  train loss: 0.0564168625
Processing class: 63
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 64
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0541997507
Epoch:   200  |  train loss: 0.0541997522
Epoch:   300  |  train loss: 0.0541997515
Epoch:   400  |  train loss: 0.0541997500
Epoch:   500  |  train loss: 0.0541997522
Epoch:   600  |  train loss: 0.0541997522
Epoch:   700  |  train loss: 0.0541997507
Epoch:   800  |  train loss: 0.0541997492
Epoch:   900  |  train loss: 0.0541997522
Epoch:  1000  |  train loss: 0.0541997522
Epoch:  1100  |  train loss: 0.0541997507
Epoch:  1200  |  train loss: 0.0541997515
Epoch:  1300  |  train loss: 0.0541997530
Epoch:  1400  |  train loss: 0.0541997522
Epoch:  1500  |  train loss: 0.0541997530
Epoch:  1600  |  train loss: 0.0541997500
Epoch:  1700  |  train loss: 0.0541997500
Epoch:  1800  |  train loss: 0.0541997507
Epoch:  1900  |  train loss: 0.0541997500
Epoch:  2000  |  train loss: 0.0541997485
Processing class: 65
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557441510
Epoch:   200  |  train loss: 0.0557441533
Epoch:   300  |  train loss: 0.0557441518
Epoch:   400  |  train loss: 0.0557441518
Epoch:   500  |  train loss: 0.0557441495
Epoch:   600  |  train loss: 0.0557441518
Epoch:   700  |  train loss: 0.0557441518
Epoch:   800  |  train loss: 0.0557441503
Epoch:   900  |  train loss: 0.0557441510
Epoch:  1000  |  train loss: 0.0557441525
Epoch:  1100  |  train loss: 0.0557441518
Epoch:  1200  |  train loss: 0.0557441518
Epoch:  1300  |  train loss: 0.0557441480
Epoch:  1400  |  train loss: 0.0557441503
Epoch:  1500  |  train loss: 0.0557441540
Epoch:  1600  |  train loss: 0.0557441533
Epoch:  1700  |  train loss: 0.0557441525
Epoch:  1800  |  train loss: 0.0557441495
Epoch:  1900  |  train loss: 0.0557441503
Epoch:  2000  |  train loss: 0.0557441510
Processing class: 66
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565743521
Epoch:   200  |  train loss: 0.0565743499
Epoch:   300  |  train loss: 0.0565743491
Epoch:   400  |  train loss: 0.0565743491
Epoch:   500  |  train loss: 0.0565743513
Epoch:   600  |  train loss: 0.0565743491
Epoch:   700  |  train loss: 0.0565743491
Epoch:   800  |  train loss: 0.0565743499
Epoch:   900  |  train loss: 0.0565743499
Epoch:  1000  |  train loss: 0.0565743506
Epoch:  1100  |  train loss: 0.0565743499
Epoch:  1200  |  train loss: 0.0565743476
Epoch:  1300  |  train loss: 0.0565743499
Epoch:  1400  |  train loss: 0.0565743499
Epoch:  1500  |  train loss: 0.0565743469
Epoch:  1600  |  train loss: 0.0565743484
Epoch:  1700  |  train loss: 0.0565743499
Epoch:  1800  |  train loss: 0.0565743484
Epoch:  1900  |  train loss: 0.0565743491
Epoch:  2000  |  train loss: 0.0565743499
Processing class: 67
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0548169255
Epoch:   200  |  train loss: 0.0548169248
Epoch:   300  |  train loss: 0.0548169270
Epoch:   400  |  train loss: 0.0548169263
Epoch:   500  |  train loss: 0.0548169255
Epoch:   600  |  train loss: 0.0548169240
Epoch:   700  |  train loss: 0.0548169270
Epoch:   800  |  train loss: 0.0548169240
Epoch:   900  |  train loss: 0.0548169270
Epoch:  1000  |  train loss: 0.0548169255
Epoch:  1100  |  train loss: 0.0548169240
Epoch:  1200  |  train loss: 0.0548169240
Epoch:  1300  |  train loss: 0.0548169255
Epoch:  1400  |  train loss: 0.0548169255
Epoch:  1500  |  train loss: 0.0548169263
Epoch:  1600  |  train loss: 0.0548169255
Epoch:  1700  |  train loss: 0.0548169233
Epoch:  1800  |  train loss: 0.0548169255
Epoch:  1900  |  train loss: 0.0548169285
Epoch:  2000  |  train loss: 0.0548169263
Processing class: 68
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0551902689
Epoch:   200  |  train loss: 0.0551902652
Epoch:   300  |  train loss: 0.0551902667
Epoch:   400  |  train loss: 0.0551902667
Epoch:   500  |  train loss: 0.0551902689
Epoch:   600  |  train loss: 0.0551902637
Epoch:   700  |  train loss: 0.0551902659
Epoch:   800  |  train loss: 0.0551902659
Epoch:   900  |  train loss: 0.0551902689
Epoch:  1000  |  train loss: 0.0551902652
Epoch:  1100  |  train loss: 0.0551902667
Epoch:  1200  |  train loss: 0.0551902667
Epoch:  1300  |  train loss: 0.0551902667
Epoch:  1400  |  train loss: 0.0551902674
Epoch:  1500  |  train loss: 0.0551902652
Epoch:  1600  |  train loss: 0.0551902659
Epoch:  1700  |  train loss: 0.0551902667
Epoch:  1800  |  train loss: 0.0551902674
Epoch:  1900  |  train loss: 0.0551902682
Epoch:  2000  |  train loss: 0.0551902652
Processing class: 69
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565856308
Epoch:   200  |  train loss: 0.0565856278
Epoch:   300  |  train loss: 0.0565856248
Epoch:   400  |  train loss: 0.0565856278
Epoch:   500  |  train loss: 0.0565856270
Epoch:   600  |  train loss: 0.0565856248
Epoch:   700  |  train loss: 0.0565856293
Epoch:   800  |  train loss: 0.0565856256
Epoch:   900  |  train loss: 0.0565856263
Epoch:  1000  |  train loss: 0.0565856270
Epoch:  1100  |  train loss: 0.0565856270
Epoch:  1200  |  train loss: 0.0565856278
Epoch:  1300  |  train loss: 0.0565856256
Epoch:  1400  |  train loss: 0.0565856256
Epoch:  1500  |  train loss: 0.0565856270
Epoch:  1600  |  train loss: 0.0565856256
Epoch:  1700  |  train loss: 0.0565856248
Epoch:  1800  |  train loss: 0.0565856248
Epoch:  1900  |  train loss: 0.0565856278
Epoch:  2000  |  train loss: 0.0565856263
Clasifying using reconstruction function cost
2024-04-01 02:37:00,280 [trainer.py] => CNN: {'total': 64.66, '00-09': 75.0, '10-19': 70.1, '20-29': 77.1, '30-39': 70.6, '40-49': 64.0, '50-59': 45.8, '60-69': 50.0, 'old': 67.1, 'new': 50.0}
2024-04-01 02:37:00,281 [trainer.py] => No NME accuracy
2024-04-01 02:37:00,281 [trainer.py] => FeCAM: {'total': 47.46, '00-09': 68.2, '10-19': 55.0, '20-29': 65.9, '30-39': 55.7, '40-49': 58.0, '50-59': 12.1, '60-69': 17.3, 'old': 52.48, 'new': 17.3}
2024-04-01 02:37:00,281 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66]
2024-04-01 02:37:00,281 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54]
2024-04-01 02:37:00,281 [trainer.py] => FeCAM top1 curve: [70.96, 58.87, 47.46]
2024-04-01 02:37:00,281 [trainer.py] => FeCAM top5 curve: [86.38, 79.28, 72.51]

2024-04-01 02:37:00,285 [fecam.py] => Learning on 70-80
Processing class: 70
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0534395732
Epoch:   200  |  train loss: 0.0534395717
Epoch:   300  |  train loss: 0.0534395717
Epoch:   400  |  train loss: 0.0534395717
Epoch:   500  |  train loss: 0.0534395710
Epoch:   600  |  train loss: 0.0534395717
Epoch:   700  |  train loss: 0.0534395732
Epoch:   800  |  train loss: 0.0534395717
Epoch:   900  |  train loss: 0.0534395710
Epoch:  1000  |  train loss: 0.0534395710
Epoch:  1100  |  train loss: 0.0534395717
Epoch:  1200  |  train loss: 0.0534395710
Epoch:  1300  |  train loss: 0.0534395739
Epoch:  1400  |  train loss: 0.0534395725
Epoch:  1500  |  train loss: 0.0534395732
Epoch:  1600  |  train loss: 0.0534395754
Epoch:  1700  |  train loss: 0.0534395717
Epoch:  1800  |  train loss: 0.0534395717
Epoch:  1900  |  train loss: 0.0534395710
Epoch:  2000  |  train loss: 0.0534395747
Processing class: 71
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564124234
Epoch:   200  |  train loss: 0.0564124249
Epoch:   300  |  train loss: 0.0564124212
Epoch:   400  |  train loss: 0.0564124241
Epoch:   500  |  train loss: 0.0564124212
Epoch:   600  |  train loss: 0.0564124212
Epoch:   700  |  train loss: 0.0564124204
Epoch:   800  |  train loss: 0.0564124234
Epoch:   900  |  train loss: 0.0564124212
Epoch:  1000  |  train loss: 0.0564124189
Epoch:  1100  |  train loss: 0.0564124227
Epoch:  1200  |  train loss: 0.0564124212
Epoch:  1300  |  train loss: 0.0564124227
Epoch:  1400  |  train loss: 0.0564124212
Epoch:  1500  |  train loss: 0.0564124212
Epoch:  1600  |  train loss: 0.0564124219
Epoch:  1700  |  train loss: 0.0564124241
Epoch:  1800  |  train loss: 0.0564124219
Epoch:  1900  |  train loss: 0.0564124204
Epoch:  2000  |  train loss: 0.0564124204
Processing class: 72
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0556758672
Epoch:   200  |  train loss: 0.0556758679
Epoch:   300  |  train loss: 0.0556758665
Epoch:   400  |  train loss: 0.0556758672
Epoch:   500  |  train loss: 0.0556758635
Epoch:   600  |  train loss: 0.0556758694
Epoch:   700  |  train loss: 0.0556758679
Epoch:   800  |  train loss: 0.0556758657
Epoch:   900  |  train loss: 0.0556758672
Epoch:  1000  |  train loss: 0.0556758665
Epoch:  1100  |  train loss: 0.0556758665
Epoch:  1200  |  train loss: 0.0556758702
Epoch:  1300  |  train loss: 0.0556758657
Epoch:  1400  |  train loss: 0.0556758642
Epoch:  1500  |  train loss: 0.0556758657
Epoch:  1600  |  train loss: 0.0556758679
Epoch:  1700  |  train loss: 0.0556758672
Epoch:  1800  |  train loss: 0.0556758642
Epoch:  1900  |  train loss: 0.0556758650
Epoch:  2000  |  train loss: 0.0556758679
Processing class: 73
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0563481025
Epoch:   200  |  train loss: 0.0563481033
Epoch:   300  |  train loss: 0.0563481033
Epoch:   400  |  train loss: 0.0563481040
Epoch:   500  |  train loss: 0.0563481040
Epoch:   600  |  train loss: 0.0563481040
Epoch:   700  |  train loss: 0.0563481048
Epoch:   800  |  train loss: 0.0563481048
Epoch:   900  |  train loss: 0.0563481018
Epoch:  1000  |  train loss: 0.0563481040
Epoch:  1100  |  train loss: 0.0563481018
Epoch:  1200  |  train loss: 0.0563481063
Epoch:  1300  |  train loss: 0.0563481025
Epoch:  1400  |  train loss: 0.0563481010
Epoch:  1500  |  train loss: 0.0563481003
Epoch:  1600  |  train loss: 0.0563481048
Epoch:  1700  |  train loss: 0.0563481040
Epoch:  1800  |  train loss: 0.0563481040
Epoch:  1900  |  train loss: 0.0563481025
Epoch:  2000  |  train loss: 0.0563481025
Processing class: 74
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557510205
Epoch:   200  |  train loss: 0.0557510220
Epoch:   300  |  train loss: 0.0557510234
Epoch:   400  |  train loss: 0.0557510227
Epoch:   500  |  train loss: 0.0557510212
Epoch:   600  |  train loss: 0.0557510205
Epoch:   700  |  train loss: 0.0557510220
Epoch:   800  |  train loss: 0.0557510205
Epoch:   900  |  train loss: 0.0557510249
Epoch:  1000  |  train loss: 0.0557510220
Epoch:  1100  |  train loss: 0.0557510234
Epoch:  1200  |  train loss: 0.0557510227
Epoch:  1300  |  train loss: 0.0557510242
Epoch:  1400  |  train loss: 0.0557510242
Epoch:  1500  |  train loss: 0.0557510227
Epoch:  1600  |  train loss: 0.0557510182
Epoch:  1700  |  train loss: 0.0557510220
Epoch:  1800  |  train loss: 0.0557510220
Epoch:  1900  |  train loss: 0.0557510190
Epoch:  2000  |  train loss: 0.0557510227
Processing class: 75
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 76
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0561957888
Epoch:   200  |  train loss: 0.0561957873
Epoch:   300  |  train loss: 0.0561957866
Epoch:   400  |  train loss: 0.0561957903
Epoch:   500  |  train loss: 0.0561957896
Epoch:   600  |  train loss: 0.0561957881
Epoch:   700  |  train loss: 0.0561957888
Epoch:   800  |  train loss: 0.0561957896
Epoch:   900  |  train loss: 0.0561957888
Epoch:  1000  |  train loss: 0.0561957888
Epoch:  1100  |  train loss: 0.0561957896
Epoch:  1200  |  train loss: 0.0561957881
Epoch:  1300  |  train loss: 0.0561957903
Epoch:  1400  |  train loss: 0.0561957896
Epoch:  1500  |  train loss: 0.0561957896
Epoch:  1600  |  train loss: 0.0561957881
Epoch:  1700  |  train loss: 0.0561957873
Epoch:  1800  |  train loss: 0.0561957896
Epoch:  1900  |  train loss: 0.0561957896
Epoch:  2000  |  train loss: 0.0561957896
Processing class: 77
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 78
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0558756821
Epoch:   200  |  train loss: 0.0558756799
Epoch:   300  |  train loss: 0.0558756791
Epoch:   400  |  train loss: 0.0558756813
Epoch:   500  |  train loss: 0.0558756784
Epoch:   600  |  train loss: 0.0558756821
Epoch:   700  |  train loss: 0.0558756784
Epoch:   800  |  train loss: 0.0558756821
Epoch:   900  |  train loss: 0.0558756806
Epoch:  1000  |  train loss: 0.0558756799
Epoch:  1100  |  train loss: 0.0558756828
Epoch:  1200  |  train loss: 0.0558756806
Epoch:  1300  |  train loss: 0.0558756806
Epoch:  1400  |  train loss: 0.0558756821
Epoch:  1500  |  train loss: 0.0558756828
Epoch:  1600  |  train loss: 0.0558756784
Epoch:  1700  |  train loss: 0.0558756791
Epoch:  1800  |  train loss: 0.0558756828
Epoch:  1900  |  train loss: 0.0558756813
Epoch:  2000  |  train loss: 0.0558756791
Processing class: 79
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0560637213
Epoch:   200  |  train loss: 0.0560637213
Epoch:   300  |  train loss: 0.0560637198
Epoch:   400  |  train loss: 0.0560637198
Epoch:   500  |  train loss: 0.0560637213
Epoch:   600  |  train loss: 0.0560637206
Epoch:   700  |  train loss: 0.0560637243
Epoch:   800  |  train loss: 0.0560637213
Epoch:   900  |  train loss: 0.0560637228
Epoch:  1000  |  train loss: 0.0560637213
Epoch:  1100  |  train loss: 0.0560637198
Epoch:  1200  |  train loss: 0.0560637228
Epoch:  1300  |  train loss: 0.0560637236
Epoch:  1400  |  train loss: 0.0560637191
Epoch:  1500  |  train loss: 0.0560637213
Epoch:  1600  |  train loss: 0.0560637228
Epoch:  1700  |  train loss: 0.0560637206
Epoch:  1800  |  train loss: 0.0560637228
Epoch:  1900  |  train loss: 0.0560637221
Epoch:  2000  |  train loss: 0.0560637236
Clasifying using reconstruction function cost
2024-04-01 03:38:07,229 [trainer.py] => CNN: {'total': 59.18, '00-09': 73.6, '10-19': 68.4, '20-29': 76.9, '30-39': 69.1, '40-49': 60.6, '50-59': 37.2, '60-69': 45.7, '70-79': 41.9, 'old': 61.64, 'new': 41.9}
2024-04-01 03:38:07,230 [trainer.py] => No NME accuracy
2024-04-01 03:38:07,230 [trainer.py] => FeCAM: {'total': 40.29, '00-09': 65.5, '10-19': 53.2, '20-29': 62.9, '30-39': 52.7, '40-49': 55.4, '50-59': 9.9, '60-69': 14.1, '70-79': 8.6, 'old': 44.81, 'new': 8.6}
2024-04-01 03:38:07,230 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18]
2024-04-01 03:38:07,230 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09]
2024-04-01 03:38:07,230 [trainer.py] => FeCAM top1 curve: [70.96, 58.87, 47.46, 40.29]
2024-04-01 03:38:07,230 [trainer.py] => FeCAM top5 curve: [86.38, 79.28, 72.51, 66.66]

2024-04-01 03:38:07,235 [fecam.py] => Learning on 80-90
Processing class: 80
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0550746746
Epoch:   200  |  train loss: 0.0550746754
Epoch:   300  |  train loss: 0.0550746746
Epoch:   400  |  train loss: 0.0550746746
Epoch:   500  |  train loss: 0.0550746754
Epoch:   600  |  train loss: 0.0550746776
Epoch:   700  |  train loss: 0.0550746739
Epoch:   800  |  train loss: 0.0550746776
Epoch:   900  |  train loss: 0.0550746776
Epoch:  1000  |  train loss: 0.0550746761
Epoch:  1100  |  train loss: 0.0550746754
Epoch:  1200  |  train loss: 0.0550746776
Epoch:  1300  |  train loss: 0.0550746746
Epoch:  1400  |  train loss: 0.0550746739
Epoch:  1500  |  train loss: 0.0550746776
Epoch:  1600  |  train loss: 0.0550746769
Epoch:  1700  |  train loss: 0.0550746754
Epoch:  1800  |  train loss: 0.0550746761
Epoch:  1900  |  train loss: 0.0550746776
Epoch:  2000  |  train loss: 0.0550746754
Processing class: 81
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0560282014
Epoch:   200  |  train loss: 0.0560281985
Epoch:   300  |  train loss: 0.0560282007
Epoch:   400  |  train loss: 0.0560281962
Epoch:   500  |  train loss: 0.0560282014
Epoch:   600  |  train loss: 0.0560282022
Epoch:   700  |  train loss: 0.0560281977
Epoch:   800  |  train loss: 0.0560282014
Epoch:   900  |  train loss: 0.0560281992
Epoch:  1000  |  train loss: 0.0560281977
Epoch:  1100  |  train loss: 0.0560281970
Epoch:  1200  |  train loss: 0.0560282029
Epoch:  1300  |  train loss: 0.0560281977
Epoch:  1400  |  train loss: 0.0560281992
Epoch:  1500  |  train loss: 0.0560281992
Epoch:  1600  |  train loss: 0.0560281999
Epoch:  1700  |  train loss: 0.0560282007
Epoch:  1800  |  train loss: 0.0560281962
Epoch:  1900  |  train loss: 0.0560281985
Epoch:  2000  |  train loss: 0.0560282007
Processing class: 82
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557662040
Epoch:   200  |  train loss: 0.0557662040
Epoch:   300  |  train loss: 0.0557662018
Epoch:   400  |  train loss: 0.0557662047
Epoch:   500  |  train loss: 0.0557662033
Epoch:   600  |  train loss: 0.0557662033
Epoch:   700  |  train loss: 0.0557662055
Epoch:   800  |  train loss: 0.0557662070
Epoch:   900  |  train loss: 0.0557662025
Epoch:  1000  |  train loss: 0.0557662033
Epoch:  1100  |  train loss: 0.0557662047
Epoch:  1200  |  train loss: 0.0557662033
Epoch:  1300  |  train loss: 0.0557662047
Epoch:  1400  |  train loss: 0.0557662040
Epoch:  1500  |  train loss: 0.0557662062
Epoch:  1600  |  train loss: 0.0557662025
Epoch:  1700  |  train loss: 0.0557662047
Epoch:  1800  |  train loss: 0.0557662047
Epoch:  1900  |  train loss: 0.0557662018
Epoch:  2000  |  train loss: 0.0557662033
Processing class: 83
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0561493188
Epoch:   200  |  train loss: 0.0561493225
Epoch:   300  |  train loss: 0.0561493225
Epoch:   400  |  train loss: 0.0561493233
Epoch:   500  |  train loss: 0.0561493225
Epoch:   600  |  train loss: 0.0561493225
Epoch:   700  |  train loss: 0.0561493233
Epoch:   800  |  train loss: 0.0561493210
Epoch:   900  |  train loss: 0.0561493240
Epoch:  1000  |  train loss: 0.0561493210
Epoch:  1100  |  train loss: 0.0561493225
Epoch:  1200  |  train loss: 0.0561493210
Epoch:  1300  |  train loss: 0.0561493218
Epoch:  1400  |  train loss: 0.0561493203
Epoch:  1500  |  train loss: 0.0561493233
Epoch:  1600  |  train loss: 0.0561493203
Epoch:  1700  |  train loss: 0.0561493210
Epoch:  1800  |  train loss: 0.0561493210
Epoch:  1900  |  train loss: 0.0561493210
Epoch:  2000  |  train loss: 0.0561493203
Processing class: 84
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0562116235
Epoch:   200  |  train loss: 0.0562116243
Epoch:   300  |  train loss: 0.0562116235
Epoch:   400  |  train loss: 0.0562116235
Epoch:   500  |  train loss: 0.0562116235
Epoch:   600  |  train loss: 0.0562116250
Epoch:   700  |  train loss: 0.0562116221
Epoch:   800  |  train loss: 0.0562116235
Epoch:   900  |  train loss: 0.0562116243
Epoch:  1000  |  train loss: 0.0562116221
Epoch:  1100  |  train loss: 0.0562116221
Epoch:  1200  |  train loss: 0.0562116228
Epoch:  1300  |  train loss: 0.0562116228
Epoch:  1400  |  train loss: 0.0562116206
Epoch:  1500  |  train loss: 0.0562116258
Epoch:  1600  |  train loss: 0.0562116235
Epoch:  1700  |  train loss: 0.0562116228
Epoch:  1800  |  train loss: 0.0562116213
Epoch:  1900  |  train loss: 0.0562116228
Epoch:  2000  |  train loss: 0.0562116213
Processing class: 85
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0542483538
Epoch:   200  |  train loss: 0.0542483576
Epoch:   300  |  train loss: 0.0542483576
Epoch:   400  |  train loss: 0.0542483561
Epoch:   500  |  train loss: 0.0542483568
Epoch:   600  |  train loss: 0.0542483576
Epoch:   700  |  train loss: 0.0542483553
Epoch:   800  |  train loss: 0.0542483561
Epoch:   900  |  train loss: 0.0542483576
Epoch:  1000  |  train loss: 0.0542483553
Epoch:  1100  |  train loss: 0.0542483531
Epoch:  1200  |  train loss: 0.0542483553
Epoch:  1300  |  train loss: 0.0542483568
Epoch:  1400  |  train loss: 0.0542483538
Epoch:  1500  |  train loss: 0.0542483546
Epoch:  1600  |  train loss: 0.0542483576
Epoch:  1700  |  train loss: 0.0542483583
Epoch:  1800  |  train loss: 0.0542483561
Epoch:  1900  |  train loss: 0.0542483568
Epoch:  2000  |  train loss: 0.0542483561
Processing class: 86
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564357519
Epoch:   200  |  train loss: 0.0564357519
Epoch:   300  |  train loss: 0.0564357519
Epoch:   400  |  train loss: 0.0564357542
Epoch:   500  |  train loss: 0.0564357519
Epoch:   600  |  train loss: 0.0564357542
Epoch:   700  |  train loss: 0.0564357512
Epoch:   800  |  train loss: 0.0564357489
Epoch:   900  |  train loss: 0.0564357534
Epoch:  1000  |  train loss: 0.0564357549
Epoch:  1100  |  train loss: 0.0564357527
Epoch:  1200  |  train loss: 0.0564357519
Epoch:  1300  |  train loss: 0.0564357519
Epoch:  1400  |  train loss: 0.0564357534
Epoch:  1500  |  train loss: 0.0564357542
Epoch:  1600  |  train loss: 0.0564357534
Epoch:  1700  |  train loss: 0.0564357519
Epoch:  1800  |  train loss: 0.0564357519
Epoch:  1900  |  train loss: 0.0564357527
Epoch:  2000  |  train loss: 0.0564357497
Processing class: 87
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0564955607
Epoch:   200  |  train loss: 0.0564955600
Epoch:   300  |  train loss: 0.0564955600
Epoch:   400  |  train loss: 0.0564955600
Epoch:   500  |  train loss: 0.0564955644
Epoch:   600  |  train loss: 0.0564955629
Epoch:   700  |  train loss: 0.0564955615
Epoch:   800  |  train loss: 0.0564955637
Epoch:   900  |  train loss: 0.0564955622
Epoch:  1000  |  train loss: 0.0564955607
Epoch:  1100  |  train loss: 0.0564955622
Epoch:  1200  |  train loss: 0.0564955622
Epoch:  1300  |  train loss: 0.0564955622
Epoch:  1400  |  train loss: 0.0564955629
Epoch:  1500  |  train loss: 0.0564955622
Epoch:  1600  |  train loss: 0.0564955577
Epoch:  1700  |  train loss: 0.0564955629
Epoch:  1800  |  train loss: 0.0564955615
Epoch:  1900  |  train loss: 0.0564955600
Epoch:  2000  |  train loss: 0.0564955629
Processing class: 88
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0558578640
Epoch:   200  |  train loss: 0.0558578640
Epoch:   300  |  train loss: 0.0558578618
Epoch:   400  |  train loss: 0.0558578640
Epoch:   500  |  train loss: 0.0558578603
Epoch:   600  |  train loss: 0.0558578648
Epoch:   700  |  train loss: 0.0558578618
Epoch:   800  |  train loss: 0.0558578655
Epoch:   900  |  train loss: 0.0558578640
Epoch:  1000  |  train loss: 0.0558578648
Epoch:  1100  |  train loss: 0.0558578648
Epoch:  1200  |  train loss: 0.0558578663
Epoch:  1300  |  train loss: 0.0558578648
Epoch:  1400  |  train loss: 0.0558578663
Epoch:  1500  |  train loss: 0.0558578663
Epoch:  1600  |  train loss: 0.0558578655
Epoch:  1700  |  train loss: 0.0558578640
Epoch:  1800  |  train loss: 0.0558578655
Epoch:  1900  |  train loss: 0.0558578648
Epoch:  2000  |  train loss: 0.0558578663
Processing class: 89
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0565715663
Epoch:   200  |  train loss: 0.0565715671
Epoch:   300  |  train loss: 0.0565715656
Epoch:   400  |  train loss: 0.0565715648
Epoch:   500  |  train loss: 0.0565715656
Epoch:   600  |  train loss: 0.0565715671
Epoch:   700  |  train loss: 0.0565715671
Epoch:   800  |  train loss: 0.0565715671
Epoch:   900  |  train loss: 0.0565715700
Epoch:  1000  |  train loss: 0.0565715656
Epoch:  1100  |  train loss: 0.0565715678
Epoch:  1200  |  train loss: 0.0565715685
Epoch:  1300  |  train loss: 0.0565715663
Epoch:  1400  |  train loss: 0.0565715648
Epoch:  1500  |  train loss: 0.0565715656
Epoch:  1600  |  train loss: 0.0565715678
Epoch:  1700  |  train loss: 0.0565715656
Epoch:  1800  |  train loss: 0.0565715671
Epoch:  1900  |  train loss: 0.0565715648
Epoch:  2000  |  train loss: 0.0565715663
Clasifying using reconstruction function cost
2024-04-01 04:41:33,987 [trainer.py] => CNN: {'total': 54.08, '00-09': 67.9, '10-19': 63.6, '20-29': 73.2, '30-39': 68.8, '40-49': 57.2, '50-59': 32.6, '60-69': 40.9, '70-79': 38.1, '80-89': 44.4, 'old': 55.29, 'new': 44.4}
2024-04-01 04:41:34,030 [trainer.py] => No NME accuracy
2024-04-01 04:41:34,030 [trainer.py] => FeCAM: {'total': 36.14, '00-09': 64.8, '10-19': 51.2, '20-29': 61.8, '30-39': 52.6, '40-49': 54.5, '50-59': 9.5, '60-69': 13.1, '70-79': 8.3, '80-89': 9.5, 'old': 39.48, 'new': 9.5}
2024-04-01 04:41:34,030 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08]
2024-04-01 04:41:34,030 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74]
2024-04-01 04:41:34,030 [trainer.py] => FeCAM top1 curve: [70.96, 58.87, 47.46, 40.29, 36.14]
2024-04-01 04:41:34,030 [trainer.py] => FeCAM top5 curve: [86.38, 79.28, 72.51, 66.66, 62.81]

2024-04-01 04:41:34,034 [fecam.py] => Learning on 90-100
Processing class: 90
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0553758919
Epoch:   200  |  train loss: 0.0553758927
Epoch:   300  |  train loss: 0.0553758927
Epoch:   400  |  train loss: 0.0553758927
Epoch:   500  |  train loss: 0.0553758912
Epoch:   600  |  train loss: 0.0553758949
Epoch:   700  |  train loss: 0.0553758919
Epoch:   800  |  train loss: 0.0553758919
Epoch:   900  |  train loss: 0.0553758919
Epoch:  1000  |  train loss: 0.0553758919
Epoch:  1100  |  train loss: 0.0553758904
Epoch:  1200  |  train loss: 0.0553758949
Epoch:  1300  |  train loss: 0.0553758927
Epoch:  1400  |  train loss: 0.0553758927
Epoch:  1500  |  train loss: 0.0553758934
Epoch:  1600  |  train loss: 0.0553758942
Epoch:  1700  |  train loss: 0.0553758934
Epoch:  1800  |  train loss: 0.0553758927
Epoch:  1900  |  train loss: 0.0553758927
Epoch:  2000  |  train loss: 0.0553758934
Processing class: 91
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0566566601
Epoch:   200  |  train loss: 0.0566566564
Epoch:   300  |  train loss: 0.0566566572
Epoch:   400  |  train loss: 0.0566566579
Epoch:   500  |  train loss: 0.0566566564
Epoch:   600  |  train loss: 0.0566566609
Epoch:   700  |  train loss: 0.0566566579
Epoch:   800  |  train loss: 0.0566566557
Epoch:   900  |  train loss: 0.0566566594
Epoch:  1000  |  train loss: 0.0566566579
Epoch:  1100  |  train loss: 0.0566566564
Epoch:  1200  |  train loss: 0.0566566564
Epoch:  1300  |  train loss: 0.0566566579
Epoch:  1400  |  train loss: 0.0566566579
Epoch:  1500  |  train loss: 0.0566566594
Epoch:  1600  |  train loss: 0.0566566579
Epoch:  1700  |  train loss: 0.0566566601
Epoch:  1800  |  train loss: 0.0566566572
Epoch:  1900  |  train loss: 0.0566566579
Epoch:  2000  |  train loss: 0.0566566586
Processing class: 92
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0557389393
Epoch:   200  |  train loss: 0.0557389393
Epoch:   300  |  train loss: 0.0557389408
Epoch:   400  |  train loss: 0.0557389408
Epoch:   500  |  train loss: 0.0557389393
Epoch:   600  |  train loss: 0.0557389393
Epoch:   700  |  train loss: 0.0557389386
Epoch:   800  |  train loss: 0.0557389408
Epoch:   900  |  train loss: 0.0557389379
Epoch:  1000  |  train loss: 0.0557389364
Epoch:  1100  |  train loss: 0.0557389408
Epoch:  1200  |  train loss: 0.0557389393
Epoch:  1300  |  train loss: 0.0557389393
Epoch:  1400  |  train loss: 0.0557389379
Epoch:  1500  |  train loss: 0.0557389386
Epoch:  1600  |  train loss: 0.0557389364
Epoch:  1700  |  train loss: 0.0557389393
Epoch:  1800  |  train loss: 0.0557389379
Epoch:  1900  |  train loss: 0.0557389386
Epoch:  2000  |  train loss: 0.0557389401
Processing class: 93
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0563699268
Epoch:   200  |  train loss: 0.0563699290
Epoch:   300  |  train loss: 0.0563699290
Epoch:   400  |  train loss: 0.0563699283
Epoch:   500  |  train loss: 0.0563699283
Epoch:   600  |  train loss: 0.0563699290
Epoch:   700  |  train loss: 0.0563699245
Epoch:   800  |  train loss: 0.0563699268
Epoch:   900  |  train loss: 0.0563699268
Epoch:  1000  |  train loss: 0.0563699268
Epoch:  1100  |  train loss: 0.0563699283
Epoch:  1200  |  train loss: 0.0563699275
Epoch:  1300  |  train loss: 0.0563699290
Epoch:  1400  |  train loss: 0.0563699268
Epoch:  1500  |  train loss: 0.0563699268
Epoch:  1600  |  train loss: 0.0563699275
Epoch:  1700  |  train loss: 0.0563699283
Epoch:  1800  |  train loss: 0.0563699275
Epoch:  1900  |  train loss: 0.0563699268
Epoch:  2000  |  train loss: 0.0563699275
Processing class: 94
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0545140587
Epoch:   200  |  train loss: 0.0545140602
Epoch:   300  |  train loss: 0.0545140602
Epoch:   400  |  train loss: 0.0545140609
Epoch:   500  |  train loss: 0.0545140594
Epoch:   600  |  train loss: 0.0545140609
Epoch:   700  |  train loss: 0.0545140617
Epoch:   800  |  train loss: 0.0545140594
Epoch:   900  |  train loss: 0.0545140602
Epoch:  1000  |  train loss: 0.0545140594
Epoch:  1100  |  train loss: 0.0545140579
Epoch:  1200  |  train loss: 0.0545140609
Epoch:  1300  |  train loss: 0.0545140609
Epoch:  1400  |  train loss: 0.0545140602
Epoch:  1500  |  train loss: 0.0545140609
Epoch:  1600  |  train loss: 0.0545140602
Epoch:  1700  |  train loss: 0.0545140624
Epoch:  1800  |  train loss: 0.0545140602
Epoch:  1900  |  train loss: 0.0545140617
Epoch:  2000  |  train loss: 0.0545140602
Processing class: 95
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0559436925
Epoch:   200  |  train loss: 0.0559436917
Epoch:   300  |  train loss: 0.0559436932
Epoch:   400  |  train loss: 0.0559436902
Epoch:   500  |  train loss: 0.0559436902
Epoch:   600  |  train loss: 0.0559436925
Epoch:   700  |  train loss: 0.0559436895
Epoch:   800  |  train loss: 0.0559436940
Epoch:   900  |  train loss: 0.0559436917
Epoch:  1000  |  train loss: 0.0559436902
Epoch:  1100  |  train loss: 0.0559436932
Epoch:  1200  |  train loss: 0.0559436940
Epoch:  1300  |  train loss: 0.0559436917
Epoch:  1400  |  train loss: 0.0559436895
Epoch:  1500  |  train loss: 0.0559436917
Epoch:  1600  |  train loss: 0.0559436910
Epoch:  1700  |  train loss: 0.0559436940
Epoch:  1800  |  train loss: 0.0559436917
Epoch:  1900  |  train loss: 0.0559436940
Epoch:  2000  |  train loss: 0.0559436925
Processing class: 96
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0559112363
Epoch:   200  |  train loss: 0.0559112325
Epoch:   300  |  train loss: 0.0559112296
Epoch:   400  |  train loss: 0.0559112340
Epoch:   500  |  train loss: 0.0559112348
Epoch:   600  |  train loss: 0.0559112325
Epoch:   700  |  train loss: 0.0559112325
Epoch:   800  |  train loss: 0.0559112310
Epoch:   900  |  train loss: 0.0559112325
Epoch:  1000  |  train loss: 0.0559112348
Epoch:  1100  |  train loss: 0.0559112310
Epoch:  1200  |  train loss: 0.0559112340
Epoch:  1300  |  train loss: 0.0559112340
Epoch:  1400  |  train loss: 0.0559112348
Epoch:  1500  |  train loss: 0.0559112333
Epoch:  1600  |  train loss: 0.0559112340
Epoch:  1700  |  train loss: 0.0559112325
Epoch:  1800  |  train loss: 0.0559112325
Epoch:  1900  |  train loss: 0.0559112318
Epoch:  2000  |  train loss: 0.0559112333
Processing class: 97
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0538305141
Epoch:   200  |  train loss: 0.0538305156
Epoch:   300  |  train loss: 0.0538305141
Epoch:   400  |  train loss: 0.0538305156
Epoch:   500  |  train loss: 0.0538305148
Epoch:   600  |  train loss: 0.0538305163
Epoch:   700  |  train loss: 0.0538305134
Epoch:   800  |  train loss: 0.0538305186
Epoch:   900  |  train loss: 0.0538305156
Epoch:  1000  |  train loss: 0.0538305171
Epoch:  1100  |  train loss: 0.0538305141
Epoch:  1200  |  train loss: 0.0538305178
Epoch:  1300  |  train loss: 0.0538305148
Epoch:  1400  |  train loss: 0.0538305156
Epoch:  1500  |  train loss: 0.0538305163
Epoch:  1600  |  train loss: 0.0538305171
Epoch:  1700  |  train loss: 0.0538305141
Epoch:  1800  |  train loss: 0.0538305171
Epoch:  1900  |  train loss: 0.0538305156
Epoch:  2000  |  train loss: 0.0538305148
Processing class: 98
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 99
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0558301091
Epoch:   200  |  train loss: 0.0558301099
Epoch:   300  |  train loss: 0.0558301084
Epoch:   400  |  train loss: 0.0558301076
Epoch:   500  |  train loss: 0.0558301106
Epoch:   600  |  train loss: 0.0558301099
Epoch:   700  |  train loss: 0.0558301121
Epoch:   800  |  train loss: 0.0558301106
Epoch:   900  |  train loss: 0.0558301121
Epoch:  1000  |  train loss: 0.0558301114
Epoch:  1100  |  train loss: 0.0558301091
Epoch:  1200  |  train loss: 0.0558301091
Epoch:  1300  |  train loss: 0.0558301106
Epoch:  1400  |  train loss: 0.0558301076
Epoch:  1500  |  train loss: 0.0558301084
Epoch:  1600  |  train loss: 0.0558301076
Epoch:  1700  |  train loss: 0.0558301076
Epoch:  1800  |  train loss: 0.0558301091
Epoch:  1900  |  train loss: 0.0558301091
Epoch:  2000  |  train loss: 0.0558301106
Clasifying using reconstruction function cost
2024-04-01 05:47:33,450 [trainer.py] => CNN: {'total': 50.36, '00-09': 57.7, '10-19': 63.6, '20-29': 71.4, '30-39': 68.5, '40-49': 56.8, '50-59': 29.6, '60-69': 38.9, '70-79': 36.6, '80-89': 42.7, '90-99': 37.8, 'old': 51.76, 'new': 37.8}
2024-04-01 05:47:33,451 [trainer.py] => No NME accuracy
2024-04-01 05:47:33,451 [trainer.py] => FeCAM: {'total': 31.68, '00-09': 62.1, '10-19': 48.6, '20-29': 59.9, '30-39': 50.0, '40-49': 53.3, '50-59': 8.5, '60-69': 11.5, '70-79': 6.9, '80-89': 8.4, '90-99': 7.6, 'old': 34.36, 'new': 7.6}
2024-04-01 05:47:33,451 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08, 50.36]
2024-04-01 05:47:33,451 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74, 79.63]
2024-04-01 05:47:33,451 [trainer.py] => FeCAM top1 curve: [70.96, 58.87, 47.46, 40.29, 36.14, 31.68]
2024-04-01 05:47:33,451 [trainer.py] => FeCAM top5 curve: [86.38, 79.28, 72.51, 66.66, 62.81, 58.68]

=========================================
2024-04-01 05:47:40,612 [trainer.py] => config: ./exps/FeCAM_cifar100.json
2024-04-01 05:47:40,612 [trainer.py] => prefix: train
2024-04-01 05:47:40,612 [trainer.py] => dataset: cifar100
2024-04-01 05:47:40,612 [trainer.py] => memory_size: 0
2024-04-01 05:47:40,612 [trainer.py] => shuffle: True
2024-04-01 05:47:40,612 [trainer.py] => init_cls: 50
2024-04-01 05:47:40,612 [trainer.py] => increment: 10
2024-04-01 05:47:40,612 [trainer.py] => model_name: fecam
2024-04-01 05:47:40,612 [trainer.py] => convnet_type: resnet18
2024-04-01 05:47:40,612 [trainer.py] => device: [device(type='cuda', index=0)]
2024-04-01 05:47:40,612 [trainer.py] => seed: 1993
2024-04-01 05:47:40,612 [trainer.py] => init_epochs: 200
2024-04-01 05:47:40,612 [trainer.py] => init_lr: 0.1
2024-04-01 05:47:40,612 [trainer.py] => init_weight_decay: 0.0005
2024-04-01 05:47:40,612 [trainer.py] => batch_size: 128
2024-04-01 05:47:40,612 [trainer.py] => num_workers: 8
2024-04-01 05:47:40,612 [trainer.py] => T: 5
2024-04-01 05:47:40,612 [trainer.py] => beta: 0.5
2024-04-01 05:47:40,612 [trainer.py] => alpha1: 1
2024-04-01 05:47:40,612 [trainer.py] => alpha2: 1
2024-04-01 05:47:40,612 [trainer.py] => ncm: False
2024-04-01 05:47:40,613 [trainer.py] => tukey: False
2024-04-01 05:47:40,613 [trainer.py] => diagonal: False
2024-04-01 05:47:40,613 [trainer.py] => per_class: True
2024-04-01 05:47:40,613 [trainer.py] => full_cov: True
2024-04-01 05:47:40,613 [trainer.py] => shrink: True
2024-04-01 05:47:40,613 [trainer.py] => norm_cov: False
2024-04-01 05:47:40,613 [trainer.py] => epochs: 2000
2024-04-01 05:47:40,613 [trainer.py] => vecnorm: False
2024-04-01 05:47:40,613 [trainer.py] => ae_type: ae
2024-04-01 05:47:40,613 [trainer.py] => ae_latent_dim: 32
2024-04-01 05:47:40,613 [trainer.py] => ae_n: 1
2024-04-01 05:47:40,613 [trainer.py] => wae_sigma: 10
2024-04-01 05:47:40,613 [trainer.py] => wae_C: 0.1
2024-04-01 05:47:40,613 [trainer.py] => ae_standarization: False
2024-04-01 05:47:40,613 [trainer.py] => ae_pca: False
2024-04-01 05:47:40,613 [trainer.py] => ae_pca_components: 500
2024-04-01 05:47:40,613 [trainer.py] => ae_clsf: maha-recon-cost
2024-04-01 05:47:40,613 [trainer.py] => maha_alpha: 0.01
2024-04-01 05:47:40,613 [trainer.py] => maha_beta: 0.05
Files already downloaded and verified
Files already downloaded and verified
2024-04-01 05:47:42,269 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-04-01 05:47:42,535 [fecam.py] => Learning on 0-50
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Processing class: 0
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0667205110
Epoch:   200  |  train loss: 0.0667205140
Epoch:   300  |  train loss: 0.0667205110
Epoch:   400  |  train loss: 0.0667205140
Epoch:   500  |  train loss: 0.0667205080
Epoch:   600  |  train loss: 0.0667205095
Epoch:   700  |  train loss: 0.0667205110
Epoch:   800  |  train loss: 0.0667205110
Epoch:   900  |  train loss: 0.0667205125
Epoch:  1000  |  train loss: 0.0667205110
Epoch:  1100  |  train loss: 0.0667205095
Epoch:  1200  |  train loss: 0.0667205125
Epoch:  1300  |  train loss: 0.0667205125
Epoch:  1400  |  train loss: 0.0667205095
Epoch:  1500  |  train loss: 0.0667205110
Epoch:  1600  |  train loss: 0.0667205125
Epoch:  1700  |  train loss: 0.0667205125
Epoch:  1800  |  train loss: 0.0667205125
Epoch:  1900  |  train loss: 0.0667205095
Epoch:  2000  |  train loss: 0.0667205125
Processing class: 1
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662085429
Epoch:   200  |  train loss: 0.0662085444
Epoch:   300  |  train loss: 0.0662085399
Epoch:   400  |  train loss: 0.0662085414
Epoch:   500  |  train loss: 0.0662085429
Epoch:   600  |  train loss: 0.0662085399
Epoch:   700  |  train loss: 0.0662085399
Epoch:   800  |  train loss: 0.0662085429
Epoch:   900  |  train loss: 0.0662085429
Epoch:  1000  |  train loss: 0.0662085429
Epoch:  1100  |  train loss: 0.0662085444
Epoch:  1200  |  train loss: 0.0662085429
Epoch:  1300  |  train loss: 0.0662085414
Epoch:  1400  |  train loss: 0.0662085429
Epoch:  1500  |  train loss: 0.0662085414
Epoch:  1600  |  train loss: 0.0662085429
Epoch:  1700  |  train loss: 0.0662085429
Epoch:  1800  |  train loss: 0.0662085429
Epoch:  1900  |  train loss: 0.0662085444
Epoch:  2000  |  train loss: 0.0662085429
Processing class: 2
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0633998446
Epoch:   200  |  train loss: 0.0633998439
Epoch:   300  |  train loss: 0.0633998446
Epoch:   400  |  train loss: 0.0633998454
Epoch:   500  |  train loss: 0.0633998454
Epoch:   600  |  train loss: 0.0633998431
Epoch:   700  |  train loss: 0.0633998439
Epoch:   800  |  train loss: 0.0633998431
Epoch:   900  |  train loss: 0.0633998424
Epoch:  1000  |  train loss: 0.0633998431
Epoch:  1100  |  train loss: 0.0633998439
Epoch:  1200  |  train loss: 0.0633998454
Epoch:  1300  |  train loss: 0.0633998446
Epoch:  1400  |  train loss: 0.0633998439
Epoch:  1500  |  train loss: 0.0633998439
Epoch:  1600  |  train loss: 0.0633998424
Epoch:  1700  |  train loss: 0.0633998454
Epoch:  1800  |  train loss: 0.0633998446
Epoch:  1900  |  train loss: 0.0633998439
Epoch:  2000  |  train loss: 0.0633998454
Processing class: 3
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666494265
Epoch:   200  |  train loss: 0.0666494280
Epoch:   300  |  train loss: 0.0666494265
Epoch:   400  |  train loss: 0.0666494250
Epoch:   500  |  train loss: 0.0666494265
Epoch:   600  |  train loss: 0.0666494280
Epoch:   700  |  train loss: 0.0666494265
Epoch:   800  |  train loss: 0.0666494250
Epoch:   900  |  train loss: 0.0666494250
Epoch:  1000  |  train loss: 0.0666494191
Epoch:  1100  |  train loss: 0.0666494265
Epoch:  1200  |  train loss: 0.0666494235
Epoch:  1300  |  train loss: 0.0666494280
Epoch:  1400  |  train loss: 0.0666494250
Epoch:  1500  |  train loss: 0.0666494250
Epoch:  1600  |  train loss: 0.0666494250
Epoch:  1700  |  train loss: 0.0666494235
Epoch:  1800  |  train loss: 0.0666494265
Epoch:  1900  |  train loss: 0.0666494250
Epoch:  2000  |  train loss: 0.0666494265
Processing class: 4
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0660170585
Epoch:   200  |  train loss: 0.0660170570
Epoch:   300  |  train loss: 0.0660170585
Epoch:   400  |  train loss: 0.0660170570
Epoch:   500  |  train loss: 0.0660170585
Epoch:   600  |  train loss: 0.0660170570
Epoch:   700  |  train loss: 0.0660170570
Epoch:   800  |  train loss: 0.0660170555
Epoch:   900  |  train loss: 0.0660170585
Epoch:  1000  |  train loss: 0.0660170570
Epoch:  1100  |  train loss: 0.0660170570
Epoch:  1200  |  train loss: 0.0660170555
Epoch:  1300  |  train loss: 0.0660170585
Epoch:  1400  |  train loss: 0.0660170585
Epoch:  1500  |  train loss: 0.0660170570
Epoch:  1600  |  train loss: 0.0660170585
Epoch:  1700  |  train loss: 0.0660170600
Epoch:  1800  |  train loss: 0.0660170570
Epoch:  1900  |  train loss: 0.0660170585
Epoch:  2000  |  train loss: 0.0660170585
Processing class: 5
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 6
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0663689613
Epoch:   200  |  train loss: 0.0663689613
Epoch:   300  |  train loss: 0.0663689598
Epoch:   400  |  train loss: 0.0663689628
Epoch:   500  |  train loss: 0.0663689569
Epoch:   600  |  train loss: 0.0663689598
Epoch:   700  |  train loss: 0.0663689598
Epoch:   800  |  train loss: 0.0663689628
Epoch:   900  |  train loss: 0.0663689584
Epoch:  1000  |  train loss: 0.0663689598
Epoch:  1100  |  train loss: 0.0663689613
Epoch:  1200  |  train loss: 0.0663689584
Epoch:  1300  |  train loss: 0.0663689569
Epoch:  1400  |  train loss: 0.0663689598
Epoch:  1500  |  train loss: 0.0663689584
Epoch:  1600  |  train loss: 0.0663689613
Epoch:  1700  |  train loss: 0.0663689628
Epoch:  1800  |  train loss: 0.0663689628
Epoch:  1900  |  train loss: 0.0663689569
Epoch:  2000  |  train loss: 0.0663689584
Processing class: 7
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666428342
Epoch:   200  |  train loss: 0.0666428328
Epoch:   300  |  train loss: 0.0666428328
Epoch:   400  |  train loss: 0.0666428357
Epoch:   500  |  train loss: 0.0666428357
Epoch:   600  |  train loss: 0.0666428342
Epoch:   700  |  train loss: 0.0666428328
Epoch:   800  |  train loss: 0.0666428328
Epoch:   900  |  train loss: 0.0666428298
Epoch:  1000  |  train loss: 0.0666428328
Epoch:  1100  |  train loss: 0.0666428328
Epoch:  1200  |  train loss: 0.0666428342
Epoch:  1300  |  train loss: 0.0666428328
Epoch:  1400  |  train loss: 0.0666428342
Epoch:  1500  |  train loss: 0.0666428342
Epoch:  1600  |  train loss: 0.0666428313
Epoch:  1700  |  train loss: 0.0666428313
Epoch:  1800  |  train loss: 0.0666428372
Epoch:  1900  |  train loss: 0.0666428328
Epoch:  2000  |  train loss: 0.0666428342
Processing class: 8
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0664523393
Epoch:   200  |  train loss: 0.0664523438
Epoch:   300  |  train loss: 0.0664523393
Epoch:   400  |  train loss: 0.0664523438
Epoch:   500  |  train loss: 0.0664523393
Epoch:   600  |  train loss: 0.0664523393
Epoch:   700  |  train loss: 0.0664523393
Epoch:   800  |  train loss: 0.0664523408
Epoch:   900  |  train loss: 0.0664523378
Epoch:  1000  |  train loss: 0.0664523408
Epoch:  1100  |  train loss: 0.0664523423
Epoch:  1200  |  train loss: 0.0664523423
Epoch:  1300  |  train loss: 0.0664523423
Epoch:  1400  |  train loss: 0.0664523423
Epoch:  1500  |  train loss: 0.0664523438
Epoch:  1600  |  train loss: 0.0664523423
Epoch:  1700  |  train loss: 0.0664523408
Epoch:  1800  |  train loss: 0.0664523408
Epoch:  1900  |  train loss: 0.0664523393
Epoch:  2000  |  train loss: 0.0664523423
Processing class: 9
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0643037617
Epoch:   200  |  train loss: 0.0643037610
Epoch:   300  |  train loss: 0.0643037640
Epoch:   400  |  train loss: 0.0643037602
Epoch:   500  |  train loss: 0.0643037632
Epoch:   600  |  train loss: 0.0643037632
Epoch:   700  |  train loss: 0.0643037617
Epoch:   800  |  train loss: 0.0643037625
Epoch:   900  |  train loss: 0.0643037617
Epoch:  1000  |  train loss: 0.0643037647
Epoch:  1100  |  train loss: 0.0643037647
Epoch:  1200  |  train loss: 0.0643037625
Epoch:  1300  |  train loss: 0.0643037632
Epoch:  1400  |  train loss: 0.0643037647
Epoch:  1500  |  train loss: 0.0643037617
Epoch:  1600  |  train loss: 0.0643037632
Epoch:  1700  |  train loss: 0.0643037587
Epoch:  1800  |  train loss: 0.0643037640
Epoch:  1900  |  train loss: 0.0643037602
Epoch:  2000  |  train loss: 0.0643037662
Processing class: 10
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0664303109
Epoch:   200  |  train loss: 0.0664303094
Epoch:   300  |  train loss: 0.0664303094
Epoch:   400  |  train loss: 0.0664303109
Epoch:   500  |  train loss: 0.0664303124
Epoch:   600  |  train loss: 0.0664303064
Epoch:   700  |  train loss: 0.0664303094
Epoch:   800  |  train loss: 0.0664303109
Epoch:   900  |  train loss: 0.0664303094
Epoch:  1000  |  train loss: 0.0664303094
Epoch:  1100  |  train loss: 0.0664303079
Epoch:  1200  |  train loss: 0.0664303109
Epoch:  1300  |  train loss: 0.0664303109
Epoch:  1400  |  train loss: 0.0664303079
Epoch:  1500  |  train loss: 0.0664303079
Epoch:  1600  |  train loss: 0.0664303094
Epoch:  1700  |  train loss: 0.0664303094
Epoch:  1800  |  train loss: 0.0664303094
Epoch:  1900  |  train loss: 0.0664303094
Epoch:  2000  |  train loss: 0.0664303079
Processing class: 11
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666426629
Epoch:   200  |  train loss: 0.0666426599
Epoch:   300  |  train loss: 0.0666426629
Epoch:   400  |  train loss: 0.0666426629
Epoch:   500  |  train loss: 0.0666426644
Epoch:   600  |  train loss: 0.0666426599
Epoch:   700  |  train loss: 0.0666426629
Epoch:   800  |  train loss: 0.0666426659
Epoch:   900  |  train loss: 0.0666426599
Epoch:  1000  |  train loss: 0.0666426599
Epoch:  1100  |  train loss: 0.0666426599
Epoch:  1200  |  train loss: 0.0666426599
Epoch:  1300  |  train loss: 0.0666426644
Epoch:  1400  |  train loss: 0.0666426614
Epoch:  1500  |  train loss: 0.0666426614
Epoch:  1600  |  train loss: 0.0666426614
Epoch:  1700  |  train loss: 0.0666426629
Epoch:  1800  |  train loss: 0.0666426629
Epoch:  1900  |  train loss: 0.0666426629
Epoch:  2000  |  train loss: 0.0666426599
Processing class: 12
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666490763
Epoch:   200  |  train loss: 0.0666490778
Epoch:   300  |  train loss: 0.0666490749
Epoch:   400  |  train loss: 0.0666490778
Epoch:   500  |  train loss: 0.0666490793
Epoch:   600  |  train loss: 0.0666490763
Epoch:   700  |  train loss: 0.0666490763
Epoch:   800  |  train loss: 0.0666490763
Epoch:   900  |  train loss: 0.0666490763
Epoch:  1000  |  train loss: 0.0666490763
Epoch:  1100  |  train loss: 0.0666490778
Epoch:  1200  |  train loss: 0.0666490778
Epoch:  1300  |  train loss: 0.0666490778
Epoch:  1400  |  train loss: 0.0666490763
Epoch:  1500  |  train loss: 0.0666490778
Epoch:  1600  |  train loss: 0.0666490763
Epoch:  1700  |  train loss: 0.0666490734
Epoch:  1800  |  train loss: 0.0666490793
Epoch:  1900  |  train loss: 0.0666490793
Epoch:  2000  |  train loss: 0.0666490778
Processing class: 13
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0660022557
Epoch:   200  |  train loss: 0.0660022542
Epoch:   300  |  train loss: 0.0660022557
Epoch:   400  |  train loss: 0.0660022527
Epoch:   500  |  train loss: 0.0660022527
Epoch:   600  |  train loss: 0.0660022572
Epoch:   700  |  train loss: 0.0660022557
Epoch:   800  |  train loss: 0.0660022557
Epoch:   900  |  train loss: 0.0660022572
Epoch:  1000  |  train loss: 0.0660022542
Epoch:  1100  |  train loss: 0.0660022557
Epoch:  1200  |  train loss: 0.0660022542
Epoch:  1300  |  train loss: 0.0660022572
Epoch:  1400  |  train loss: 0.0660022557
Epoch:  1500  |  train loss: 0.0660022542
Epoch:  1600  |  train loss: 0.0660022572
Epoch:  1700  |  train loss: 0.0660022572
Epoch:  1800  |  train loss: 0.0660022572
Epoch:  1900  |  train loss: 0.0660022527
Epoch:  2000  |  train loss: 0.0660022587
Processing class: 14
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666607454
Epoch:   200  |  train loss: 0.0666607440
Epoch:   300  |  train loss: 0.0666607425
Epoch:   400  |  train loss: 0.0666607440
Epoch:   500  |  train loss: 0.0666607425
Epoch:   600  |  train loss: 0.0666607425
Epoch:   700  |  train loss: 0.0666607454
Epoch:   800  |  train loss: 0.0666607410
Epoch:   900  |  train loss: 0.0666607440
Epoch:  1000  |  train loss: 0.0666607440
Epoch:  1100  |  train loss: 0.0666607469
Epoch:  1200  |  train loss: 0.0666607454
Epoch:  1300  |  train loss: 0.0666607440
Epoch:  1400  |  train loss: 0.0666607454
Epoch:  1500  |  train loss: 0.0666607454
Epoch:  1600  |  train loss: 0.0666607440
Epoch:  1700  |  train loss: 0.0666607469
Epoch:  1800  |  train loss: 0.0666607454
Epoch:  1900  |  train loss: 0.0666607454
Epoch:  2000  |  train loss: 0.0666607425
Processing class: 15
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655742288
Epoch:   200  |  train loss: 0.0655742273
Epoch:   300  |  train loss: 0.0655742288
Epoch:   400  |  train loss: 0.0655742258
Epoch:   500  |  train loss: 0.0655742273
Epoch:   600  |  train loss: 0.0655742288
Epoch:   700  |  train loss: 0.0655742288
Epoch:   800  |  train loss: 0.0655742288
Epoch:   900  |  train loss: 0.0655742258
Epoch:  1000  |  train loss: 0.0655742332
Epoch:  1100  |  train loss: 0.0655742288
Epoch:  1200  |  train loss: 0.0655742258
Epoch:  1300  |  train loss: 0.0655742273
Epoch:  1400  |  train loss: 0.0655742273
Epoch:  1500  |  train loss: 0.0655742273
Epoch:  1600  |  train loss: 0.0655742273
Epoch:  1700  |  train loss: 0.0655742303
Epoch:  1800  |  train loss: 0.0655742258
Epoch:  1900  |  train loss: 0.0655742243
Epoch:  2000  |  train loss: 0.0655742288
Processing class: 16
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0665620580
Epoch:   200  |  train loss: 0.0665620580
Epoch:   300  |  train loss: 0.0665620595
Epoch:   400  |  train loss: 0.0665620565
Epoch:   500  |  train loss: 0.0665620595
Epoch:   600  |  train loss: 0.0665620565
Epoch:   700  |  train loss: 0.0665620580
Epoch:   800  |  train loss: 0.0665620565
Epoch:   900  |  train loss: 0.0665620580
Epoch:  1000  |  train loss: 0.0665620580
Epoch:  1100  |  train loss: 0.0665620551
Epoch:  1200  |  train loss: 0.0665620595
Epoch:  1300  |  train loss: 0.0665620551
Epoch:  1400  |  train loss: 0.0665620580
Epoch:  1500  |  train loss: 0.0665620565
Epoch:  1600  |  train loss: 0.0665620551
Epoch:  1700  |  train loss: 0.0665620565
Epoch:  1800  |  train loss: 0.0665620536
Epoch:  1900  |  train loss: 0.0665620565
Epoch:  2000  |  train loss: 0.0665620565
Processing class: 17
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 18
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666360736
Epoch:   200  |  train loss: 0.0666360706
Epoch:   300  |  train loss: 0.0666360706
Epoch:   400  |  train loss: 0.0666360721
Epoch:   500  |  train loss: 0.0666360736
Epoch:   600  |  train loss: 0.0666360736
Epoch:   700  |  train loss: 0.0666360736
Epoch:   800  |  train loss: 0.0666360736
Epoch:   900  |  train loss: 0.0666360736
Epoch:  1000  |  train loss: 0.0666360736
Epoch:  1100  |  train loss: 0.0666360736
Epoch:  1200  |  train loss: 0.0666360691
Epoch:  1300  |  train loss: 0.0666360736
Epoch:  1400  |  train loss: 0.0666360766
Epoch:  1500  |  train loss: 0.0666360736
Epoch:  1600  |  train loss: 0.0666360736
Epoch:  1700  |  train loss: 0.0666360736
Epoch:  1800  |  train loss: 0.0666360736
Epoch:  1900  |  train loss: 0.0666360676
Epoch:  2000  |  train loss: 0.0666360736
Processing class: 19
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0625109918
Epoch:   200  |  train loss: 0.0625109948
Epoch:   300  |  train loss: 0.0625109941
Epoch:   400  |  train loss: 0.0625109941
Epoch:   500  |  train loss: 0.0625109918
Epoch:   600  |  train loss: 0.0625109978
Epoch:   700  |  train loss: 0.0625109896
Epoch:   800  |  train loss: 0.0625109933
Epoch:   900  |  train loss: 0.0625109926
Epoch:  1000  |  train loss: 0.0625109971
Epoch:  1100  |  train loss: 0.0625109933
Epoch:  1200  |  train loss: 0.0625109948
Epoch:  1300  |  train loss: 0.0625109948
Epoch:  1400  |  train loss: 0.0625109918
Epoch:  1500  |  train loss: 0.0625109918
Epoch:  1600  |  train loss: 0.0625109941
Epoch:  1700  |  train loss: 0.0625109956
Epoch:  1800  |  train loss: 0.0625109926
Epoch:  1900  |  train loss: 0.0625109948
Epoch:  2000  |  train loss: 0.0625109926
Processing class: 20
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0663005501
Epoch:   200  |  train loss: 0.0663005471
Epoch:   300  |  train loss: 0.0663005531
Epoch:   400  |  train loss: 0.0663005471
Epoch:   500  |  train loss: 0.0663005501
Epoch:   600  |  train loss: 0.0663005501
Epoch:   700  |  train loss: 0.0663005501
Epoch:   800  |  train loss: 0.0663005471
Epoch:   900  |  train loss: 0.0663005501
Epoch:  1000  |  train loss: 0.0663005486
Epoch:  1100  |  train loss: 0.0663005516
Epoch:  1200  |  train loss: 0.0663005516
Epoch:  1300  |  train loss: 0.0663005471
Epoch:  1400  |  train loss: 0.0663005531
Epoch:  1500  |  train loss: 0.0663005501
Epoch:  1600  |  train loss: 0.0663005516
Epoch:  1700  |  train loss: 0.0663005516
Epoch:  1800  |  train loss: 0.0663005501
Epoch:  1900  |  train loss: 0.0663005516
Epoch:  2000  |  train loss: 0.0663005486
Processing class: 21
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 22
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666090965
Epoch:   200  |  train loss: 0.0666090980
Epoch:   300  |  train loss: 0.0666090980
Epoch:   400  |  train loss: 0.0666090995
Epoch:   500  |  train loss: 0.0666090980
Epoch:   600  |  train loss: 0.0666090995
Epoch:   700  |  train loss: 0.0666090995
Epoch:   800  |  train loss: 0.0666090980
Epoch:   900  |  train loss: 0.0666091010
Epoch:  1000  |  train loss: 0.0666090995
Epoch:  1100  |  train loss: 0.0666091010
Epoch:  1200  |  train loss: 0.0666091010
Epoch:  1300  |  train loss: 0.0666090995
Epoch:  1400  |  train loss: 0.0666090995
Epoch:  1500  |  train loss: 0.0666090965
Epoch:  1600  |  train loss: 0.0666090995
Epoch:  1700  |  train loss: 0.0666091010
Epoch:  1800  |  train loss: 0.0666090980
Epoch:  1900  |  train loss: 0.0666091010
Epoch:  2000  |  train loss: 0.0666090995
Processing class: 23
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0668559492
Epoch:   200  |  train loss: 0.0668559507
Epoch:   300  |  train loss: 0.0668559477
Epoch:   400  |  train loss: 0.0668559447
Epoch:   500  |  train loss: 0.0668559477
Epoch:   600  |  train loss: 0.0668559477
Epoch:   700  |  train loss: 0.0668559477
Epoch:   800  |  train loss: 0.0668559447
Epoch:   900  |  train loss: 0.0668559477
Epoch:  1000  |  train loss: 0.0668559477
Epoch:  1100  |  train loss: 0.0668559492
Epoch:  1200  |  train loss: 0.0668559477
Epoch:  1300  |  train loss: 0.0668559492
Epoch:  1400  |  train loss: 0.0668559462
Epoch:  1500  |  train loss: 0.0668559492
Epoch:  1600  |  train loss: 0.0668559477
Epoch:  1700  |  train loss: 0.0668559462
Epoch:  1800  |  train loss: 0.0668559462
Epoch:  1900  |  train loss: 0.0668559477
Epoch:  2000  |  train loss: 0.0668559477
Processing class: 24
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661415562
Epoch:   200  |  train loss: 0.0661415532
Epoch:   300  |  train loss: 0.0661415517
Epoch:   400  |  train loss: 0.0661415547
Epoch:   500  |  train loss: 0.0661415562
Epoch:   600  |  train loss: 0.0661415532
Epoch:   700  |  train loss: 0.0661415547
Epoch:   800  |  train loss: 0.0661415532
Epoch:   900  |  train loss: 0.0661415532
Epoch:  1000  |  train loss: 0.0661415517
Epoch:  1100  |  train loss: 0.0661415562
Epoch:  1200  |  train loss: 0.0661415577
Epoch:  1300  |  train loss: 0.0661415532
Epoch:  1400  |  train loss: 0.0661415547
Epoch:  1500  |  train loss: 0.0661415547
Epoch:  1600  |  train loss: 0.0661415532
Epoch:  1700  |  train loss: 0.0661415532
Epoch:  1800  |  train loss: 0.0661415547
Epoch:  1900  |  train loss: 0.0661415547
Epoch:  2000  |  train loss: 0.0661415532
Processing class: 25
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661984131
Epoch:   200  |  train loss: 0.0661984146
Epoch:   300  |  train loss: 0.0661984161
Epoch:   400  |  train loss: 0.0661984146
Epoch:   500  |  train loss: 0.0661984131
Epoch:   600  |  train loss: 0.0661984116
Epoch:   700  |  train loss: 0.0661984146
Epoch:   800  |  train loss: 0.0661984175
Epoch:   900  |  train loss: 0.0661984131
Epoch:  1000  |  train loss: 0.0661984146
Epoch:  1100  |  train loss: 0.0661984131
Epoch:  1200  |  train loss: 0.0661984131
Epoch:  1300  |  train loss: 0.0661984131
Epoch:  1400  |  train loss: 0.0661984161
Epoch:  1500  |  train loss: 0.0661984146
Epoch:  1600  |  train loss: 0.0661984146
Epoch:  1700  |  train loss: 0.0661984146
Epoch:  1800  |  train loss: 0.0661984131
Epoch:  1900  |  train loss: 0.0661984146
Epoch:  2000  |  train loss: 0.0661984131
Processing class: 26
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0667839065
Epoch:   200  |  train loss: 0.0667839080
Epoch:   300  |  train loss: 0.0667839035
Epoch:   400  |  train loss: 0.0667839050
Epoch:   500  |  train loss: 0.0667839050
Epoch:   600  |  train loss: 0.0667839050
Epoch:   700  |  train loss: 0.0667839050
Epoch:   800  |  train loss: 0.0667839080
Epoch:   900  |  train loss: 0.0667839065
Epoch:  1000  |  train loss: 0.0667839065
Epoch:  1100  |  train loss: 0.0667839065
Epoch:  1200  |  train loss: 0.0667839050
Epoch:  1300  |  train loss: 0.0667839050
Epoch:  1400  |  train loss: 0.0667839065
Epoch:  1500  |  train loss: 0.0667839065
Epoch:  1600  |  train loss: 0.0667839065
Epoch:  1700  |  train loss: 0.0667839065
Epoch:  1800  |  train loss: 0.0667839050
Epoch:  1900  |  train loss: 0.0667839095
Epoch:  2000  |  train loss: 0.0667839065
Processing class: 27
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0648662195
Epoch:   200  |  train loss: 0.0648662150
Epoch:   300  |  train loss: 0.0648662180
Epoch:   400  |  train loss: 0.0648662150
Epoch:   500  |  train loss: 0.0648662180
Epoch:   600  |  train loss: 0.0648662165
Epoch:   700  |  train loss: 0.0648662165
Epoch:   800  |  train loss: 0.0648662180
Epoch:   900  |  train loss: 0.0648662210
Epoch:  1000  |  train loss: 0.0648662195
Epoch:  1100  |  train loss: 0.0648662165
Epoch:  1200  |  train loss: 0.0648662165
Epoch:  1300  |  train loss: 0.0648662180
Epoch:  1400  |  train loss: 0.0648662195
Epoch:  1500  |  train loss: 0.0648662195
Epoch:  1600  |  train loss: 0.0648662165
Epoch:  1700  |  train loss: 0.0648662150
Epoch:  1800  |  train loss: 0.0648662180
Epoch:  1900  |  train loss: 0.0648662165
Epoch:  2000  |  train loss: 0.0648662165
Processing class: 28
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0668941081
Epoch:   200  |  train loss: 0.0668941081
Epoch:   300  |  train loss: 0.0668941081
Epoch:   400  |  train loss: 0.0668941066
Epoch:   500  |  train loss: 0.0668941051
Epoch:   600  |  train loss: 0.0668941081
Epoch:   700  |  train loss: 0.0668941036
Epoch:   800  |  train loss: 0.0668941066
Epoch:   900  |  train loss: 0.0668941081
Epoch:  1000  |  train loss: 0.0668941051
Epoch:  1100  |  train loss: 0.0668941081
Epoch:  1200  |  train loss: 0.0668941095
Epoch:  1300  |  train loss: 0.0668941095
Epoch:  1400  |  train loss: 0.0668941081
Epoch:  1500  |  train loss: 0.0668941081
Epoch:  1600  |  train loss: 0.0668941081
Epoch:  1700  |  train loss: 0.0668941066
Epoch:  1800  |  train loss: 0.0668941066
Epoch:  1900  |  train loss: 0.0668941081
Epoch:  2000  |  train loss: 0.0668941066
Processing class: 29
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0660526618
Epoch:   200  |  train loss: 0.0660526633
Epoch:   300  |  train loss: 0.0660526633
Epoch:   400  |  train loss: 0.0660526603
Epoch:   500  |  train loss: 0.0660526603
Epoch:   600  |  train loss: 0.0660526633
Epoch:   700  |  train loss: 0.0660526589
Epoch:   800  |  train loss: 0.0660526618
Epoch:   900  |  train loss: 0.0660526618
Epoch:  1000  |  train loss: 0.0660526618
Epoch:  1100  |  train loss: 0.0660526618
Epoch:  1200  |  train loss: 0.0660526618
Epoch:  1300  |  train loss: 0.0660526603
Epoch:  1400  |  train loss: 0.0660526633
Epoch:  1500  |  train loss: 0.0660526603
Epoch:  1600  |  train loss: 0.0660526589
Epoch:  1700  |  train loss: 0.0660526589
Epoch:  1800  |  train loss: 0.0660526618
Epoch:  1900  |  train loss: 0.0660526633
Epoch:  2000  |  train loss: 0.0660526574
Processing class: 30
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0664629206
Epoch:   200  |  train loss: 0.0664629236
Epoch:   300  |  train loss: 0.0664629221
Epoch:   400  |  train loss: 0.0664629236
Epoch:   500  |  train loss: 0.0664629251
Epoch:   600  |  train loss: 0.0664629206
Epoch:   700  |  train loss: 0.0664629236
Epoch:   800  |  train loss: 0.0664629266
Epoch:   900  |  train loss: 0.0664629236
Epoch:  1000  |  train loss: 0.0664629251
Epoch:  1100  |  train loss: 0.0664629266
Epoch:  1200  |  train loss: 0.0664629266
Epoch:  1300  |  train loss: 0.0664629251
Epoch:  1400  |  train loss: 0.0664629236
Epoch:  1500  |  train loss: 0.0664629236
Epoch:  1600  |  train loss: 0.0664629236
Epoch:  1700  |  train loss: 0.0664629236
Epoch:  1800  |  train loss: 0.0664629206
Epoch:  1900  |  train loss: 0.0664629281
Epoch:  2000  |  train loss: 0.0664629266
Processing class: 31
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 32
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0663812563
Epoch:   200  |  train loss: 0.0663812518
Epoch:   300  |  train loss: 0.0663812518
Epoch:   400  |  train loss: 0.0663812503
Epoch:   500  |  train loss: 0.0663812518
Epoch:   600  |  train loss: 0.0663812548
Epoch:   700  |  train loss: 0.0663812533
Epoch:   800  |  train loss: 0.0663812548
Epoch:   900  |  train loss: 0.0663812548
Epoch:  1000  |  train loss: 0.0663812518
Epoch:  1100  |  train loss: 0.0663812533
Epoch:  1200  |  train loss: 0.0663812518
Epoch:  1300  |  train loss: 0.0663812533
Epoch:  1400  |  train loss: 0.0663812533
Epoch:  1500  |  train loss: 0.0663812563
Epoch:  1600  |  train loss: 0.0663812518
Epoch:  1700  |  train loss: 0.0663812503
Epoch:  1800  |  train loss: 0.0663812533
Epoch:  1900  |  train loss: 0.0663812503
Epoch:  2000  |  train loss: 0.0663812548
Processing class: 33
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 34
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662063047
Epoch:   200  |  train loss: 0.0662063062
Epoch:   300  |  train loss: 0.0662063092
Epoch:   400  |  train loss: 0.0662063077
Epoch:   500  |  train loss: 0.0662063077
Epoch:   600  |  train loss: 0.0662063032
Epoch:   700  |  train loss: 0.0662063092
Epoch:   800  |  train loss: 0.0662063032
Epoch:   900  |  train loss: 0.0662063092
Epoch:  1000  |  train loss: 0.0662063077
Epoch:  1100  |  train loss: 0.0662063032
Epoch:  1200  |  train loss: 0.0662063062
Epoch:  1300  |  train loss: 0.0662063047
Epoch:  1400  |  train loss: 0.0662063062
Epoch:  1500  |  train loss: 0.0662063092
Epoch:  1600  |  train loss: 0.0662063062
Epoch:  1700  |  train loss: 0.0662063062
Epoch:  1800  |  train loss: 0.0662063077
Epoch:  1900  |  train loss: 0.0662063047
Epoch:  2000  |  train loss: 0.0662063062
Processing class: 35
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 36
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662350968
Epoch:   200  |  train loss: 0.0662350923
Epoch:   300  |  train loss: 0.0662350938
Epoch:   400  |  train loss: 0.0662350938
Epoch:   500  |  train loss: 0.0662350997
Epoch:   600  |  train loss: 0.0662350968
Epoch:   700  |  train loss: 0.0662350968
Epoch:   800  |  train loss: 0.0662350968
Epoch:   900  |  train loss: 0.0662350953
Epoch:  1000  |  train loss: 0.0662350968
Epoch:  1100  |  train loss: 0.0662350982
Epoch:  1200  |  train loss: 0.0662350968
Epoch:  1300  |  train loss: 0.0662350953
Epoch:  1400  |  train loss: 0.0662350938
Epoch:  1500  |  train loss: 0.0662350953
Epoch:  1600  |  train loss: 0.0662350953
Epoch:  1700  |  train loss: 0.0662350968
Epoch:  1800  |  train loss: 0.0662350938
Epoch:  1900  |  train loss: 0.0662350968
Epoch:  2000  |  train loss: 0.0662350968
Processing class: 37
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0663829595
Epoch:   200  |  train loss: 0.0663829550
Epoch:   300  |  train loss: 0.0663829595
Epoch:   400  |  train loss: 0.0663829595
Epoch:   500  |  train loss: 0.0663829565
Epoch:   600  |  train loss: 0.0663829550
Epoch:   700  |  train loss: 0.0663829580
Epoch:   800  |  train loss: 0.0663829565
Epoch:   900  |  train loss: 0.0663829610
Epoch:  1000  |  train loss: 0.0663829565
Epoch:  1100  |  train loss: 0.0663829580
Epoch:  1200  |  train loss: 0.0663829580
Epoch:  1300  |  train loss: 0.0663829580
Epoch:  1400  |  train loss: 0.0663829580
Epoch:  1500  |  train loss: 0.0663829580
Epoch:  1600  |  train loss: 0.0663829565
Epoch:  1700  |  train loss: 0.0663829580
Epoch:  1800  |  train loss: 0.0663829580
Epoch:  1900  |  train loss: 0.0663829565
Epoch:  2000  |  train loss: 0.0663829565
Processing class: 38
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0652980804
Epoch:   200  |  train loss: 0.0652980819
Epoch:   300  |  train loss: 0.0652980819
Epoch:   400  |  train loss: 0.0652980790
Epoch:   500  |  train loss: 0.0652980790
Epoch:   600  |  train loss: 0.0652980819
Epoch:   700  |  train loss: 0.0652980819
Epoch:   800  |  train loss: 0.0652980804
Epoch:   900  |  train loss: 0.0652980834
Epoch:  1000  |  train loss: 0.0652980849
Epoch:  1100  |  train loss: 0.0652980819
Epoch:  1200  |  train loss: 0.0652980812
Epoch:  1300  |  train loss: 0.0652980804
Epoch:  1400  |  train loss: 0.0652980819
Epoch:  1500  |  train loss: 0.0652980790
Epoch:  1600  |  train loss: 0.0652980775
Epoch:  1700  |  train loss: 0.0652980804
Epoch:  1800  |  train loss: 0.0652980790
Epoch:  1900  |  train loss: 0.0652980819
Epoch:  2000  |  train loss: 0.0652980804
Processing class: 39
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662538990
Epoch:   200  |  train loss: 0.0662539020
Epoch:   300  |  train loss: 0.0662539020
Epoch:   400  |  train loss: 0.0662539035
Epoch:   500  |  train loss: 0.0662539035
Epoch:   600  |  train loss: 0.0662539020
Epoch:   700  |  train loss: 0.0662539020
Epoch:   800  |  train loss: 0.0662539035
Epoch:   900  |  train loss: 0.0662539035
Epoch:  1000  |  train loss: 0.0662539050
Epoch:  1100  |  train loss: 0.0662539005
Epoch:  1200  |  train loss: 0.0662539005
Epoch:  1300  |  train loss: 0.0662539020
Epoch:  1400  |  train loss: 0.0662539020
Epoch:  1500  |  train loss: 0.0662539005
Epoch:  1600  |  train loss: 0.0662539050
Epoch:  1700  |  train loss: 0.0662539020
Epoch:  1800  |  train loss: 0.0662539035
Epoch:  1900  |  train loss: 0.0662539035
Epoch:  2000  |  train loss: 0.0662539020
Processing class: 40
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0667788193
Epoch:   200  |  train loss: 0.0667788222
Epoch:   300  |  train loss: 0.0667788222
Epoch:   400  |  train loss: 0.0667788193
Epoch:   500  |  train loss: 0.0667788222
Epoch:   600  |  train loss: 0.0667788208
Epoch:   700  |  train loss: 0.0667788193
Epoch:   800  |  train loss: 0.0667788208
Epoch:   900  |  train loss: 0.0667788237
Epoch:  1000  |  train loss: 0.0667788252
Epoch:  1100  |  train loss: 0.0667788222
Epoch:  1200  |  train loss: 0.0667788237
Epoch:  1300  |  train loss: 0.0667788193
Epoch:  1400  |  train loss: 0.0667788222
Epoch:  1500  |  train loss: 0.0667788222
Epoch:  1600  |  train loss: 0.0667788208
Epoch:  1700  |  train loss: 0.0667788208
Epoch:  1800  |  train loss: 0.0667788208
Epoch:  1900  |  train loss: 0.0667788178
Epoch:  2000  |  train loss: 0.0667788208
Processing class: 41
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0665128142
Epoch:   200  |  train loss: 0.0665128127
Epoch:   300  |  train loss: 0.0665128171
Epoch:   400  |  train loss: 0.0665128171
Epoch:   500  |  train loss: 0.0665128171
Epoch:   600  |  train loss: 0.0665128157
Epoch:   700  |  train loss: 0.0665128171
Epoch:   800  |  train loss: 0.0665128157
Epoch:   900  |  train loss: 0.0665128149
Epoch:  1000  |  train loss: 0.0665128142
Epoch:  1100  |  train loss: 0.0665128127
Epoch:  1200  |  train loss: 0.0665128157
Epoch:  1300  |  train loss: 0.0665128157
Epoch:  1400  |  train loss: 0.0665128186
Epoch:  1500  |  train loss: 0.0665128157
Epoch:  1600  |  train loss: 0.0665128171
Epoch:  1700  |  train loss: 0.0665128157
Epoch:  1800  |  train loss: 0.0665128186
Epoch:  1900  |  train loss: 0.0665128171
Epoch:  2000  |  train loss: 0.0665128157
Processing class: 42
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657541111
Epoch:   200  |  train loss: 0.0657541081
Epoch:   300  |  train loss: 0.0657541066
Epoch:   400  |  train loss: 0.0657541052
Epoch:   500  |  train loss: 0.0657541096
Epoch:   600  |  train loss: 0.0657541066
Epoch:   700  |  train loss: 0.0657541111
Epoch:   800  |  train loss: 0.0657541052
Epoch:   900  |  train loss: 0.0657541066
Epoch:  1000  |  train loss: 0.0657541037
Epoch:  1100  |  train loss: 0.0657541096
Epoch:  1200  |  train loss: 0.0657541066
Epoch:  1300  |  train loss: 0.0657541096
Epoch:  1400  |  train loss: 0.0657541096
Epoch:  1500  |  train loss: 0.0657541066
Epoch:  1600  |  train loss: 0.0657541066
Epoch:  1700  |  train loss: 0.0657541081
Epoch:  1800  |  train loss: 0.0657541081
Epoch:  1900  |  train loss: 0.0657541066
Epoch:  2000  |  train loss: 0.0657541096
Processing class: 43
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666832551
Epoch:   200  |  train loss: 0.0666832596
Epoch:   300  |  train loss: 0.0666832551
Epoch:   400  |  train loss: 0.0666832536
Epoch:   500  |  train loss: 0.0666832551
Epoch:   600  |  train loss: 0.0666832581
Epoch:   700  |  train loss: 0.0666832611
Epoch:   800  |  train loss: 0.0666832566
Epoch:   900  |  train loss: 0.0666832596
Epoch:  1000  |  train loss: 0.0666832611
Epoch:  1100  |  train loss: 0.0666832581
Epoch:  1200  |  train loss: 0.0666832596
Epoch:  1300  |  train loss: 0.0666832536
Epoch:  1400  |  train loss: 0.0666832522
Epoch:  1500  |  train loss: 0.0666832596
Epoch:  1600  |  train loss: 0.0666832611
Epoch:  1700  |  train loss: 0.0666832566
Epoch:  1800  |  train loss: 0.0666832596
Epoch:  1900  |  train loss: 0.0666832581
Epoch:  2000  |  train loss: 0.0666832551
Processing class: 44
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0664010212
Epoch:   200  |  train loss: 0.0664010182
Epoch:   300  |  train loss: 0.0664010182
Epoch:   400  |  train loss: 0.0664010212
Epoch:   500  |  train loss: 0.0664010167
Epoch:   600  |  train loss: 0.0664010212
Epoch:   700  |  train loss: 0.0664010212
Epoch:   800  |  train loss: 0.0664010182
Epoch:   900  |  train loss: 0.0664010212
Epoch:  1000  |  train loss: 0.0664010197
Epoch:  1100  |  train loss: 0.0664010212
Epoch:  1200  |  train loss: 0.0664010212
Epoch:  1300  |  train loss: 0.0664010182
Epoch:  1400  |  train loss: 0.0664010182
Epoch:  1500  |  train loss: 0.0664010227
Epoch:  1600  |  train loss: 0.0664010227
Epoch:  1700  |  train loss: 0.0664010212
Epoch:  1800  |  train loss: 0.0664010182
Epoch:  1900  |  train loss: 0.0664010197
Epoch:  2000  |  train loss: 0.0664010212
Processing class: 45
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0665967420
Epoch:   200  |  train loss: 0.0665967450
Epoch:   300  |  train loss: 0.0665967420
Epoch:   400  |  train loss: 0.0665967405
Epoch:   500  |  train loss: 0.0665967435
Epoch:   600  |  train loss: 0.0665967405
Epoch:   700  |  train loss: 0.0665967390
Epoch:   800  |  train loss: 0.0665967405
Epoch:   900  |  train loss: 0.0665967390
Epoch:  1000  |  train loss: 0.0665967435
Epoch:  1100  |  train loss: 0.0665967420
Epoch:  1200  |  train loss: 0.0665967420
Epoch:  1300  |  train loss: 0.0665967435
Epoch:  1400  |  train loss: 0.0665967420
Epoch:  1500  |  train loss: 0.0665967390
Epoch:  1600  |  train loss: 0.0665967420
Epoch:  1700  |  train loss: 0.0665967405
Epoch:  1800  |  train loss: 0.0665967435
Epoch:  1900  |  train loss: 0.0665967420
Epoch:  2000  |  train loss: 0.0665967405
Processing class: 46
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0666028157
Epoch:   200  |  train loss: 0.0666028187
Epoch:   300  |  train loss: 0.0666028202
Epoch:   400  |  train loss: 0.0666028172
Epoch:   500  |  train loss: 0.0666028202
Epoch:   600  |  train loss: 0.0666028157
Epoch:   700  |  train loss: 0.0666028187
Epoch:   800  |  train loss: 0.0666028187
Epoch:   900  |  train loss: 0.0666028187
Epoch:  1000  |  train loss: 0.0666028202
Epoch:  1100  |  train loss: 0.0666028172
Epoch:  1200  |  train loss: 0.0666028187
Epoch:  1300  |  train loss: 0.0666028187
Epoch:  1400  |  train loss: 0.0666028157
Epoch:  1500  |  train loss: 0.0666028187
Epoch:  1600  |  train loss: 0.0666028172
Epoch:  1700  |  train loss: 0.0666028172
Epoch:  1800  |  train loss: 0.0666028172
Epoch:  1900  |  train loss: 0.0666028172
Epoch:  2000  |  train loss: 0.0666028172
Processing class: 47
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661030129
Epoch:   200  |  train loss: 0.0661030129
Epoch:   300  |  train loss: 0.0661030158
Epoch:   400  |  train loss: 0.0661030114
Epoch:   500  |  train loss: 0.0661030158
Epoch:   600  |  train loss: 0.0661030158
Epoch:   700  |  train loss: 0.0661030173
Epoch:   800  |  train loss: 0.0661030158
Epoch:   900  |  train loss: 0.0661030203
Epoch:  1000  |  train loss: 0.0661030143
Epoch:  1100  |  train loss: 0.0661030143
Epoch:  1200  |  train loss: 0.0661030188
Epoch:  1300  |  train loss: 0.0661030188
Epoch:  1400  |  train loss: 0.0661030173
Epoch:  1500  |  train loss: 0.0661030143
Epoch:  1600  |  train loss: 0.0661030173
Epoch:  1700  |  train loss: 0.0661030158
Epoch:  1800  |  train loss: 0.0661030173
Epoch:  1900  |  train loss: 0.0661030173
Epoch:  2000  |  train loss: 0.0661030188
Processing class: 48
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0664623901
Epoch:   200  |  train loss: 0.0664623916
Epoch:   300  |  train loss: 0.0664623901
Epoch:   400  |  train loss: 0.0664623916
Epoch:   500  |  train loss: 0.0664623901
Epoch:   600  |  train loss: 0.0664623916
Epoch:   700  |  train loss: 0.0664623901
Epoch:   800  |  train loss: 0.0664623901
Epoch:   900  |  train loss: 0.0664623886
Epoch:  1000  |  train loss: 0.0664623842
Epoch:  1100  |  train loss: 0.0664623886
Epoch:  1200  |  train loss: 0.0664623871
Epoch:  1300  |  train loss: 0.0664623901
Epoch:  1400  |  train loss: 0.0664623901
Epoch:  1500  |  train loss: 0.0664623871
Epoch:  1600  |  train loss: 0.0664623886
Epoch:  1700  |  train loss: 0.0664623886
Epoch:  1800  |  train loss: 0.0664623886
Epoch:  1900  |  train loss: 0.0664623901
Epoch:  2000  |  train loss: 0.0664623886
Processing class: 49
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Clasifying using reconstruction function cost
/home/z1165703/FeCAM/models/base.py:195: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data_point = torch.tensor(data_point).float().cuda()
2024-04-01 10:13:24,343 [trainer.py] => CNN: {'total': 83.44, '00-09': 87.7, '10-19': 79.6, '20-29': 84.9, '30-39': 81.0, '40-49': 84.0, 'old': 0, 'new': 83.44}
2024-04-01 10:13:24,344 [trainer.py] => No NME accuracy
2024-04-01 10:13:24,344 [trainer.py] => FeCAM: {'total': 70.96, '00-09': 78.1, '10-19': 64.7, '20-29': 73.8, '30-39': 66.3, '40-49': 71.9, 'old': 0, 'new': 70.96}
2024-04-01 10:13:24,344 [trainer.py] => CNN top1 curve: [83.44]
2024-04-01 10:13:24,344 [trainer.py] => CNN top5 curve: [96.5]
2024-04-01 10:13:24,344 [trainer.py] => FeCAM top1 curve: [70.96]
2024-04-01 10:13:24,344 [trainer.py] => FeCAM top5 curve: [86.38]

2024-04-01 10:13:24,348 [fecam.py] => Learning on 50-60
Processing class: 50
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655817166
Epoch:   200  |  train loss: 0.0655817136
Epoch:   300  |  train loss: 0.0655817136
Epoch:   400  |  train loss: 0.0655817136
Epoch:   500  |  train loss: 0.0655817159
Epoch:   600  |  train loss: 0.0655817121
Epoch:   700  |  train loss: 0.0655817136
Epoch:   800  |  train loss: 0.0655817136
Epoch:   900  |  train loss: 0.0655817166
Epoch:  1000  |  train loss: 0.0655817136
Epoch:  1100  |  train loss: 0.0655817091
Epoch:  1200  |  train loss: 0.0655817121
Epoch:  1300  |  train loss: 0.0655817136
Epoch:  1400  |  train loss: 0.0655817166
Epoch:  1500  |  train loss: 0.0655817151
Epoch:  1600  |  train loss: 0.0655817151
Epoch:  1700  |  train loss: 0.0655817106
Epoch:  1800  |  train loss: 0.0655817136
Epoch:  1900  |  train loss: 0.0655817106
Epoch:  2000  |  train loss: 0.0655817121
Processing class: 51
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661975220
Epoch:   200  |  train loss: 0.0661975235
Epoch:   300  |  train loss: 0.0661975235
Epoch:   400  |  train loss: 0.0661975250
Epoch:   500  |  train loss: 0.0661975235
Epoch:   600  |  train loss: 0.0661975250
Epoch:   700  |  train loss: 0.0661975250
Epoch:   800  |  train loss: 0.0661975235
Epoch:   900  |  train loss: 0.0661975235
Epoch:  1000  |  train loss: 0.0661975235
Epoch:  1100  |  train loss: 0.0661975250
Epoch:  1200  |  train loss: 0.0661975205
Epoch:  1300  |  train loss: 0.0661975220
Epoch:  1400  |  train loss: 0.0661975250
Epoch:  1500  |  train loss: 0.0661975250
Epoch:  1600  |  train loss: 0.0661975250
Epoch:  1700  |  train loss: 0.0661975265
Epoch:  1800  |  train loss: 0.0661975220
Epoch:  1900  |  train loss: 0.0661975250
Epoch:  2000  |  train loss: 0.0661975220
Processing class: 52
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657986164
Epoch:   200  |  train loss: 0.0657986149
Epoch:   300  |  train loss: 0.0657986134
Epoch:   400  |  train loss: 0.0657986164
Epoch:   500  |  train loss: 0.0657986164
Epoch:   600  |  train loss: 0.0657986134
Epoch:   700  |  train loss: 0.0657986164
Epoch:   800  |  train loss: 0.0657986134
Epoch:   900  |  train loss: 0.0657986104
Epoch:  1000  |  train loss: 0.0657986179
Epoch:  1100  |  train loss: 0.0657986164
Epoch:  1200  |  train loss: 0.0657986119
Epoch:  1300  |  train loss: 0.0657986164
Epoch:  1400  |  train loss: 0.0657986164
Epoch:  1500  |  train loss: 0.0657986090
Epoch:  1600  |  train loss: 0.0657986164
Epoch:  1700  |  train loss: 0.0657986149
Epoch:  1800  |  train loss: 0.0657986134
Epoch:  1900  |  train loss: 0.0657986134
Epoch:  2000  |  train loss: 0.0657986119
Processing class: 53
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0654396057
Epoch:   200  |  train loss: 0.0654396057
Epoch:   300  |  train loss: 0.0654396087
Epoch:   400  |  train loss: 0.0654396072
Epoch:   500  |  train loss: 0.0654396102
Epoch:   600  |  train loss: 0.0654396072
Epoch:   700  |  train loss: 0.0654396087
Epoch:   800  |  train loss: 0.0654396079
Epoch:   900  |  train loss: 0.0654396087
Epoch:  1000  |  train loss: 0.0654396057
Epoch:  1100  |  train loss: 0.0654396065
Epoch:  1200  |  train loss: 0.0654396094
Epoch:  1300  |  train loss: 0.0654396065
Epoch:  1400  |  train loss: 0.0654396072
Epoch:  1500  |  train loss: 0.0654396087
Epoch:  1600  |  train loss: 0.0654396079
Epoch:  1700  |  train loss: 0.0654396087
Epoch:  1800  |  train loss: 0.0654396087
Epoch:  1900  |  train loss: 0.0654396057
Epoch:  2000  |  train loss: 0.0654396072
Processing class: 54
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0584612757
Epoch:   200  |  train loss: 0.0584612727
Epoch:   300  |  train loss: 0.0584612750
Epoch:   400  |  train loss: 0.0584612750
Epoch:   500  |  train loss: 0.0584612750
Epoch:   600  |  train loss: 0.0584612727
Epoch:   700  |  train loss: 0.0584612727
Epoch:   800  |  train loss: 0.0584612757
Epoch:   900  |  train loss: 0.0584612735
Epoch:  1000  |  train loss: 0.0584612742
Epoch:  1100  |  train loss: 0.0584612742
Epoch:  1200  |  train loss: 0.0584612742
Epoch:  1300  |  train loss: 0.0584612742
Epoch:  1400  |  train loss: 0.0584612757
Epoch:  1500  |  train loss: 0.0584612727
Epoch:  1600  |  train loss: 0.0584612727
Epoch:  1700  |  train loss: 0.0584612757
Epoch:  1800  |  train loss: 0.0584612727
Epoch:  1900  |  train loss: 0.0584612720
Epoch:  2000  |  train loss: 0.0584612757
Processing class: 55
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 56
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0659699157
Epoch:   200  |  train loss: 0.0659699142
Epoch:   300  |  train loss: 0.0659699142
Epoch:   400  |  train loss: 0.0659699172
Epoch:   500  |  train loss: 0.0659699172
Epoch:   600  |  train loss: 0.0659699187
Epoch:   700  |  train loss: 0.0659699142
Epoch:   800  |  train loss: 0.0659699142
Epoch:   900  |  train loss: 0.0659699172
Epoch:  1000  |  train loss: 0.0659699172
Epoch:  1100  |  train loss: 0.0659699157
Epoch:  1200  |  train loss: 0.0659699127
Epoch:  1300  |  train loss: 0.0659699127
Epoch:  1400  |  train loss: 0.0659699157
Epoch:  1500  |  train loss: 0.0659699142
Epoch:  1600  |  train loss: 0.0659699157
Epoch:  1700  |  train loss: 0.0659699142
Epoch:  1800  |  train loss: 0.0659699172
Epoch:  1900  |  train loss: 0.0659699187
Epoch:  2000  |  train loss: 0.0659699172
Processing class: 57
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0656974941
Epoch:   200  |  train loss: 0.0656974912
Epoch:   300  |  train loss: 0.0656974941
Epoch:   400  |  train loss: 0.0656974912
Epoch:   500  |  train loss: 0.0656974927
Epoch:   600  |  train loss: 0.0656974927
Epoch:   700  |  train loss: 0.0656974897
Epoch:   800  |  train loss: 0.0656974934
Epoch:   900  |  train loss: 0.0656974956
Epoch:  1000  |  train loss: 0.0656974927
Epoch:  1100  |  train loss: 0.0656974941
Epoch:  1200  |  train loss: 0.0656974927
Epoch:  1300  |  train loss: 0.0656974927
Epoch:  1400  |  train loss: 0.0656974927
Epoch:  1500  |  train loss: 0.0656974919
Epoch:  1600  |  train loss: 0.0656974941
Epoch:  1700  |  train loss: 0.0656974897
Epoch:  1800  |  train loss: 0.0656974956
Epoch:  1900  |  train loss: 0.0656974912
Epoch:  2000  |  train loss: 0.0656974927
Processing class: 58
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0649877243
Epoch:   200  |  train loss: 0.0649877220
Epoch:   300  |  train loss: 0.0649877250
Epoch:   400  |  train loss: 0.0649877295
Epoch:   500  |  train loss: 0.0649877258
Epoch:   600  |  train loss: 0.0649877258
Epoch:   700  |  train loss: 0.0649877250
Epoch:   800  |  train loss: 0.0649877295
Epoch:   900  |  train loss: 0.0649877265
Epoch:  1000  |  train loss: 0.0649877280
Epoch:  1100  |  train loss: 0.0649877250
Epoch:  1200  |  train loss: 0.0649877265
Epoch:  1300  |  train loss: 0.0649877295
Epoch:  1400  |  train loss: 0.0649877265
Epoch:  1500  |  train loss: 0.0649877250
Epoch:  1600  |  train loss: 0.0649877250
Epoch:  1700  |  train loss: 0.0649877265
Epoch:  1800  |  train loss: 0.0649877235
Epoch:  1900  |  train loss: 0.0649877205
Epoch:  2000  |  train loss: 0.0649877250
Processing class: 59
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655118391
Epoch:   200  |  train loss: 0.0655118406
Epoch:   300  |  train loss: 0.0655118346
Epoch:   400  |  train loss: 0.0655118376
Epoch:   500  |  train loss: 0.0655118361
Epoch:   600  |  train loss: 0.0655118391
Epoch:   700  |  train loss: 0.0655118391
Epoch:   800  |  train loss: 0.0655118361
Epoch:   900  |  train loss: 0.0655118361
Epoch:  1000  |  train loss: 0.0655118346
Epoch:  1100  |  train loss: 0.0655118383
Epoch:  1200  |  train loss: 0.0655118376
Epoch:  1300  |  train loss: 0.0655118376
Epoch:  1400  |  train loss: 0.0655118331
Epoch:  1500  |  train loss: 0.0655118391
Epoch:  1600  |  train loss: 0.0655118383
Epoch:  1700  |  train loss: 0.0655118376
Epoch:  1800  |  train loss: 0.0655118316
Epoch:  1900  |  train loss: 0.0655118376
Epoch:  2000  |  train loss: 0.0655118391
Clasifying using reconstruction function cost
2024-04-01 11:10:34,011 [trainer.py] => CNN: {'total': 71.75, '00-09': 82.2, '10-19': 72.8, '20-29': 78.5, '30-39': 74.9, '40-49': 68.4, '50-59': 53.7, 'old': 75.36, 'new': 53.7}
2024-04-01 11:10:34,012 [trainer.py] => No NME accuracy
2024-04-01 11:10:34,012 [trainer.py] => FeCAM: {'total': 58.88, '00-09': 74.8, '10-19': 60.7, '20-29': 71.3, '30-39': 63.6, '40-49': 65.9, '50-59': 17.0, 'old': 67.26, 'new': 17.0}
2024-04-01 11:10:34,012 [trainer.py] => CNN top1 curve: [83.44, 71.75]
2024-04-01 11:10:34,012 [trainer.py] => CNN top5 curve: [96.5, 89.6]
2024-04-01 11:10:34,012 [trainer.py] => FeCAM top1 curve: [70.96, 58.88]
2024-04-01 11:10:34,012 [trainer.py] => FeCAM top5 curve: [86.38, 79.3]

2024-04-01 11:10:34,016 [fecam.py] => Learning on 60-70
Processing class: 60
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 61
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0593134351
Epoch:   200  |  train loss: 0.0593134344
Epoch:   300  |  train loss: 0.0593134329
Epoch:   400  |  train loss: 0.0593134321
Epoch:   500  |  train loss: 0.0593134314
Epoch:   600  |  train loss: 0.0593134314
Epoch:   700  |  train loss: 0.0593134329
Epoch:   800  |  train loss: 0.0593134336
Epoch:   900  |  train loss: 0.0593134314
Epoch:  1000  |  train loss: 0.0593134336
Epoch:  1100  |  train loss: 0.0593134359
Epoch:  1200  |  train loss: 0.0593134299
Epoch:  1300  |  train loss: 0.0593134314
Epoch:  1400  |  train loss: 0.0593134329
Epoch:  1500  |  train loss: 0.0593134329
Epoch:  1600  |  train loss: 0.0593134336
Epoch:  1700  |  train loss: 0.0593134321
Epoch:  1800  |  train loss: 0.0593134321
Epoch:  1900  |  train loss: 0.0593134314
Epoch:  2000  |  train loss: 0.0593134329
Processing class: 62
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661746234
Epoch:   200  |  train loss: 0.0661746234
Epoch:   300  |  train loss: 0.0661746234
Epoch:   400  |  train loss: 0.0661746249
Epoch:   500  |  train loss: 0.0661746249
Epoch:   600  |  train loss: 0.0661746278
Epoch:   700  |  train loss: 0.0661746249
Epoch:   800  |  train loss: 0.0661746234
Epoch:   900  |  train loss: 0.0661746278
Epoch:  1000  |  train loss: 0.0661746219
Epoch:  1100  |  train loss: 0.0661746234
Epoch:  1200  |  train loss: 0.0661746249
Epoch:  1300  |  train loss: 0.0661746234
Epoch:  1400  |  train loss: 0.0661746249
Epoch:  1500  |  train loss: 0.0661746234
Epoch:  1600  |  train loss: 0.0661746234
Epoch:  1700  |  train loss: 0.0661746234
Epoch:  1800  |  train loss: 0.0661746264
Epoch:  1900  |  train loss: 0.0661746219
Epoch:  2000  |  train loss: 0.0661746249
Processing class: 63
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 64
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0638546735
Epoch:   200  |  train loss: 0.0638546750
Epoch:   300  |  train loss: 0.0638546705
Epoch:   400  |  train loss: 0.0638546720
Epoch:   500  |  train loss: 0.0638546728
Epoch:   600  |  train loss: 0.0638546735
Epoch:   700  |  train loss: 0.0638546735
Epoch:   800  |  train loss: 0.0638546742
Epoch:   900  |  train loss: 0.0638546750
Epoch:  1000  |  train loss: 0.0638546728
Epoch:  1100  |  train loss: 0.0638546757
Epoch:  1200  |  train loss: 0.0638546765
Epoch:  1300  |  train loss: 0.0638546795
Epoch:  1400  |  train loss: 0.0638546750
Epoch:  1500  |  train loss: 0.0638546720
Epoch:  1600  |  train loss: 0.0638546713
Epoch:  1700  |  train loss: 0.0638546757
Epoch:  1800  |  train loss: 0.0638546750
Epoch:  1900  |  train loss: 0.0638546742
Epoch:  2000  |  train loss: 0.0638546735
Processing class: 65
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0653702766
Epoch:   200  |  train loss: 0.0653702810
Epoch:   300  |  train loss: 0.0653702781
Epoch:   400  |  train loss: 0.0653702796
Epoch:   500  |  train loss: 0.0653702781
Epoch:   600  |  train loss: 0.0653702796
Epoch:   700  |  train loss: 0.0653702781
Epoch:   800  |  train loss: 0.0653702803
Epoch:   900  |  train loss: 0.0653702788
Epoch:  1000  |  train loss: 0.0653702796
Epoch:  1100  |  train loss: 0.0653702840
Epoch:  1200  |  train loss: 0.0653702796
Epoch:  1300  |  train loss: 0.0653702803
Epoch:  1400  |  train loss: 0.0653702781
Epoch:  1500  |  train loss: 0.0653702796
Epoch:  1600  |  train loss: 0.0653702796
Epoch:  1700  |  train loss: 0.0653702796
Epoch:  1800  |  train loss: 0.0653702796
Epoch:  1900  |  train loss: 0.0653702796
Epoch:  2000  |  train loss: 0.0653702766
Processing class: 66
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0663317323
Epoch:   200  |  train loss: 0.0663317323
Epoch:   300  |  train loss: 0.0663317278
Epoch:   400  |  train loss: 0.0663317308
Epoch:   500  |  train loss: 0.0663317293
Epoch:   600  |  train loss: 0.0663317293
Epoch:   700  |  train loss: 0.0663317278
Epoch:   800  |  train loss: 0.0663317293
Epoch:   900  |  train loss: 0.0663317308
Epoch:  1000  |  train loss: 0.0663317323
Epoch:  1100  |  train loss: 0.0663317308
Epoch:  1200  |  train loss: 0.0663317263
Epoch:  1300  |  train loss: 0.0663317323
Epoch:  1400  |  train loss: 0.0663317323
Epoch:  1500  |  train loss: 0.0663317323
Epoch:  1600  |  train loss: 0.0663317308
Epoch:  1700  |  train loss: 0.0663317263
Epoch:  1800  |  train loss: 0.0663317323
Epoch:  1900  |  train loss: 0.0663317293
Epoch:  2000  |  train loss: 0.0663317308
Processing class: 67
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0645211384
Epoch:   200  |  train loss: 0.0645211324
Epoch:   300  |  train loss: 0.0645211361
Epoch:   400  |  train loss: 0.0645211339
Epoch:   500  |  train loss: 0.0645211324
Epoch:   600  |  train loss: 0.0645211354
Epoch:   700  |  train loss: 0.0645211369
Epoch:   800  |  train loss: 0.0645211354
Epoch:   900  |  train loss: 0.0645211324
Epoch:  1000  |  train loss: 0.0645211332
Epoch:  1100  |  train loss: 0.0645211324
Epoch:  1200  |  train loss: 0.0645211369
Epoch:  1300  |  train loss: 0.0645211346
Epoch:  1400  |  train loss: 0.0645211339
Epoch:  1500  |  train loss: 0.0645211346
Epoch:  1600  |  train loss: 0.0645211369
Epoch:  1700  |  train loss: 0.0645211339
Epoch:  1800  |  train loss: 0.0645211346
Epoch:  1900  |  train loss: 0.0645211354
Epoch:  2000  |  train loss: 0.0645211361
Processing class: 68
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0648744866
Epoch:   200  |  train loss: 0.0648744866
Epoch:   300  |  train loss: 0.0648744866
Epoch:   400  |  train loss: 0.0648744859
Epoch:   500  |  train loss: 0.0648744851
Epoch:   600  |  train loss: 0.0648744836
Epoch:   700  |  train loss: 0.0648744851
Epoch:   800  |  train loss: 0.0648744836
Epoch:   900  |  train loss: 0.0648744851
Epoch:  1000  |  train loss: 0.0648744851
Epoch:  1100  |  train loss: 0.0648744866
Epoch:  1200  |  train loss: 0.0648744844
Epoch:  1300  |  train loss: 0.0648744881
Epoch:  1400  |  train loss: 0.0648744866
Epoch:  1500  |  train loss: 0.0648744866
Epoch:  1600  |  train loss: 0.0648744836
Epoch:  1700  |  train loss: 0.0648744881
Epoch:  1800  |  train loss: 0.0648744896
Epoch:  1900  |  train loss: 0.0648744851
Epoch:  2000  |  train loss: 0.0648744896
Processing class: 69
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661143467
Epoch:   200  |  train loss: 0.0661143437
Epoch:   300  |  train loss: 0.0661143497
Epoch:   400  |  train loss: 0.0661143467
Epoch:   500  |  train loss: 0.0661143482
Epoch:   600  |  train loss: 0.0661143497
Epoch:   700  |  train loss: 0.0661143497
Epoch:   800  |  train loss: 0.0661143467
Epoch:   900  |  train loss: 0.0661143452
Epoch:  1000  |  train loss: 0.0661143467
Epoch:  1100  |  train loss: 0.0661143482
Epoch:  1200  |  train loss: 0.0661143467
Epoch:  1300  |  train loss: 0.0661143452
Epoch:  1400  |  train loss: 0.0661143482
Epoch:  1500  |  train loss: 0.0661143452
Epoch:  1600  |  train loss: 0.0661143482
Epoch:  1700  |  train loss: 0.0661143452
Epoch:  1800  |  train loss: 0.0661143512
Epoch:  1900  |  train loss: 0.0661143497
Epoch:  2000  |  train loss: 0.0661143497
Clasifying using reconstruction function cost
2024-04-01 12:09:25,752 [trainer.py] => CNN: {'total': 64.66, '00-09': 75.0, '10-19': 70.1, '20-29': 77.1, '30-39': 70.6, '40-49': 64.0, '50-59': 45.8, '60-69': 50.0, 'old': 67.1, 'new': 50.0}
2024-04-01 12:09:25,753 [trainer.py] => No NME accuracy
2024-04-01 12:09:25,753 [trainer.py] => FeCAM: {'total': 47.44, '00-09': 68.2, '10-19': 55.0, '20-29': 65.9, '30-39': 55.7, '40-49': 58.0, '50-59': 12.1, '60-69': 17.2, 'old': 52.48, 'new': 17.2}
2024-04-01 12:09:25,753 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66]
2024-04-01 12:09:25,753 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54]
2024-04-01 12:09:25,753 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.44]
2024-04-01 12:09:25,753 [trainer.py] => FeCAM top5 curve: [86.38, 79.3, 72.56]

2024-04-01 12:09:25,757 [fecam.py] => Learning on 70-80
Processing class: 70
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0631203830
Epoch:   200  |  train loss: 0.0631203823
Epoch:   300  |  train loss: 0.0631203838
Epoch:   400  |  train loss: 0.0631203830
Epoch:   500  |  train loss: 0.0631203853
Epoch:   600  |  train loss: 0.0631203830
Epoch:   700  |  train loss: 0.0631203838
Epoch:   800  |  train loss: 0.0631203845
Epoch:   900  |  train loss: 0.0631203838
Epoch:  1000  |  train loss: 0.0631203815
Epoch:  1100  |  train loss: 0.0631203830
Epoch:  1200  |  train loss: 0.0631203808
Epoch:  1300  |  train loss: 0.0631203830
Epoch:  1400  |  train loss: 0.0631203845
Epoch:  1500  |  train loss: 0.0631203823
Epoch:  1600  |  train loss: 0.0631203808
Epoch:  1700  |  train loss: 0.0631203860
Epoch:  1800  |  train loss: 0.0631203808
Epoch:  1900  |  train loss: 0.0631203808
Epoch:  2000  |  train loss: 0.0631203823
Processing class: 71
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661218345
Epoch:   200  |  train loss: 0.0661218405
Epoch:   300  |  train loss: 0.0661218397
Epoch:   400  |  train loss: 0.0661218360
Epoch:   500  |  train loss: 0.0661218345
Epoch:   600  |  train loss: 0.0661218405
Epoch:   700  |  train loss: 0.0661218330
Epoch:   800  |  train loss: 0.0661218360
Epoch:   900  |  train loss: 0.0661218345
Epoch:  1000  |  train loss: 0.0661218390
Epoch:  1100  |  train loss: 0.0661218375
Epoch:  1200  |  train loss: 0.0661218375
Epoch:  1300  |  train loss: 0.0661218360
Epoch:  1400  |  train loss: 0.0661218360
Epoch:  1500  |  train loss: 0.0661218360
Epoch:  1600  |  train loss: 0.0661218375
Epoch:  1700  |  train loss: 0.0661218360
Epoch:  1800  |  train loss: 0.0661218375
Epoch:  1900  |  train loss: 0.0661218360
Epoch:  2000  |  train loss: 0.0661218360
Processing class: 72
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0653983846
Epoch:   200  |  train loss: 0.0653983831
Epoch:   300  |  train loss: 0.0653983817
Epoch:   400  |  train loss: 0.0653983831
Epoch:   500  |  train loss: 0.0653983846
Epoch:   600  |  train loss: 0.0653983817
Epoch:   700  |  train loss: 0.0653983802
Epoch:   800  |  train loss: 0.0653983817
Epoch:   900  |  train loss: 0.0653983802
Epoch:  1000  |  train loss: 0.0653983817
Epoch:  1100  |  train loss: 0.0653983817
Epoch:  1200  |  train loss: 0.0653983802
Epoch:  1300  |  train loss: 0.0653983802
Epoch:  1400  |  train loss: 0.0653983817
Epoch:  1500  |  train loss: 0.0653983817
Epoch:  1600  |  train loss: 0.0653983839
Epoch:  1700  |  train loss: 0.0653983787
Epoch:  1800  |  train loss: 0.0653983802
Epoch:  1900  |  train loss: 0.0653983817
Epoch:  2000  |  train loss: 0.0653983846
Processing class: 73
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0660767853
Epoch:   200  |  train loss: 0.0660767823
Epoch:   300  |  train loss: 0.0660767823
Epoch:   400  |  train loss: 0.0660767868
Epoch:   500  |  train loss: 0.0660767883
Epoch:   600  |  train loss: 0.0660767868
Epoch:   700  |  train loss: 0.0660767868
Epoch:   800  |  train loss: 0.0660767853
Epoch:   900  |  train loss: 0.0660767868
Epoch:  1000  |  train loss: 0.0660767853
Epoch:  1100  |  train loss: 0.0660767868
Epoch:  1200  |  train loss: 0.0660767883
Epoch:  1300  |  train loss: 0.0660767883
Epoch:  1400  |  train loss: 0.0660767838
Epoch:  1500  |  train loss: 0.0660767898
Epoch:  1600  |  train loss: 0.0660767853
Epoch:  1700  |  train loss: 0.0660767868
Epoch:  1800  |  train loss: 0.0660767883
Epoch:  1900  |  train loss: 0.0660767868
Epoch:  2000  |  train loss: 0.0660767868
Processing class: 74
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0654946953
Epoch:   200  |  train loss: 0.0654947013
Epoch:   300  |  train loss: 0.0654947013
Epoch:   400  |  train loss: 0.0654946998
Epoch:   500  |  train loss: 0.0654947013
Epoch:   600  |  train loss: 0.0654947013
Epoch:   700  |  train loss: 0.0654946998
Epoch:   800  |  train loss: 0.0654947028
Epoch:   900  |  train loss: 0.0654946983
Epoch:  1000  |  train loss: 0.0654946998
Epoch:  1100  |  train loss: 0.0654946998
Epoch:  1200  |  train loss: 0.0654947013
Epoch:  1300  |  train loss: 0.0654946990
Epoch:  1400  |  train loss: 0.0654947013
Epoch:  1500  |  train loss: 0.0654947028
Epoch:  1600  |  train loss: 0.0654947028
Epoch:  1700  |  train loss: 0.0654947028
Epoch:  1800  |  train loss: 0.0654946998
Epoch:  1900  |  train loss: 0.0654947013
Epoch:  2000  |  train loss: 0.0654946998
Processing class: 75
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 76
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657849610
Epoch:   200  |  train loss: 0.0657849625
Epoch:   300  |  train loss: 0.0657849610
Epoch:   400  |  train loss: 0.0657849640
Epoch:   500  |  train loss: 0.0657849610
Epoch:   600  |  train loss: 0.0657849640
Epoch:   700  |  train loss: 0.0657849610
Epoch:   800  |  train loss: 0.0657849625
Epoch:   900  |  train loss: 0.0657849625
Epoch:  1000  |  train loss: 0.0657849640
Epoch:  1100  |  train loss: 0.0657849640
Epoch:  1200  |  train loss: 0.0657849625
Epoch:  1300  |  train loss: 0.0657849625
Epoch:  1400  |  train loss: 0.0657849595
Epoch:  1500  |  train loss: 0.0657849625
Epoch:  1600  |  train loss: 0.0657849655
Epoch:  1700  |  train loss: 0.0657849640
Epoch:  1800  |  train loss: 0.0657849625
Epoch:  1900  |  train loss: 0.0657849610
Epoch:  2000  |  train loss: 0.0657849625
Processing class: 77
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 78
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655812338
Epoch:   200  |  train loss: 0.0655812323
Epoch:   300  |  train loss: 0.0655812338
Epoch:   400  |  train loss: 0.0655812338
Epoch:   500  |  train loss: 0.0655812323
Epoch:   600  |  train loss: 0.0655812353
Epoch:   700  |  train loss: 0.0655812353
Epoch:   800  |  train loss: 0.0655812353
Epoch:   900  |  train loss: 0.0655812338
Epoch:  1000  |  train loss: 0.0655812338
Epoch:  1100  |  train loss: 0.0655812353
Epoch:  1200  |  train loss: 0.0655812323
Epoch:  1300  |  train loss: 0.0655812323
Epoch:  1400  |  train loss: 0.0655812398
Epoch:  1500  |  train loss: 0.0655812353
Epoch:  1600  |  train loss: 0.0655812338
Epoch:  1700  |  train loss: 0.0655812338
Epoch:  1800  |  train loss: 0.0655812353
Epoch:  1900  |  train loss: 0.0655812353
Epoch:  2000  |  train loss: 0.0655812323
Processing class: 79
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657932222
Epoch:   200  |  train loss: 0.0657932222
Epoch:   300  |  train loss: 0.0657932207
Epoch:   400  |  train loss: 0.0657932222
Epoch:   500  |  train loss: 0.0657932214
Epoch:   600  |  train loss: 0.0657932252
Epoch:   700  |  train loss: 0.0657932222
Epoch:   800  |  train loss: 0.0657932237
Epoch:   900  |  train loss: 0.0657932207
Epoch:  1000  |  train loss: 0.0657932222
Epoch:  1100  |  train loss: 0.0657932222
Epoch:  1200  |  train loss: 0.0657932222
Epoch:  1300  |  train loss: 0.0657932237
Epoch:  1400  |  train loss: 0.0657932237
Epoch:  1500  |  train loss: 0.0657932222
Epoch:  1600  |  train loss: 0.0657932192
Epoch:  1700  |  train loss: 0.0657932237
Epoch:  1800  |  train loss: 0.0657932222
Epoch:  1900  |  train loss: 0.0657932237
Epoch:  2000  |  train loss: 0.0657932207
Clasifying using reconstruction function cost
2024-04-01 13:10:21,015 [trainer.py] => CNN: {'total': 59.18, '00-09': 73.6, '10-19': 68.4, '20-29': 76.9, '30-39': 69.1, '40-49': 60.6, '50-59': 37.2, '60-69': 45.7, '70-79': 41.9, 'old': 61.64, 'new': 41.9}
2024-04-01 13:10:21,016 [trainer.py] => No NME accuracy
2024-04-01 13:10:21,016 [trainer.py] => FeCAM: {'total': 40.29, '00-09': 65.5, '10-19': 53.2, '20-29': 62.9, '30-39': 52.7, '40-49': 55.4, '50-59': 9.9, '60-69': 14.1, '70-79': 8.6, 'old': 44.81, 'new': 8.6}
2024-04-01 13:10:21,016 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18]
2024-04-01 13:10:21,016 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09]
2024-04-01 13:10:21,016 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.44, 40.29]
2024-04-01 13:10:21,016 [trainer.py] => FeCAM top5 curve: [86.38, 79.3, 72.56, 66.68]

2024-04-01 13:10:21,020 [fecam.py] => Learning on 80-90
Processing class: 80
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0646934047
Epoch:   200  |  train loss: 0.0646934077
Epoch:   300  |  train loss: 0.0646934085
Epoch:   400  |  train loss: 0.0646934062
Epoch:   500  |  train loss: 0.0646934092
Epoch:   600  |  train loss: 0.0646934062
Epoch:   700  |  train loss: 0.0646934077
Epoch:   800  |  train loss: 0.0646934085
Epoch:   900  |  train loss: 0.0646934122
Epoch:  1000  |  train loss: 0.0646934107
Epoch:  1100  |  train loss: 0.0646934062
Epoch:  1200  |  train loss: 0.0646934077
Epoch:  1300  |  train loss: 0.0646934077
Epoch:  1400  |  train loss: 0.0646934099
Epoch:  1500  |  train loss: 0.0646934047
Epoch:  1600  |  train loss: 0.0646934077
Epoch:  1700  |  train loss: 0.0646934107
Epoch:  1800  |  train loss: 0.0646934077
Epoch:  1900  |  train loss: 0.0646934107
Epoch:  2000  |  train loss: 0.0646934085
Processing class: 81
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657470569
Epoch:   200  |  train loss: 0.0657470554
Epoch:   300  |  train loss: 0.0657470539
Epoch:   400  |  train loss: 0.0657470569
Epoch:   500  |  train loss: 0.0657470554
Epoch:   600  |  train loss: 0.0657470539
Epoch:   700  |  train loss: 0.0657470569
Epoch:   800  |  train loss: 0.0657470569
Epoch:   900  |  train loss: 0.0657470524
Epoch:  1000  |  train loss: 0.0657470554
Epoch:  1100  |  train loss: 0.0657470584
Epoch:  1200  |  train loss: 0.0657470539
Epoch:  1300  |  train loss: 0.0657470524
Epoch:  1400  |  train loss: 0.0657470584
Epoch:  1500  |  train loss: 0.0657470569
Epoch:  1600  |  train loss: 0.0657470554
Epoch:  1700  |  train loss: 0.0657470569
Epoch:  1800  |  train loss: 0.0657470584
Epoch:  1900  |  train loss: 0.0657470554
Epoch:  2000  |  train loss: 0.0657470554
Processing class: 82
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0653498799
Epoch:   200  |  train loss: 0.0653498776
Epoch:   300  |  train loss: 0.0653498806
Epoch:   400  |  train loss: 0.0653498784
Epoch:   500  |  train loss: 0.0653498799
Epoch:   600  |  train loss: 0.0653498784
Epoch:   700  |  train loss: 0.0653498799
Epoch:   800  |  train loss: 0.0653498784
Epoch:   900  |  train loss: 0.0653498784
Epoch:  1000  |  train loss: 0.0653498814
Epoch:  1100  |  train loss: 0.0653498814
Epoch:  1200  |  train loss: 0.0653498769
Epoch:  1300  |  train loss: 0.0653498784
Epoch:  1400  |  train loss: 0.0653498784
Epoch:  1500  |  train loss: 0.0653498828
Epoch:  1600  |  train loss: 0.0653498784
Epoch:  1700  |  train loss: 0.0653498814
Epoch:  1800  |  train loss: 0.0653498784
Epoch:  1900  |  train loss: 0.0653498784
Epoch:  2000  |  train loss: 0.0653498784
Processing class: 83
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0657953665
Epoch:   200  |  train loss: 0.0657953665
Epoch:   300  |  train loss: 0.0657953694
Epoch:   400  |  train loss: 0.0657953709
Epoch:   500  |  train loss: 0.0657953694
Epoch:   600  |  train loss: 0.0657953680
Epoch:   700  |  train loss: 0.0657953694
Epoch:   800  |  train loss: 0.0657953680
Epoch:   900  |  train loss: 0.0657953709
Epoch:  1000  |  train loss: 0.0657953709
Epoch:  1100  |  train loss: 0.0657953709
Epoch:  1200  |  train loss: 0.0657953694
Epoch:  1300  |  train loss: 0.0657953665
Epoch:  1400  |  train loss: 0.0657953739
Epoch:  1500  |  train loss: 0.0657953709
Epoch:  1600  |  train loss: 0.0657953665
Epoch:  1700  |  train loss: 0.0657953724
Epoch:  1800  |  train loss: 0.0657953694
Epoch:  1900  |  train loss: 0.0657953680
Epoch:  2000  |  train loss: 0.0657953709
Processing class: 84
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0658797890
Epoch:   200  |  train loss: 0.0658797875
Epoch:   300  |  train loss: 0.0658797875
Epoch:   400  |  train loss: 0.0658797860
Epoch:   500  |  train loss: 0.0658797890
Epoch:   600  |  train loss: 0.0658797890
Epoch:   700  |  train loss: 0.0658797905
Epoch:   800  |  train loss: 0.0658797905
Epoch:   900  |  train loss: 0.0658797875
Epoch:  1000  |  train loss: 0.0658797890
Epoch:  1100  |  train loss: 0.0658797890
Epoch:  1200  |  train loss: 0.0658797890
Epoch:  1300  |  train loss: 0.0658797860
Epoch:  1400  |  train loss: 0.0658797860
Epoch:  1500  |  train loss: 0.0658797920
Epoch:  1600  |  train loss: 0.0658797875
Epoch:  1700  |  train loss: 0.0658797920
Epoch:  1800  |  train loss: 0.0658797875
Epoch:  1900  |  train loss: 0.0658797845
Epoch:  2000  |  train loss: 0.0658797875
Processing class: 85
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0639317870
Epoch:   200  |  train loss: 0.0639317863
Epoch:   300  |  train loss: 0.0639317937
Epoch:   400  |  train loss: 0.0639317907
Epoch:   500  |  train loss: 0.0639317892
Epoch:   600  |  train loss: 0.0639317885
Epoch:   700  |  train loss: 0.0639317900
Epoch:   800  |  train loss: 0.0639317900
Epoch:   900  |  train loss: 0.0639317892
Epoch:  1000  |  train loss: 0.0639317907
Epoch:  1100  |  train loss: 0.0639317892
Epoch:  1200  |  train loss: 0.0639317900
Epoch:  1300  |  train loss: 0.0639317885
Epoch:  1400  |  train loss: 0.0639317907
Epoch:  1500  |  train loss: 0.0639317900
Epoch:  1600  |  train loss: 0.0639317900
Epoch:  1700  |  train loss: 0.0639317937
Epoch:  1800  |  train loss: 0.0639317907
Epoch:  1900  |  train loss: 0.0639317870
Epoch:  2000  |  train loss: 0.0639317915
Processing class: 86
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661502138
Epoch:   200  |  train loss: 0.0661502138
Epoch:   300  |  train loss: 0.0661502168
Epoch:   400  |  train loss: 0.0661502160
Epoch:   500  |  train loss: 0.0661502175
Epoch:   600  |  train loss: 0.0661502153
Epoch:   700  |  train loss: 0.0661502168
Epoch:   800  |  train loss: 0.0661502168
Epoch:   900  |  train loss: 0.0661502138
Epoch:  1000  |  train loss: 0.0661502168
Epoch:  1100  |  train loss: 0.0661502153
Epoch:  1200  |  train loss: 0.0661502182
Epoch:  1300  |  train loss: 0.0661502138
Epoch:  1400  |  train loss: 0.0661502138
Epoch:  1500  |  train loss: 0.0661502168
Epoch:  1600  |  train loss: 0.0661502168
Epoch:  1700  |  train loss: 0.0661502153
Epoch:  1800  |  train loss: 0.0661502138
Epoch:  1900  |  train loss: 0.0661502153
Epoch:  2000  |  train loss: 0.0661502123
Processing class: 87
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0661837682
Epoch:   200  |  train loss: 0.0661837652
Epoch:   300  |  train loss: 0.0661837652
Epoch:   400  |  train loss: 0.0661837682
Epoch:   500  |  train loss: 0.0661837667
Epoch:   600  |  train loss: 0.0661837682
Epoch:   700  |  train loss: 0.0661837667
Epoch:   800  |  train loss: 0.0661837623
Epoch:   900  |  train loss: 0.0661837652
Epoch:  1000  |  train loss: 0.0661837682
Epoch:  1100  |  train loss: 0.0661837637
Epoch:  1200  |  train loss: 0.0661837652
Epoch:  1300  |  train loss: 0.0661837652
Epoch:  1400  |  train loss: 0.0661837652
Epoch:  1500  |  train loss: 0.0661837637
Epoch:  1600  |  train loss: 0.0661837652
Epoch:  1700  |  train loss: 0.0661837637
Epoch:  1800  |  train loss: 0.0661837652
Epoch:  1900  |  train loss: 0.0661837637
Epoch:  2000  |  train loss: 0.0661837652
Processing class: 88
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655639410
Epoch:   200  |  train loss: 0.0655639410
Epoch:   300  |  train loss: 0.0655639410
Epoch:   400  |  train loss: 0.0655639410
Epoch:   500  |  train loss: 0.0655639440
Epoch:   600  |  train loss: 0.0655639365
Epoch:   700  |  train loss: 0.0655639380
Epoch:   800  |  train loss: 0.0655639395
Epoch:   900  |  train loss: 0.0655639380
Epoch:  1000  |  train loss: 0.0655639395
Epoch:  1100  |  train loss: 0.0655639395
Epoch:  1200  |  train loss: 0.0655639380
Epoch:  1300  |  train loss: 0.0655639395
Epoch:  1400  |  train loss: 0.0655639395
Epoch:  1500  |  train loss: 0.0655639380
Epoch:  1600  |  train loss: 0.0655639373
Epoch:  1700  |  train loss: 0.0655639395
Epoch:  1800  |  train loss: 0.0655639373
Epoch:  1900  |  train loss: 0.0655639410
Epoch:  2000  |  train loss: 0.0655639380
Processing class: 89
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662781045
Epoch:   200  |  train loss: 0.0662781104
Epoch:   300  |  train loss: 0.0662781104
Epoch:   400  |  train loss: 0.0662781090
Epoch:   500  |  train loss: 0.0662781090
Epoch:   600  |  train loss: 0.0662781075
Epoch:   700  |  train loss: 0.0662781075
Epoch:   800  |  train loss: 0.0662781090
Epoch:   900  |  train loss: 0.0662781090
Epoch:  1000  |  train loss: 0.0662781104
Epoch:  1100  |  train loss: 0.0662781119
Epoch:  1200  |  train loss: 0.0662781090
Epoch:  1300  |  train loss: 0.0662781045
Epoch:  1400  |  train loss: 0.0662781075
Epoch:  1500  |  train loss: 0.0662781090
Epoch:  1600  |  train loss: 0.0662781090
Epoch:  1700  |  train loss: 0.0662781075
Epoch:  1800  |  train loss: 0.0662781104
Epoch:  1900  |  train loss: 0.0662781090
Epoch:  2000  |  train loss: 0.0662781090
Clasifying using reconstruction function cost
2024-04-01 14:13:55,155 [trainer.py] => CNN: {'total': 54.08, '00-09': 67.9, '10-19': 63.6, '20-29': 73.2, '30-39': 68.8, '40-49': 57.2, '50-59': 32.6, '60-69': 40.9, '70-79': 38.1, '80-89': 44.4, 'old': 55.29, 'new': 44.4}
2024-04-01 14:13:55,156 [trainer.py] => No NME accuracy
2024-04-01 14:13:55,156 [trainer.py] => FeCAM: {'total': 36.13, '00-09': 64.8, '10-19': 51.2, '20-29': 61.8, '30-39': 52.6, '40-49': 54.5, '50-59': 9.4, '60-69': 13.1, '70-79': 8.3, '80-89': 9.5, 'old': 39.46, 'new': 9.5}
2024-04-01 14:13:55,156 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08]
2024-04-01 14:13:55,156 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74]
2024-04-01 14:13:55,156 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.44, 40.29, 36.13]
2024-04-01 14:13:55,156 [trainer.py] => FeCAM top5 curve: [86.38, 79.3, 72.56, 66.68, 62.8]

2024-04-01 14:13:55,160 [fecam.py] => Learning on 90-100
Processing class: 90
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0650899500
Epoch:   200  |  train loss: 0.0650899544
Epoch:   300  |  train loss: 0.0650899529
Epoch:   400  |  train loss: 0.0650899515
Epoch:   500  |  train loss: 0.0650899515
Epoch:   600  |  train loss: 0.0650899492
Epoch:   700  |  train loss: 0.0650899500
Epoch:   800  |  train loss: 0.0650899544
Epoch:   900  |  train loss: 0.0650899529
Epoch:  1000  |  train loss: 0.0650899529
Epoch:  1100  |  train loss: 0.0650899500
Epoch:  1200  |  train loss: 0.0650899544
Epoch:  1300  |  train loss: 0.0650899470
Epoch:  1400  |  train loss: 0.0650899515
Epoch:  1500  |  train loss: 0.0650899470
Epoch:  1600  |  train loss: 0.0650899529
Epoch:  1700  |  train loss: 0.0650899500
Epoch:  1800  |  train loss: 0.0650899515
Epoch:  1900  |  train loss: 0.0650899529
Epoch:  2000  |  train loss: 0.0650899485
Processing class: 91
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0662350282
Epoch:   200  |  train loss: 0.0662350267
Epoch:   300  |  train loss: 0.0662350275
Epoch:   400  |  train loss: 0.0662350282
Epoch:   500  |  train loss: 0.0662350282
Epoch:   600  |  train loss: 0.0662350297
Epoch:   700  |  train loss: 0.0662350267
Epoch:   800  |  train loss: 0.0662350297
Epoch:   900  |  train loss: 0.0662350297
Epoch:  1000  |  train loss: 0.0662350267
Epoch:  1100  |  train loss: 0.0662350297
Epoch:  1200  |  train loss: 0.0662350297
Epoch:  1300  |  train loss: 0.0662350237
Epoch:  1400  |  train loss: 0.0662350282
Epoch:  1500  |  train loss: 0.0662350267
Epoch:  1600  |  train loss: 0.0662350252
Epoch:  1700  |  train loss: 0.0662350275
Epoch:  1800  |  train loss: 0.0662350267
Epoch:  1900  |  train loss: 0.0662350297
Epoch:  2000  |  train loss: 0.0662350252
Processing class: 92
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0654302567
Epoch:   200  |  train loss: 0.0654302582
Epoch:   300  |  train loss: 0.0654302582
Epoch:   400  |  train loss: 0.0654302597
Epoch:   500  |  train loss: 0.0654302597
Epoch:   600  |  train loss: 0.0654302567
Epoch:   700  |  train loss: 0.0654302627
Epoch:   800  |  train loss: 0.0654302567
Epoch:   900  |  train loss: 0.0654302627
Epoch:  1000  |  train loss: 0.0654302582
Epoch:  1100  |  train loss: 0.0654302582
Epoch:  1200  |  train loss: 0.0654302612
Epoch:  1300  |  train loss: 0.0654302597
Epoch:  1400  |  train loss: 0.0654302590
Epoch:  1500  |  train loss: 0.0654302627
Epoch:  1600  |  train loss: 0.0654302627
Epoch:  1700  |  train loss: 0.0654302597
Epoch:  1800  |  train loss: 0.0654302597
Epoch:  1900  |  train loss: 0.0654302567
Epoch:  2000  |  train loss: 0.0654302612
Processing class: 93
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0660562322
Epoch:   200  |  train loss: 0.0660562307
Epoch:   300  |  train loss: 0.0660562307
Epoch:   400  |  train loss: 0.0660562322
Epoch:   500  |  train loss: 0.0660562299
Epoch:   600  |  train loss: 0.0660562307
Epoch:   700  |  train loss: 0.0660562307
Epoch:   800  |  train loss: 0.0660562292
Epoch:   900  |  train loss: 0.0660562277
Epoch:  1000  |  train loss: 0.0660562336
Epoch:  1100  |  train loss: 0.0660562307
Epoch:  1200  |  train loss: 0.0660562336
Epoch:  1300  |  train loss: 0.0660562292
Epoch:  1400  |  train loss: 0.0660562292
Epoch:  1500  |  train loss: 0.0660562277
Epoch:  1600  |  train loss: 0.0660562322
Epoch:  1700  |  train loss: 0.0660562262
Epoch:  1800  |  train loss: 0.0660562322
Epoch:  1900  |  train loss: 0.0660562322
Epoch:  2000  |  train loss: 0.0660562292
Processing class: 94
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0642108165
Epoch:   200  |  train loss: 0.0642108209
Epoch:   300  |  train loss: 0.0642108187
Epoch:   400  |  train loss: 0.0642108165
Epoch:   500  |  train loss: 0.0642108165
Epoch:   600  |  train loss: 0.0642108195
Epoch:   700  |  train loss: 0.0642108187
Epoch:   800  |  train loss: 0.0642108187
Epoch:   900  |  train loss: 0.0642108157
Epoch:  1000  |  train loss: 0.0642108172
Epoch:  1100  |  train loss: 0.0642108195
Epoch:  1200  |  train loss: 0.0642108180
Epoch:  1300  |  train loss: 0.0642108187
Epoch:  1400  |  train loss: 0.0642108202
Epoch:  1500  |  train loss: 0.0642108202
Epoch:  1600  |  train loss: 0.0642108142
Epoch:  1700  |  train loss: 0.0642108180
Epoch:  1800  |  train loss: 0.0642108165
Epoch:  1900  |  train loss: 0.0642108195
Epoch:  2000  |  train loss: 0.0642108202
Processing class: 95
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0656794235
Epoch:   200  |  train loss: 0.0656794295
Epoch:   300  |  train loss: 0.0656794265
Epoch:   400  |  train loss: 0.0656794220
Epoch:   500  |  train loss: 0.0656794250
Epoch:   600  |  train loss: 0.0656794235
Epoch:   700  |  train loss: 0.0656794235
Epoch:   800  |  train loss: 0.0656794265
Epoch:   900  |  train loss: 0.0656794205
Epoch:  1000  |  train loss: 0.0656794220
Epoch:  1100  |  train loss: 0.0656794257
Epoch:  1200  |  train loss: 0.0656794235
Epoch:  1300  |  train loss: 0.0656794228
Epoch:  1400  |  train loss: 0.0656794250
Epoch:  1500  |  train loss: 0.0656794250
Epoch:  1600  |  train loss: 0.0656794235
Epoch:  1700  |  train loss: 0.0656794250
Epoch:  1800  |  train loss: 0.0656794220
Epoch:  1900  |  train loss: 0.0656794235
Epoch:  2000  |  train loss: 0.0656794220
Processing class: 96
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0656475604
Epoch:   200  |  train loss: 0.0656475589
Epoch:   300  |  train loss: 0.0656475574
Epoch:   400  |  train loss: 0.0656475559
Epoch:   500  |  train loss: 0.0656475589
Epoch:   600  |  train loss: 0.0656475559
Epoch:   700  |  train loss: 0.0656475544
Epoch:   800  |  train loss: 0.0656475559
Epoch:   900  |  train loss: 0.0656475574
Epoch:  1000  |  train loss: 0.0656475574
Epoch:  1100  |  train loss: 0.0656475559
Epoch:  1200  |  train loss: 0.0656475559
Epoch:  1300  |  train loss: 0.0656475574
Epoch:  1400  |  train loss: 0.0656475529
Epoch:  1500  |  train loss: 0.0656475559
Epoch:  1600  |  train loss: 0.0656475529
Epoch:  1700  |  train loss: 0.0656475574
Epoch:  1800  |  train loss: 0.0656475559
Epoch:  1900  |  train loss: 0.0656475589
Epoch:  2000  |  train loss: 0.0656475574
Processing class: 97
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0635464504
Epoch:   200  |  train loss: 0.0635464475
Epoch:   300  |  train loss: 0.0635464467
Epoch:   400  |  train loss: 0.0635464489
Epoch:   500  |  train loss: 0.0635464467
Epoch:   600  |  train loss: 0.0635464489
Epoch:   700  |  train loss: 0.0635464527
Epoch:   800  |  train loss: 0.0635464512
Epoch:   900  |  train loss: 0.0635464504
Epoch:  1000  |  train loss: 0.0635464504
Epoch:  1100  |  train loss: 0.0635464482
Epoch:  1200  |  train loss: 0.0635464475
Epoch:  1300  |  train loss: 0.0635464460
Epoch:  1400  |  train loss: 0.0635464489
Epoch:  1500  |  train loss: 0.0635464497
Epoch:  1600  |  train loss: 0.0635464460
Epoch:  1700  |  train loss: 0.0635464519
Epoch:  1800  |  train loss: 0.0635464475
Epoch:  1900  |  train loss: 0.0635464475
Epoch:  2000  |  train loss: 0.0635464467
Processing class: 98
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 99
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0655389026
Epoch:   200  |  train loss: 0.0655388981
Epoch:   300  |  train loss: 0.0655388996
Epoch:   400  |  train loss: 0.0655389041
Epoch:   500  |  train loss: 0.0655389011
Epoch:   600  |  train loss: 0.0655388996
Epoch:   700  |  train loss: 0.0655389026
Epoch:   800  |  train loss: 0.0655388996
Epoch:   900  |  train loss: 0.0655388996
Epoch:  1000  |  train loss: 0.0655389026
Epoch:  1100  |  train loss: 0.0655388996
Epoch:  1200  |  train loss: 0.0655389041
Epoch:  1300  |  train loss: 0.0655388996
Epoch:  1400  |  train loss: 0.0655389011
Epoch:  1500  |  train loss: 0.0655388981
Epoch:  1600  |  train loss: 0.0655389011
Epoch:  1700  |  train loss: 0.0655389026
Epoch:  1800  |  train loss: 0.0655388996
Epoch:  1900  |  train loss: 0.0655389026
Epoch:  2000  |  train loss: 0.0655388996
Clasifying using reconstruction function cost
2024-04-01 15:19:44,130 [trainer.py] => CNN: {'total': 50.36, '00-09': 57.7, '10-19': 63.6, '20-29': 71.4, '30-39': 68.5, '40-49': 56.8, '50-59': 29.6, '60-69': 38.9, '70-79': 36.6, '80-89': 42.7, '90-99': 37.8, 'old': 51.76, 'new': 37.8}
2024-04-01 15:19:44,144 [trainer.py] => No NME accuracy
2024-04-01 15:19:44,144 [trainer.py] => FeCAM: {'total': 31.68, '00-09': 62.1, '10-19': 48.6, '20-29': 59.9, '30-39': 50.0, '40-49': 53.3, '50-59': 8.5, '60-69': 11.6, '70-79': 6.9, '80-89': 8.4, '90-99': 7.5, 'old': 34.37, 'new': 7.5}
2024-04-01 15:19:44,144 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08, 50.36]
2024-04-01 15:19:44,144 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74, 79.63]
2024-04-01 15:19:44,144 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.44, 40.29, 36.13, 31.68]
2024-04-01 15:19:44,144 [trainer.py] => FeCAM top5 curve: [86.38, 79.3, 72.56, 66.68, 62.8, 58.69]

=========================================
2024-04-01 15:19:51,531 [trainer.py] => config: ./exps/FeCAM_cifar100.json
2024-04-01 15:19:51,531 [trainer.py] => prefix: train
2024-04-01 15:19:51,531 [trainer.py] => dataset: cifar100
2024-04-01 15:19:51,531 [trainer.py] => memory_size: 0
2024-04-01 15:19:51,531 [trainer.py] => shuffle: True
2024-04-01 15:19:51,531 [trainer.py] => init_cls: 50
2024-04-01 15:19:51,531 [trainer.py] => increment: 10
2024-04-01 15:19:51,531 [trainer.py] => model_name: fecam
2024-04-01 15:19:51,531 [trainer.py] => convnet_type: resnet18
2024-04-01 15:19:51,531 [trainer.py] => device: [device(type='cuda', index=0)]
2024-04-01 15:19:51,531 [trainer.py] => seed: 1993
2024-04-01 15:19:51,531 [trainer.py] => init_epochs: 200
2024-04-01 15:19:51,531 [trainer.py] => init_lr: 0.1
2024-04-01 15:19:51,531 [trainer.py] => init_weight_decay: 0.0005
2024-04-01 15:19:51,531 [trainer.py] => batch_size: 128
2024-04-01 15:19:51,531 [trainer.py] => num_workers: 8
2024-04-01 15:19:51,531 [trainer.py] => T: 5
2024-04-01 15:19:51,531 [trainer.py] => beta: 0.5
2024-04-01 15:19:51,531 [trainer.py] => alpha1: 1
2024-04-01 15:19:51,531 [trainer.py] => alpha2: 1
2024-04-01 15:19:51,531 [trainer.py] => ncm: False
2024-04-01 15:19:51,531 [trainer.py] => tukey: False
2024-04-01 15:19:51,531 [trainer.py] => diagonal: False
2024-04-01 15:19:51,531 [trainer.py] => per_class: True
2024-04-01 15:19:51,531 [trainer.py] => full_cov: True
2024-04-01 15:19:51,531 [trainer.py] => shrink: True
2024-04-01 15:19:51,531 [trainer.py] => norm_cov: False
2024-04-01 15:19:51,531 [trainer.py] => epochs: 2000
2024-04-01 15:19:51,531 [trainer.py] => vecnorm: False
2024-04-01 15:19:51,531 [trainer.py] => ae_type: ae
2024-04-01 15:19:51,531 [trainer.py] => ae_latent_dim: 32
2024-04-01 15:19:51,531 [trainer.py] => ae_n: 1
2024-04-01 15:19:51,531 [trainer.py] => wae_sigma: 10
2024-04-01 15:19:51,531 [trainer.py] => wae_C: 0.1
2024-04-01 15:19:51,531 [trainer.py] => ae_standarization: False
2024-04-01 15:19:51,531 [trainer.py] => ae_pca: False
2024-04-01 15:19:51,532 [trainer.py] => ae_pca_components: 500
2024-04-01 15:19:51,532 [trainer.py] => ae_clsf: maha-recon-cost
2024-04-01 15:19:51,532 [trainer.py] => maha_alpha: 0.01
2024-04-01 15:19:51,532 [trainer.py] => maha_beta: 0.1
Files already downloaded and verified
Files already downloaded and verified
2024-04-01 15:19:53,229 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-04-01 15:19:53,492 [fecam.py] => Learning on 0-50
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Processing class: 0
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0786456436
Epoch:   200  |  train loss: 0.0786456436
Epoch:   300  |  train loss: 0.0786456436
Epoch:   400  |  train loss: 0.0786456421
Epoch:   500  |  train loss: 0.0786456436
Epoch:   600  |  train loss: 0.0786456421
Epoch:   700  |  train loss: 0.0786456451
Epoch:   800  |  train loss: 0.0786456451
Epoch:   900  |  train loss: 0.0786456406
Epoch:  1000  |  train loss: 0.0786456421
Epoch:  1100  |  train loss: 0.0786456436
Epoch:  1200  |  train loss: 0.0786456421
Epoch:  1300  |  train loss: 0.0786456466
Epoch:  1400  |  train loss: 0.0786456466
Epoch:  1500  |  train loss: 0.0786456436
Epoch:  1600  |  train loss: 0.0786456436
Epoch:  1700  |  train loss: 0.0786456406
Epoch:  1800  |  train loss: 0.0786456496
Epoch:  1900  |  train loss: 0.0786456451
Epoch:  2000  |  train loss: 0.0786456481
Processing class: 1
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0781416386
Epoch:   200  |  train loss: 0.0781416342
Epoch:   300  |  train loss: 0.0781416371
Epoch:   400  |  train loss: 0.0781416386
Epoch:   500  |  train loss: 0.0781416327
Epoch:   600  |  train loss: 0.0781416371
Epoch:   700  |  train loss: 0.0781416401
Epoch:   800  |  train loss: 0.0781416416
Epoch:   900  |  train loss: 0.0781416357
Epoch:  1000  |  train loss: 0.0781416371
Epoch:  1100  |  train loss: 0.0781416401
Epoch:  1200  |  train loss: 0.0781416401
Epoch:  1300  |  train loss: 0.0781416371
Epoch:  1400  |  train loss: 0.0781416401
Epoch:  1500  |  train loss: 0.0781416357
Epoch:  1600  |  train loss: 0.0781416371
Epoch:  1700  |  train loss: 0.0781416357
Epoch:  1800  |  train loss: 0.0781416386
Epoch:  1900  |  train loss: 0.0781416371
Epoch:  2000  |  train loss: 0.0781416386
Processing class: 2
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0753372461
Epoch:   200  |  train loss: 0.0753372476
Epoch:   300  |  train loss: 0.0753372446
Epoch:   400  |  train loss: 0.0753372446
Epoch:   500  |  train loss: 0.0753372490
Epoch:   600  |  train loss: 0.0753372490
Epoch:   700  |  train loss: 0.0753372476
Epoch:   800  |  train loss: 0.0753372476
Epoch:   900  |  train loss: 0.0753372446
Epoch:  1000  |  train loss: 0.0753372446
Epoch:  1100  |  train loss: 0.0753372476
Epoch:  1200  |  train loss: 0.0753372416
Epoch:  1300  |  train loss: 0.0753372431
Epoch:  1400  |  train loss: 0.0753372446
Epoch:  1500  |  train loss: 0.0753372476
Epoch:  1600  |  train loss: 0.0753372461
Epoch:  1700  |  train loss: 0.0753372461
Epoch:  1800  |  train loss: 0.0753372461
Epoch:  1900  |  train loss: 0.0753372431
Epoch:  2000  |  train loss: 0.0753372476
Processing class: 3
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783782169
Epoch:   200  |  train loss: 0.0783782139
Epoch:   300  |  train loss: 0.0783782184
Epoch:   400  |  train loss: 0.0783782154
Epoch:   500  |  train loss: 0.0783782125
Epoch:   600  |  train loss: 0.0783782154
Epoch:   700  |  train loss: 0.0783782110
Epoch:   800  |  train loss: 0.0783782169
Epoch:   900  |  train loss: 0.0783782169
Epoch:  1000  |  train loss: 0.0783782139
Epoch:  1100  |  train loss: 0.0783782125
Epoch:  1200  |  train loss: 0.0783782154
Epoch:  1300  |  train loss: 0.0783782125
Epoch:  1400  |  train loss: 0.0783782139
Epoch:  1500  |  train loss: 0.0783782154
Epoch:  1600  |  train loss: 0.0783782154
Epoch:  1700  |  train loss: 0.0783782139
Epoch:  1800  |  train loss: 0.0783782169
Epoch:  1900  |  train loss: 0.0783782214
Epoch:  2000  |  train loss: 0.0783782110
Processing class: 4
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0779783800
Epoch:   200  |  train loss: 0.0779783800
Epoch:   300  |  train loss: 0.0779783830
Epoch:   400  |  train loss: 0.0779783815
Epoch:   500  |  train loss: 0.0779783815
Epoch:   600  |  train loss: 0.0779783800
Epoch:   700  |  train loss: 0.0779783815
Epoch:   800  |  train loss: 0.0779783815
Epoch:   900  |  train loss: 0.0779783800
Epoch:  1000  |  train loss: 0.0779783815
Epoch:  1100  |  train loss: 0.0779783830
Epoch:  1200  |  train loss: 0.0779783785
Epoch:  1300  |  train loss: 0.0779783815
Epoch:  1400  |  train loss: 0.0779783815
Epoch:  1500  |  train loss: 0.0779783815
Epoch:  1600  |  train loss: 0.0779783815
Epoch:  1700  |  train loss: 0.0779783785
Epoch:  1800  |  train loss: 0.0779783785
Epoch:  1900  |  train loss: 0.0779783830
Epoch:  2000  |  train loss: 0.0779783770
Processing class: 5
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 6
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783349216
Epoch:   200  |  train loss: 0.0783349216
Epoch:   300  |  train loss: 0.0783349201
Epoch:   400  |  train loss: 0.0783349201
Epoch:   500  |  train loss: 0.0783349201
Epoch:   600  |  train loss: 0.0783349186
Epoch:   700  |  train loss: 0.0783349186
Epoch:   800  |  train loss: 0.0783349231
Epoch:   900  |  train loss: 0.0783349171
Epoch:  1000  |  train loss: 0.0783349216
Epoch:  1100  |  train loss: 0.0783349186
Epoch:  1200  |  train loss: 0.0783349216
Epoch:  1300  |  train loss: 0.0783349141
Epoch:  1400  |  train loss: 0.0783349216
Epoch:  1500  |  train loss: 0.0783349186
Epoch:  1600  |  train loss: 0.0783349201
Epoch:  1700  |  train loss: 0.0783349201
Epoch:  1800  |  train loss: 0.0783349171
Epoch:  1900  |  train loss: 0.0783349216
Epoch:  2000  |  train loss: 0.0783349186
Processing class: 7
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0785324618
Epoch:   200  |  train loss: 0.0785324603
Epoch:   300  |  train loss: 0.0785324603
Epoch:   400  |  train loss: 0.0785324603
Epoch:   500  |  train loss: 0.0785324603
Epoch:   600  |  train loss: 0.0785324588
Epoch:   700  |  train loss: 0.0785324618
Epoch:   800  |  train loss: 0.0785324618
Epoch:   900  |  train loss: 0.0785324633
Epoch:  1000  |  train loss: 0.0785324603
Epoch:  1100  |  train loss: 0.0785324633
Epoch:  1200  |  train loss: 0.0785324648
Epoch:  1300  |  train loss: 0.0785324603
Epoch:  1400  |  train loss: 0.0785324633
Epoch:  1500  |  train loss: 0.0785324633
Epoch:  1600  |  train loss: 0.0785324618
Epoch:  1700  |  train loss: 0.0785324603
Epoch:  1800  |  train loss: 0.0785324678
Epoch:  1900  |  train loss: 0.0785324633
Epoch:  2000  |  train loss: 0.0785324603
Processing class: 8
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783083588
Epoch:   200  |  train loss: 0.0783083588
Epoch:   300  |  train loss: 0.0783083618
Epoch:   400  |  train loss: 0.0783083633
Epoch:   500  |  train loss: 0.0783083588
Epoch:   600  |  train loss: 0.0783083618
Epoch:   700  |  train loss: 0.0783083603
Epoch:   800  |  train loss: 0.0783083618
Epoch:   900  |  train loss: 0.0783083573
Epoch:  1000  |  train loss: 0.0783083573
Epoch:  1100  |  train loss: 0.0783083618
Epoch:  1200  |  train loss: 0.0783083618
Epoch:  1300  |  train loss: 0.0783083603
Epoch:  1400  |  train loss: 0.0783083633
Epoch:  1500  |  train loss: 0.0783083618
Epoch:  1600  |  train loss: 0.0783083603
Epoch:  1700  |  train loss: 0.0783083588
Epoch:  1800  |  train loss: 0.0783083588
Epoch:  1900  |  train loss: 0.0783083573
Epoch:  2000  |  train loss: 0.0783083588
Processing class: 9
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0763317525
Epoch:   200  |  train loss: 0.0763317496
Epoch:   300  |  train loss: 0.0763317540
Epoch:   400  |  train loss: 0.0763317540
Epoch:   500  |  train loss: 0.0763317525
Epoch:   600  |  train loss: 0.0763317466
Epoch:   700  |  train loss: 0.0763317540
Epoch:   800  |  train loss: 0.0763317466
Epoch:   900  |  train loss: 0.0763317496
Epoch:  1000  |  train loss: 0.0763317510
Epoch:  1100  |  train loss: 0.0763317496
Epoch:  1200  |  train loss: 0.0763317540
Epoch:  1300  |  train loss: 0.0763317496
Epoch:  1400  |  train loss: 0.0763317540
Epoch:  1500  |  train loss: 0.0763317466
Epoch:  1600  |  train loss: 0.0763317496
Epoch:  1700  |  train loss: 0.0763317525
Epoch:  1800  |  train loss: 0.0763317510
Epoch:  1900  |  train loss: 0.0763317466
Epoch:  2000  |  train loss: 0.0763317481
Processing class: 10
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0784645587
Epoch:   200  |  train loss: 0.0784645602
Epoch:   300  |  train loss: 0.0784645602
Epoch:   400  |  train loss: 0.0784645677
Epoch:   500  |  train loss: 0.0784645617
Epoch:   600  |  train loss: 0.0784645587
Epoch:   700  |  train loss: 0.0784645617
Epoch:   800  |  train loss: 0.0784645587
Epoch:   900  |  train loss: 0.0784645587
Epoch:  1000  |  train loss: 0.0784645617
Epoch:  1100  |  train loss: 0.0784645602
Epoch:  1200  |  train loss: 0.0784645602
Epoch:  1300  |  train loss: 0.0784645632
Epoch:  1400  |  train loss: 0.0784645587
Epoch:  1500  |  train loss: 0.0784645587
Epoch:  1600  |  train loss: 0.0784645572
Epoch:  1700  |  train loss: 0.0784645632
Epoch:  1800  |  train loss: 0.0784645602
Epoch:  1900  |  train loss: 0.0784645617
Epoch:  2000  |  train loss: 0.0784645632
Processing class: 11
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783954665
Epoch:   200  |  train loss: 0.0783954635
Epoch:   300  |  train loss: 0.0783954680
Epoch:   400  |  train loss: 0.0783954635
Epoch:   500  |  train loss: 0.0783954650
Epoch:   600  |  train loss: 0.0783954665
Epoch:   700  |  train loss: 0.0783954620
Epoch:   800  |  train loss: 0.0783954665
Epoch:   900  |  train loss: 0.0783954635
Epoch:  1000  |  train loss: 0.0783954620
Epoch:  1100  |  train loss: 0.0783954650
Epoch:  1200  |  train loss: 0.0783954680
Epoch:  1300  |  train loss: 0.0783954635
Epoch:  1400  |  train loss: 0.0783954635
Epoch:  1500  |  train loss: 0.0783954695
Epoch:  1600  |  train loss: 0.0783954650
Epoch:  1700  |  train loss: 0.0783954665
Epoch:  1800  |  train loss: 0.0783954665
Epoch:  1900  |  train loss: 0.0783954680
Epoch:  2000  |  train loss: 0.0783954680
Processing class: 12
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0785634384
Epoch:   200  |  train loss: 0.0785634369
Epoch:   300  |  train loss: 0.0785634369
Epoch:   400  |  train loss: 0.0785634369
Epoch:   500  |  train loss: 0.0785634339
Epoch:   600  |  train loss: 0.0785634354
Epoch:   700  |  train loss: 0.0785634354
Epoch:   800  |  train loss: 0.0785634369
Epoch:   900  |  train loss: 0.0785634354
Epoch:  1000  |  train loss: 0.0785634369
Epoch:  1100  |  train loss: 0.0785634369
Epoch:  1200  |  train loss: 0.0785634369
Epoch:  1300  |  train loss: 0.0785634369
Epoch:  1400  |  train loss: 0.0785634339
Epoch:  1500  |  train loss: 0.0785634339
Epoch:  1600  |  train loss: 0.0785634324
Epoch:  1700  |  train loss: 0.0785634354
Epoch:  1800  |  train loss: 0.0785634324
Epoch:  1900  |  train loss: 0.0785634354
Epoch:  2000  |  train loss: 0.0785634354
Processing class: 13
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778389037
Epoch:   200  |  train loss: 0.0778389037
Epoch:   300  |  train loss: 0.0778389037
Epoch:   400  |  train loss: 0.0778389081
Epoch:   500  |  train loss: 0.0778389037
Epoch:   600  |  train loss: 0.0778389052
Epoch:   700  |  train loss: 0.0778389022
Epoch:   800  |  train loss: 0.0778389022
Epoch:   900  |  train loss: 0.0778389052
Epoch:  1000  |  train loss: 0.0778389096
Epoch:  1100  |  train loss: 0.0778389037
Epoch:  1200  |  train loss: 0.0778389052
Epoch:  1300  |  train loss: 0.0778389066
Epoch:  1400  |  train loss: 0.0778389066
Epoch:  1500  |  train loss: 0.0778389052
Epoch:  1600  |  train loss: 0.0778389052
Epoch:  1700  |  train loss: 0.0778389066
Epoch:  1800  |  train loss: 0.0778389066
Epoch:  1900  |  train loss: 0.0778389052
Epoch:  2000  |  train loss: 0.0778389081
Processing class: 14
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0786389202
Epoch:   200  |  train loss: 0.0786389217
Epoch:   300  |  train loss: 0.0786389202
Epoch:   400  |  train loss: 0.0786389247
Epoch:   500  |  train loss: 0.0786389247
Epoch:   600  |  train loss: 0.0786389232
Epoch:   700  |  train loss: 0.0786389217
Epoch:   800  |  train loss: 0.0786389202
Epoch:   900  |  train loss: 0.0786389247
Epoch:  1000  |  train loss: 0.0786389232
Epoch:  1100  |  train loss: 0.0786389232
Epoch:  1200  |  train loss: 0.0786389232
Epoch:  1300  |  train loss: 0.0786389247
Epoch:  1400  |  train loss: 0.0786389217
Epoch:  1500  |  train loss: 0.0786389247
Epoch:  1600  |  train loss: 0.0786389217
Epoch:  1700  |  train loss: 0.0786389202
Epoch:  1800  |  train loss: 0.0786389232
Epoch:  1900  |  train loss: 0.0786389202
Epoch:  2000  |  train loss: 0.0786389232
Processing class: 15
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0774551243
Epoch:   200  |  train loss: 0.0774551243
Epoch:   300  |  train loss: 0.0774551272
Epoch:   400  |  train loss: 0.0774551272
Epoch:   500  |  train loss: 0.0774551272
Epoch:   600  |  train loss: 0.0774551228
Epoch:   700  |  train loss: 0.0774551228
Epoch:   800  |  train loss: 0.0774551243
Epoch:   900  |  train loss: 0.0774551243
Epoch:  1000  |  train loss: 0.0774551228
Epoch:  1100  |  train loss: 0.0774551228
Epoch:  1200  |  train loss: 0.0774551228
Epoch:  1300  |  train loss: 0.0774551257
Epoch:  1400  |  train loss: 0.0774551302
Epoch:  1500  |  train loss: 0.0774551257
Epoch:  1600  |  train loss: 0.0774551228
Epoch:  1700  |  train loss: 0.0774551287
Epoch:  1800  |  train loss: 0.0774551272
Epoch:  1900  |  train loss: 0.0774551243
Epoch:  2000  |  train loss: 0.0774551228
Processing class: 16
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0784319624
Epoch:   200  |  train loss: 0.0784319654
Epoch:   300  |  train loss: 0.0784319624
Epoch:   400  |  train loss: 0.0784319639
Epoch:   500  |  train loss: 0.0784319639
Epoch:   600  |  train loss: 0.0784319669
Epoch:   700  |  train loss: 0.0784319624
Epoch:   800  |  train loss: 0.0784319639
Epoch:   900  |  train loss: 0.0784319639
Epoch:  1000  |  train loss: 0.0784319609
Epoch:  1100  |  train loss: 0.0784319654
Epoch:  1200  |  train loss: 0.0784319639
Epoch:  1300  |  train loss: 0.0784319639
Epoch:  1400  |  train loss: 0.0784319639
Epoch:  1500  |  train loss: 0.0784319639
Epoch:  1600  |  train loss: 0.0784319624
Epoch:  1700  |  train loss: 0.0784319639
Epoch:  1800  |  train loss: 0.0784319624
Epoch:  1900  |  train loss: 0.0784319624
Epoch:  2000  |  train loss: 0.0784319609
Processing class: 17
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 18
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783664480
Epoch:   200  |  train loss: 0.0783664495
Epoch:   300  |  train loss: 0.0783664465
Epoch:   400  |  train loss: 0.0783664450
Epoch:   500  |  train loss: 0.0783664510
Epoch:   600  |  train loss: 0.0783664435
Epoch:   700  |  train loss: 0.0783664495
Epoch:   800  |  train loss: 0.0783664495
Epoch:   900  |  train loss: 0.0783664510
Epoch:  1000  |  train loss: 0.0783664450
Epoch:  1100  |  train loss: 0.0783664465
Epoch:  1200  |  train loss: 0.0783664480
Epoch:  1300  |  train loss: 0.0783664435
Epoch:  1400  |  train loss: 0.0783664510
Epoch:  1500  |  train loss: 0.0783664495
Epoch:  1600  |  train loss: 0.0783664495
Epoch:  1700  |  train loss: 0.0783664465
Epoch:  1800  |  train loss: 0.0783664450
Epoch:  1900  |  train loss: 0.0783664480
Epoch:  2000  |  train loss: 0.0783664480
Processing class: 19
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0744073674
Epoch:   200  |  train loss: 0.0744073674
Epoch:   300  |  train loss: 0.0744073689
Epoch:   400  |  train loss: 0.0744073659
Epoch:   500  |  train loss: 0.0744073659
Epoch:   600  |  train loss: 0.0744073659
Epoch:   700  |  train loss: 0.0744073689
Epoch:   800  |  train loss: 0.0744073644
Epoch:   900  |  train loss: 0.0744073674
Epoch:  1000  |  train loss: 0.0744073644
Epoch:  1100  |  train loss: 0.0744073689
Epoch:  1200  |  train loss: 0.0744073644
Epoch:  1300  |  train loss: 0.0744073659
Epoch:  1400  |  train loss: 0.0744073644
Epoch:  1500  |  train loss: 0.0744073659
Epoch:  1600  |  train loss: 0.0744073614
Epoch:  1700  |  train loss: 0.0744073629
Epoch:  1800  |  train loss: 0.0744073674
Epoch:  1900  |  train loss: 0.0744073644
Epoch:  2000  |  train loss: 0.0744073659
Processing class: 20
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780180603
Epoch:   200  |  train loss: 0.0780180603
Epoch:   300  |  train loss: 0.0780180618
Epoch:   400  |  train loss: 0.0780180603
Epoch:   500  |  train loss: 0.0780180603
Epoch:   600  |  train loss: 0.0780180648
Epoch:   700  |  train loss: 0.0780180648
Epoch:   800  |  train loss: 0.0780180603
Epoch:   900  |  train loss: 0.0780180618
Epoch:  1000  |  train loss: 0.0780180603
Epoch:  1100  |  train loss: 0.0780180648
Epoch:  1200  |  train loss: 0.0780180633
Epoch:  1300  |  train loss: 0.0780180588
Epoch:  1400  |  train loss: 0.0780180633
Epoch:  1500  |  train loss: 0.0780180618
Epoch:  1600  |  train loss: 0.0780180618
Epoch:  1700  |  train loss: 0.0780180588
Epoch:  1800  |  train loss: 0.0780180648
Epoch:  1900  |  train loss: 0.0780180603
Epoch:  2000  |  train loss: 0.0780180573
Processing class: 21
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 22
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0786119714
Epoch:   200  |  train loss: 0.0786119759
Epoch:   300  |  train loss: 0.0786119774
Epoch:   400  |  train loss: 0.0786119774
Epoch:   500  |  train loss: 0.0786119729
Epoch:   600  |  train loss: 0.0786119774
Epoch:   700  |  train loss: 0.0786119789
Epoch:   800  |  train loss: 0.0786119744
Epoch:   900  |  train loss: 0.0786119744
Epoch:  1000  |  train loss: 0.0786119759
Epoch:  1100  |  train loss: 0.0786119744
Epoch:  1200  |  train loss: 0.0786119729
Epoch:  1300  |  train loss: 0.0786119759
Epoch:  1400  |  train loss: 0.0786119804
Epoch:  1500  |  train loss: 0.0786119729
Epoch:  1600  |  train loss: 0.0786119729
Epoch:  1700  |  train loss: 0.0786119774
Epoch:  1800  |  train loss: 0.0786119759
Epoch:  1900  |  train loss: 0.0786119744
Epoch:  2000  |  train loss: 0.0786119774
Processing class: 23
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0786003262
Epoch:   200  |  train loss: 0.0786003277
Epoch:   300  |  train loss: 0.0786003247
Epoch:   400  |  train loss: 0.0786003217
Epoch:   500  |  train loss: 0.0786003262
Epoch:   600  |  train loss: 0.0786003262
Epoch:   700  |  train loss: 0.0786003247
Epoch:   800  |  train loss: 0.0786003262
Epoch:   900  |  train loss: 0.0786003262
Epoch:  1000  |  train loss: 0.0786003232
Epoch:  1100  |  train loss: 0.0786003247
Epoch:  1200  |  train loss: 0.0786003247
Epoch:  1300  |  train loss: 0.0786003247
Epoch:  1400  |  train loss: 0.0786003232
Epoch:  1500  |  train loss: 0.0786003247
Epoch:  1600  |  train loss: 0.0786003232
Epoch:  1700  |  train loss: 0.0786003262
Epoch:  1800  |  train loss: 0.0786003262
Epoch:  1900  |  train loss: 0.0786003247
Epoch:  2000  |  train loss: 0.0786003247
Processing class: 24
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780807361
Epoch:   200  |  train loss: 0.0780807331
Epoch:   300  |  train loss: 0.0780807376
Epoch:   400  |  train loss: 0.0780807376
Epoch:   500  |  train loss: 0.0780807391
Epoch:   600  |  train loss: 0.0780807346
Epoch:   700  |  train loss: 0.0780807361
Epoch:   800  |  train loss: 0.0780807391
Epoch:   900  |  train loss: 0.0780807361
Epoch:  1000  |  train loss: 0.0780807361
Epoch:  1100  |  train loss: 0.0780807391
Epoch:  1200  |  train loss: 0.0780807406
Epoch:  1300  |  train loss: 0.0780807361
Epoch:  1400  |  train loss: 0.0780807361
Epoch:  1500  |  train loss: 0.0780807376
Epoch:  1600  |  train loss: 0.0780807376
Epoch:  1700  |  train loss: 0.0780807361
Epoch:  1800  |  train loss: 0.0780807361
Epoch:  1900  |  train loss: 0.0780807361
Epoch:  2000  |  train loss: 0.0780807361
Processing class: 25
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0781035766
Epoch:   200  |  train loss: 0.0781035736
Epoch:   300  |  train loss: 0.0781035736
Epoch:   400  |  train loss: 0.0781035751
Epoch:   500  |  train loss: 0.0781035766
Epoch:   600  |  train loss: 0.0781035751
Epoch:   700  |  train loss: 0.0781035796
Epoch:   800  |  train loss: 0.0781035766
Epoch:   900  |  train loss: 0.0781035751
Epoch:  1000  |  train loss: 0.0781035736
Epoch:  1100  |  train loss: 0.0781035766
Epoch:  1200  |  train loss: 0.0781035736
Epoch:  1300  |  train loss: 0.0781035781
Epoch:  1400  |  train loss: 0.0781035781
Epoch:  1500  |  train loss: 0.0781035766
Epoch:  1600  |  train loss: 0.0781035751
Epoch:  1700  |  train loss: 0.0781035766
Epoch:  1800  |  train loss: 0.0781035721
Epoch:  1900  |  train loss: 0.0781035736
Epoch:  2000  |  train loss: 0.0781035736
Processing class: 26
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0787511751
Epoch:   200  |  train loss: 0.0787511751
Epoch:   300  |  train loss: 0.0787511721
Epoch:   400  |  train loss: 0.0787511736
Epoch:   500  |  train loss: 0.0787511736
Epoch:   600  |  train loss: 0.0787511721
Epoch:   700  |  train loss: 0.0787511721
Epoch:   800  |  train loss: 0.0787511736
Epoch:   900  |  train loss: 0.0787511751
Epoch:  1000  |  train loss: 0.0787511751
Epoch:  1100  |  train loss: 0.0787511751
Epoch:  1200  |  train loss: 0.0787511766
Epoch:  1300  |  train loss: 0.0787511721
Epoch:  1400  |  train loss: 0.0787511721
Epoch:  1500  |  train loss: 0.0787511736
Epoch:  1600  |  train loss: 0.0787511721
Epoch:  1700  |  train loss: 0.0787511751
Epoch:  1800  |  train loss: 0.0787511736
Epoch:  1900  |  train loss: 0.0787511736
Epoch:  2000  |  train loss: 0.0787511721
Processing class: 27
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0767574653
Epoch:   200  |  train loss: 0.0767574653
Epoch:   300  |  train loss: 0.0767574653
Epoch:   400  |  train loss: 0.0767574668
Epoch:   500  |  train loss: 0.0767574653
Epoch:   600  |  train loss: 0.0767574683
Epoch:   700  |  train loss: 0.0767574683
Epoch:   800  |  train loss: 0.0767574668
Epoch:   900  |  train loss: 0.0767574683
Epoch:  1000  |  train loss: 0.0767574668
Epoch:  1100  |  train loss: 0.0767574698
Epoch:  1200  |  train loss: 0.0767574638
Epoch:  1300  |  train loss: 0.0767574653
Epoch:  1400  |  train loss: 0.0767574638
Epoch:  1500  |  train loss: 0.0767574653
Epoch:  1600  |  train loss: 0.0767574668
Epoch:  1700  |  train loss: 0.0767574668
Epoch:  1800  |  train loss: 0.0767574653
Epoch:  1900  |  train loss: 0.0767574653
Epoch:  2000  |  train loss: 0.0767574668
Processing class: 28
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0787607849
Epoch:   200  |  train loss: 0.0787607834
Epoch:   300  |  train loss: 0.0787607834
Epoch:   400  |  train loss: 0.0787607849
Epoch:   500  |  train loss: 0.0787607849
Epoch:   600  |  train loss: 0.0787607834
Epoch:   700  |  train loss: 0.0787607864
Epoch:   800  |  train loss: 0.0787607789
Epoch:   900  |  train loss: 0.0787607864
Epoch:  1000  |  train loss: 0.0787607849
Epoch:  1100  |  train loss: 0.0787607834
Epoch:  1200  |  train loss: 0.0787607864
Epoch:  1300  |  train loss: 0.0787607819
Epoch:  1400  |  train loss: 0.0787607819
Epoch:  1500  |  train loss: 0.0787607819
Epoch:  1600  |  train loss: 0.0787607834
Epoch:  1700  |  train loss: 0.0787607834
Epoch:  1800  |  train loss: 0.0787607834
Epoch:  1900  |  train loss: 0.0787607878
Epoch:  2000  |  train loss: 0.0787607849
Processing class: 29
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778652579
Epoch:   200  |  train loss: 0.0778652579
Epoch:   300  |  train loss: 0.0778652593
Epoch:   400  |  train loss: 0.0778652593
Epoch:   500  |  train loss: 0.0778652593
Epoch:   600  |  train loss: 0.0778652579
Epoch:   700  |  train loss: 0.0778652608
Epoch:   800  |  train loss: 0.0778652623
Epoch:   900  |  train loss: 0.0778652608
Epoch:  1000  |  train loss: 0.0778652593
Epoch:  1100  |  train loss: 0.0778652564
Epoch:  1200  |  train loss: 0.0778652579
Epoch:  1300  |  train loss: 0.0778652579
Epoch:  1400  |  train loss: 0.0778652593
Epoch:  1500  |  train loss: 0.0778652564
Epoch:  1600  |  train loss: 0.0778652623
Epoch:  1700  |  train loss: 0.0778652593
Epoch:  1800  |  train loss: 0.0778652579
Epoch:  1900  |  train loss: 0.0778652564
Epoch:  2000  |  train loss: 0.0778652593
Processing class: 30
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782499745
Epoch:   200  |  train loss: 0.0782499731
Epoch:   300  |  train loss: 0.0782499745
Epoch:   400  |  train loss: 0.0782499731
Epoch:   500  |  train loss: 0.0782499731
Epoch:   600  |  train loss: 0.0782499716
Epoch:   700  |  train loss: 0.0782499745
Epoch:   800  |  train loss: 0.0782499716
Epoch:   900  |  train loss: 0.0782499716
Epoch:  1000  |  train loss: 0.0782499760
Epoch:  1100  |  train loss: 0.0782499731
Epoch:  1200  |  train loss: 0.0782499731
Epoch:  1300  |  train loss: 0.0782499716
Epoch:  1400  |  train loss: 0.0782499716
Epoch:  1500  |  train loss: 0.0782499716
Epoch:  1600  |  train loss: 0.0782499701
Epoch:  1700  |  train loss: 0.0782499716
Epoch:  1800  |  train loss: 0.0782499731
Epoch:  1900  |  train loss: 0.0782499731
Epoch:  2000  |  train loss: 0.0782499701
Processing class: 31
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 32
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783483118
Epoch:   200  |  train loss: 0.0783483103
Epoch:   300  |  train loss: 0.0783483073
Epoch:   400  |  train loss: 0.0783483088
Epoch:   500  |  train loss: 0.0783483103
Epoch:   600  |  train loss: 0.0783483058
Epoch:   700  |  train loss: 0.0783483118
Epoch:   800  |  train loss: 0.0783483088
Epoch:   900  |  train loss: 0.0783483073
Epoch:  1000  |  train loss: 0.0783483088
Epoch:  1100  |  train loss: 0.0783483088
Epoch:  1200  |  train loss: 0.0783483103
Epoch:  1300  |  train loss: 0.0783483118
Epoch:  1400  |  train loss: 0.0783483118
Epoch:  1500  |  train loss: 0.0783483073
Epoch:  1600  |  train loss: 0.0783483088
Epoch:  1700  |  train loss: 0.0783483073
Epoch:  1800  |  train loss: 0.0783483118
Epoch:  1900  |  train loss: 0.0783483088
Epoch:  2000  |  train loss: 0.0783483073
Processing class: 33
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 34
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780359596
Epoch:   200  |  train loss: 0.0780359566
Epoch:   300  |  train loss: 0.0780359611
Epoch:   400  |  train loss: 0.0780359596
Epoch:   500  |  train loss: 0.0780359566
Epoch:   600  |  train loss: 0.0780359581
Epoch:   700  |  train loss: 0.0780359596
Epoch:   800  |  train loss: 0.0780359581
Epoch:   900  |  train loss: 0.0780359551
Epoch:  1000  |  train loss: 0.0780359596
Epoch:  1100  |  train loss: 0.0780359566
Epoch:  1200  |  train loss: 0.0780359611
Epoch:  1300  |  train loss: 0.0780359566
Epoch:  1400  |  train loss: 0.0780359581
Epoch:  1500  |  train loss: 0.0780359611
Epoch:  1600  |  train loss: 0.0780359581
Epoch:  1700  |  train loss: 0.0780359596
Epoch:  1800  |  train loss: 0.0780359581
Epoch:  1900  |  train loss: 0.0780359611
Epoch:  2000  |  train loss: 0.0780359551
Processing class: 35
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 36
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780997917
Epoch:   200  |  train loss: 0.0780997872
Epoch:   300  |  train loss: 0.0780997917
Epoch:   400  |  train loss: 0.0780997917
Epoch:   500  |  train loss: 0.0780997887
Epoch:   600  |  train loss: 0.0780997932
Epoch:   700  |  train loss: 0.0780997932
Epoch:   800  |  train loss: 0.0780997887
Epoch:   900  |  train loss: 0.0780997843
Epoch:  1000  |  train loss: 0.0780997902
Epoch:  1100  |  train loss: 0.0780997887
Epoch:  1200  |  train loss: 0.0780997887
Epoch:  1300  |  train loss: 0.0780997932
Epoch:  1400  |  train loss: 0.0780997932
Epoch:  1500  |  train loss: 0.0780997887
Epoch:  1600  |  train loss: 0.0780997902
Epoch:  1700  |  train loss: 0.0780997902
Epoch:  1800  |  train loss: 0.0780997887
Epoch:  1900  |  train loss: 0.0780997902
Epoch:  2000  |  train loss: 0.0780997932
Processing class: 37
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782898098
Epoch:   200  |  train loss: 0.0782898128
Epoch:   300  |  train loss: 0.0782898113
Epoch:   400  |  train loss: 0.0782898113
Epoch:   500  |  train loss: 0.0782898113
Epoch:   600  |  train loss: 0.0782898098
Epoch:   700  |  train loss: 0.0782898143
Epoch:   800  |  train loss: 0.0782898113
Epoch:   900  |  train loss: 0.0782898128
Epoch:  1000  |  train loss: 0.0782898083
Epoch:  1100  |  train loss: 0.0782898158
Epoch:  1200  |  train loss: 0.0782898098
Epoch:  1300  |  train loss: 0.0782898128
Epoch:  1400  |  train loss: 0.0782898128
Epoch:  1500  |  train loss: 0.0782898113
Epoch:  1600  |  train loss: 0.0782898113
Epoch:  1700  |  train loss: 0.0782898158
Epoch:  1800  |  train loss: 0.0782898143
Epoch:  1900  |  train loss: 0.0782898113
Epoch:  2000  |  train loss: 0.0782898098
Processing class: 38
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0772102997
Epoch:   200  |  train loss: 0.0772103012
Epoch:   300  |  train loss: 0.0772102967
Epoch:   400  |  train loss: 0.0772103012
Epoch:   500  |  train loss: 0.0772103027
Epoch:   600  |  train loss: 0.0772103012
Epoch:   700  |  train loss: 0.0772102982
Epoch:   800  |  train loss: 0.0772102997
Epoch:   900  |  train loss: 0.0772103012
Epoch:  1000  |  train loss: 0.0772102997
Epoch:  1100  |  train loss: 0.0772102997
Epoch:  1200  |  train loss: 0.0772103012
Epoch:  1300  |  train loss: 0.0772102982
Epoch:  1400  |  train loss: 0.0772102982
Epoch:  1500  |  train loss: 0.0772102997
Epoch:  1600  |  train loss: 0.0772102967
Epoch:  1700  |  train loss: 0.0772102997
Epoch:  1800  |  train loss: 0.0772103012
Epoch:  1900  |  train loss: 0.0772102997
Epoch:  2000  |  train loss: 0.0772103012
Processing class: 39
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782369837
Epoch:   200  |  train loss: 0.0782369837
Epoch:   300  |  train loss: 0.0782369852
Epoch:   400  |  train loss: 0.0782369837
Epoch:   500  |  train loss: 0.0782369852
Epoch:   600  |  train loss: 0.0782369837
Epoch:   700  |  train loss: 0.0782369852
Epoch:   800  |  train loss: 0.0782369867
Epoch:   900  |  train loss: 0.0782369867
Epoch:  1000  |  train loss: 0.0782369822
Epoch:  1100  |  train loss: 0.0782369822
Epoch:  1200  |  train loss: 0.0782369822
Epoch:  1300  |  train loss: 0.0782369852
Epoch:  1400  |  train loss: 0.0782369852
Epoch:  1500  |  train loss: 0.0782369852
Epoch:  1600  |  train loss: 0.0782369852
Epoch:  1700  |  train loss: 0.0782369837
Epoch:  1800  |  train loss: 0.0782369822
Epoch:  1900  |  train loss: 0.0782369837
Epoch:  2000  |  train loss: 0.0782369852
Processing class: 40
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0786394939
Epoch:   200  |  train loss: 0.0786394909
Epoch:   300  |  train loss: 0.0786394879
Epoch:   400  |  train loss: 0.0786394879
Epoch:   500  |  train loss: 0.0786394894
Epoch:   600  |  train loss: 0.0786394879
Epoch:   700  |  train loss: 0.0786394864
Epoch:   800  |  train loss: 0.0786394909
Epoch:   900  |  train loss: 0.0786394909
Epoch:  1000  |  train loss: 0.0786394879
Epoch:  1100  |  train loss: 0.0786394909
Epoch:  1200  |  train loss: 0.0786394894
Epoch:  1300  |  train loss: 0.0786394909
Epoch:  1400  |  train loss: 0.0786394894
Epoch:  1500  |  train loss: 0.0786394894
Epoch:  1600  |  train loss: 0.0786394879
Epoch:  1700  |  train loss: 0.0786394909
Epoch:  1800  |  train loss: 0.0786394864
Epoch:  1900  |  train loss: 0.0786394879
Epoch:  2000  |  train loss: 0.0786394909
Processing class: 41
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783429846
Epoch:   200  |  train loss: 0.0783429846
Epoch:   300  |  train loss: 0.0783429846
Epoch:   400  |  train loss: 0.0783429831
Epoch:   500  |  train loss: 0.0783429816
Epoch:   600  |  train loss: 0.0783429831
Epoch:   700  |  train loss: 0.0783429831
Epoch:   800  |  train loss: 0.0783429801
Epoch:   900  |  train loss: 0.0783429816
Epoch:  1000  |  train loss: 0.0783429787
Epoch:  1100  |  train loss: 0.0783429816
Epoch:  1200  |  train loss: 0.0783429831
Epoch:  1300  |  train loss: 0.0783429816
Epoch:  1400  |  train loss: 0.0783429846
Epoch:  1500  |  train loss: 0.0783429816
Epoch:  1600  |  train loss: 0.0783429831
Epoch:  1700  |  train loss: 0.0783429816
Epoch:  1800  |  train loss: 0.0783429831
Epoch:  1900  |  train loss: 0.0783429801
Epoch:  2000  |  train loss: 0.0783429846
Processing class: 42
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0777130350
Epoch:   200  |  train loss: 0.0777130350
Epoch:   300  |  train loss: 0.0777130380
Epoch:   400  |  train loss: 0.0777130336
Epoch:   500  |  train loss: 0.0777130350
Epoch:   600  |  train loss: 0.0777130306
Epoch:   700  |  train loss: 0.0777130321
Epoch:   800  |  train loss: 0.0777130350
Epoch:   900  |  train loss: 0.0777130365
Epoch:  1000  |  train loss: 0.0777130350
Epoch:  1100  |  train loss: 0.0777130365
Epoch:  1200  |  train loss: 0.0777130336
Epoch:  1300  |  train loss: 0.0777130350
Epoch:  1400  |  train loss: 0.0777130350
Epoch:  1500  |  train loss: 0.0777130321
Epoch:  1600  |  train loss: 0.0777130336
Epoch:  1700  |  train loss: 0.0777130350
Epoch:  1800  |  train loss: 0.0777130336
Epoch:  1900  |  train loss: 0.0777130380
Epoch:  2000  |  train loss: 0.0777130365
Processing class: 43
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0787124842
Epoch:   200  |  train loss: 0.0787124872
Epoch:   300  |  train loss: 0.0787124828
Epoch:   400  |  train loss: 0.0787124872
Epoch:   500  |  train loss: 0.0787124872
Epoch:   600  |  train loss: 0.0787124857
Epoch:   700  |  train loss: 0.0787124842
Epoch:   800  |  train loss: 0.0787124828
Epoch:   900  |  train loss: 0.0787124842
Epoch:  1000  |  train loss: 0.0787124828
Epoch:  1100  |  train loss: 0.0787124872
Epoch:  1200  |  train loss: 0.0787124902
Epoch:  1300  |  train loss: 0.0787124857
Epoch:  1400  |  train loss: 0.0787124857
Epoch:  1500  |  train loss: 0.0787124857
Epoch:  1600  |  train loss: 0.0787124813
Epoch:  1700  |  train loss: 0.0787124842
Epoch:  1800  |  train loss: 0.0787124842
Epoch:  1900  |  train loss: 0.0787124842
Epoch:  2000  |  train loss: 0.0787124872
Processing class: 44
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783503100
Epoch:   200  |  train loss: 0.0783503160
Epoch:   300  |  train loss: 0.0783503160
Epoch:   400  |  train loss: 0.0783503130
Epoch:   500  |  train loss: 0.0783503130
Epoch:   600  |  train loss: 0.0783503100
Epoch:   700  |  train loss: 0.0783503115
Epoch:   800  |  train loss: 0.0783503145
Epoch:   900  |  train loss: 0.0783503160
Epoch:  1000  |  train loss: 0.0783503145
Epoch:  1100  |  train loss: 0.0783503115
Epoch:  1200  |  train loss: 0.0783503160
Epoch:  1300  |  train loss: 0.0783503100
Epoch:  1400  |  train loss: 0.0783503130
Epoch:  1500  |  train loss: 0.0783503115
Epoch:  1600  |  train loss: 0.0783503115
Epoch:  1700  |  train loss: 0.0783503145
Epoch:  1800  |  train loss: 0.0783503145
Epoch:  1900  |  train loss: 0.0783503130
Epoch:  2000  |  train loss: 0.0783503130
Processing class: 45
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0784731582
Epoch:   200  |  train loss: 0.0784731537
Epoch:   300  |  train loss: 0.0784731522
Epoch:   400  |  train loss: 0.0784731552
Epoch:   500  |  train loss: 0.0784731552
Epoch:   600  |  train loss: 0.0784731537
Epoch:   700  |  train loss: 0.0784731522
Epoch:   800  |  train loss: 0.0784731582
Epoch:   900  |  train loss: 0.0784731507
Epoch:  1000  |  train loss: 0.0784731552
Epoch:  1100  |  train loss: 0.0784731522
Epoch:  1200  |  train loss: 0.0784731567
Epoch:  1300  |  train loss: 0.0784731537
Epoch:  1400  |  train loss: 0.0784731522
Epoch:  1500  |  train loss: 0.0784731537
Epoch:  1600  |  train loss: 0.0784731552
Epoch:  1700  |  train loss: 0.0784731537
Epoch:  1800  |  train loss: 0.0784731537
Epoch:  1900  |  train loss: 0.0784731552
Epoch:  2000  |  train loss: 0.0784731552
Processing class: 46
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0784659445
Epoch:   200  |  train loss: 0.0784659401
Epoch:   300  |  train loss: 0.0784659415
Epoch:   400  |  train loss: 0.0784659430
Epoch:   500  |  train loss: 0.0784659460
Epoch:   600  |  train loss: 0.0784659430
Epoch:   700  |  train loss: 0.0784659445
Epoch:   800  |  train loss: 0.0784659430
Epoch:   900  |  train loss: 0.0784659415
Epoch:  1000  |  train loss: 0.0784659460
Epoch:  1100  |  train loss: 0.0784659445
Epoch:  1200  |  train loss: 0.0784659415
Epoch:  1300  |  train loss: 0.0784659460
Epoch:  1400  |  train loss: 0.0784659430
Epoch:  1500  |  train loss: 0.0784659475
Epoch:  1600  |  train loss: 0.0784659430
Epoch:  1700  |  train loss: 0.0784659430
Epoch:  1800  |  train loss: 0.0784659430
Epoch:  1900  |  train loss: 0.0784659415
Epoch:  2000  |  train loss: 0.0784659445
Processing class: 47
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780175447
Epoch:   200  |  train loss: 0.0780175462
Epoch:   300  |  train loss: 0.0780175522
Epoch:   400  |  train loss: 0.0780175462
Epoch:   500  |  train loss: 0.0780175462
Epoch:   600  |  train loss: 0.0780175477
Epoch:   700  |  train loss: 0.0780175477
Epoch:   800  |  train loss: 0.0780175492
Epoch:   900  |  train loss: 0.0780175507
Epoch:  1000  |  train loss: 0.0780175492
Epoch:  1100  |  train loss: 0.0780175447
Epoch:  1200  |  train loss: 0.0780175492
Epoch:  1300  |  train loss: 0.0780175477
Epoch:  1400  |  train loss: 0.0780175477
Epoch:  1500  |  train loss: 0.0780175492
Epoch:  1600  |  train loss: 0.0780175477
Epoch:  1700  |  train loss: 0.0780175477
Epoch:  1800  |  train loss: 0.0780175492
Epoch:  1900  |  train loss: 0.0780175447
Epoch:  2000  |  train loss: 0.0780175477
Processing class: 48
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782982111
Epoch:   200  |  train loss: 0.0782982111
Epoch:   300  |  train loss: 0.0782982111
Epoch:   400  |  train loss: 0.0782982126
Epoch:   500  |  train loss: 0.0782982141
Epoch:   600  |  train loss: 0.0782982126
Epoch:   700  |  train loss: 0.0782982141
Epoch:   800  |  train loss: 0.0782982141
Epoch:   900  |  train loss: 0.0782982141
Epoch:  1000  |  train loss: 0.0782982156
Epoch:  1100  |  train loss: 0.0782982126
Epoch:  1200  |  train loss: 0.0782982111
Epoch:  1300  |  train loss: 0.0782982111
Epoch:  1400  |  train loss: 0.0782982141
Epoch:  1500  |  train loss: 0.0782982141
Epoch:  1600  |  train loss: 0.0782982126
Epoch:  1700  |  train loss: 0.0782982126
Epoch:  1800  |  train loss: 0.0782982126
Epoch:  1900  |  train loss: 0.0782982126
Epoch:  2000  |  train loss: 0.0782982111
Processing class: 49
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Clasifying using reconstruction function cost
/home/z1165703/FeCAM/models/base.py:195: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data_point = torch.tensor(data_point).float().cuda()
2024-04-01 19:46:24,590 [trainer.py] => CNN: {'total': 83.44, '00-09': 87.7, '10-19': 79.6, '20-29': 84.9, '30-39': 81.0, '40-49': 84.0, 'old': 0, 'new': 83.44}
2024-04-01 19:46:24,591 [trainer.py] => No NME accuracy
2024-04-01 19:46:24,591 [trainer.py] => FeCAM: {'total': 70.96, '00-09': 78.1, '10-19': 64.7, '20-29': 73.8, '30-39': 66.3, '40-49': 71.9, 'old': 0, 'new': 70.96}
2024-04-01 19:46:24,591 [trainer.py] => CNN top1 curve: [83.44]
2024-04-01 19:46:24,591 [trainer.py] => CNN top5 curve: [96.5]
2024-04-01 19:46:24,591 [trainer.py] => FeCAM top1 curve: [70.96]
2024-04-01 19:46:24,591 [trainer.py] => FeCAM top5 curve: [86.38]

2024-04-01 19:46:24,595 [fecam.py] => Learning on 50-60
Processing class: 50
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0777271017
Epoch:   200  |  train loss: 0.0777271047
Epoch:   300  |  train loss: 0.0777271032
Epoch:   400  |  train loss: 0.0777270988
Epoch:   500  |  train loss: 0.0777271017
Epoch:   600  |  train loss: 0.0777271017
Epoch:   700  |  train loss: 0.0777271017
Epoch:   800  |  train loss: 0.0777270988
Epoch:   900  |  train loss: 0.0777271003
Epoch:  1000  |  train loss: 0.0777271017
Epoch:  1100  |  train loss: 0.0777271003
Epoch:  1200  |  train loss: 0.0777271003
Epoch:  1300  |  train loss: 0.0777271017
Epoch:  1400  |  train loss: 0.0777271017
Epoch:  1500  |  train loss: 0.0777271032
Epoch:  1600  |  train loss: 0.0777271003
Epoch:  1700  |  train loss: 0.0777271017
Epoch:  1800  |  train loss: 0.0777271003
Epoch:  1900  |  train loss: 0.0777271017
Epoch:  2000  |  train loss: 0.0777271047
Processing class: 51
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783204719
Epoch:   200  |  train loss: 0.0783204764
Epoch:   300  |  train loss: 0.0783204764
Epoch:   400  |  train loss: 0.0783204779
Epoch:   500  |  train loss: 0.0783204705
Epoch:   600  |  train loss: 0.0783204779
Epoch:   700  |  train loss: 0.0783204749
Epoch:   800  |  train loss: 0.0783204779
Epoch:   900  |  train loss: 0.0783204764
Epoch:  1000  |  train loss: 0.0783204779
Epoch:  1100  |  train loss: 0.0783204779
Epoch:  1200  |  train loss: 0.0783204764
Epoch:  1300  |  train loss: 0.0783204734
Epoch:  1400  |  train loss: 0.0783204779
Epoch:  1500  |  train loss: 0.0783204779
Epoch:  1600  |  train loss: 0.0783204779
Epoch:  1700  |  train loss: 0.0783204764
Epoch:  1800  |  train loss: 0.0783204764
Epoch:  1900  |  train loss: 0.0783204749
Epoch:  2000  |  train loss: 0.0783204779
Processing class: 52
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0779181764
Epoch:   200  |  train loss: 0.0779181823
Epoch:   300  |  train loss: 0.0779181778
Epoch:   400  |  train loss: 0.0779181778
Epoch:   500  |  train loss: 0.0779181808
Epoch:   600  |  train loss: 0.0779181793
Epoch:   700  |  train loss: 0.0779181793
Epoch:   800  |  train loss: 0.0779181808
Epoch:   900  |  train loss: 0.0779181778
Epoch:  1000  |  train loss: 0.0779181793
Epoch:  1100  |  train loss: 0.0779181793
Epoch:  1200  |  train loss: 0.0779181778
Epoch:  1300  |  train loss: 0.0779181778
Epoch:  1400  |  train loss: 0.0779181764
Epoch:  1500  |  train loss: 0.0779181808
Epoch:  1600  |  train loss: 0.0779181778
Epoch:  1700  |  train loss: 0.0779181778
Epoch:  1800  |  train loss: 0.0779181823
Epoch:  1900  |  train loss: 0.0779181808
Epoch:  2000  |  train loss: 0.0779181793
Processing class: 53
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0775902763
Epoch:   200  |  train loss: 0.0775902808
Epoch:   300  |  train loss: 0.0775902793
Epoch:   400  |  train loss: 0.0775902793
Epoch:   500  |  train loss: 0.0775902748
Epoch:   600  |  train loss: 0.0775902793
Epoch:   700  |  train loss: 0.0775902823
Epoch:   800  |  train loss: 0.0775902823
Epoch:   900  |  train loss: 0.0775902808
Epoch:  1000  |  train loss: 0.0775902763
Epoch:  1100  |  train loss: 0.0775902763
Epoch:  1200  |  train loss: 0.0775902778
Epoch:  1300  |  train loss: 0.0775902808
Epoch:  1400  |  train loss: 0.0775902778
Epoch:  1500  |  train loss: 0.0775902793
Epoch:  1600  |  train loss: 0.0775902793
Epoch:  1700  |  train loss: 0.0775902808
Epoch:  1800  |  train loss: 0.0775902793
Epoch:  1900  |  train loss: 0.0775902778
Epoch:  2000  |  train loss: 0.0775902763
Processing class: 54
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0705595538
Epoch:   200  |  train loss: 0.0705595553
Epoch:   300  |  train loss: 0.0705595583
Epoch:   400  |  train loss: 0.0705595538
Epoch:   500  |  train loss: 0.0705595553
Epoch:   600  |  train loss: 0.0705595523
Epoch:   700  |  train loss: 0.0705595538
Epoch:   800  |  train loss: 0.0705595538
Epoch:   900  |  train loss: 0.0705595553
Epoch:  1000  |  train loss: 0.0705595553
Epoch:  1100  |  train loss: 0.0705595538
Epoch:  1200  |  train loss: 0.0705595553
Epoch:  1300  |  train loss: 0.0705595568
Epoch:  1400  |  train loss: 0.0705595553
Epoch:  1500  |  train loss: 0.0705595553
Epoch:  1600  |  train loss: 0.0705595583
Epoch:  1700  |  train loss: 0.0705595553
Epoch:  1800  |  train loss: 0.0705595538
Epoch:  1900  |  train loss: 0.0705595538
Epoch:  2000  |  train loss: 0.0705595568
Processing class: 55
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 56
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780293018
Epoch:   200  |  train loss: 0.0780293003
Epoch:   300  |  train loss: 0.0780293018
Epoch:   400  |  train loss: 0.0780293003
Epoch:   500  |  train loss: 0.0780293033
Epoch:   600  |  train loss: 0.0780293003
Epoch:   700  |  train loss: 0.0780293018
Epoch:   800  |  train loss: 0.0780293003
Epoch:   900  |  train loss: 0.0780293018
Epoch:  1000  |  train loss: 0.0780293003
Epoch:  1100  |  train loss: 0.0780292988
Epoch:  1200  |  train loss: 0.0780293047
Epoch:  1300  |  train loss: 0.0780292988
Epoch:  1400  |  train loss: 0.0780292988
Epoch:  1500  |  train loss: 0.0780293033
Epoch:  1600  |  train loss: 0.0780293018
Epoch:  1700  |  train loss: 0.0780293047
Epoch:  1800  |  train loss: 0.0780293033
Epoch:  1900  |  train loss: 0.0780292973
Epoch:  2000  |  train loss: 0.0780293003
Processing class: 57
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778819025
Epoch:   200  |  train loss: 0.0778819039
Epoch:   300  |  train loss: 0.0778819025
Epoch:   400  |  train loss: 0.0778819069
Epoch:   500  |  train loss: 0.0778819039
Epoch:   600  |  train loss: 0.0778819039
Epoch:   700  |  train loss: 0.0778819039
Epoch:   800  |  train loss: 0.0778819025
Epoch:   900  |  train loss: 0.0778819039
Epoch:  1000  |  train loss: 0.0778819039
Epoch:  1100  |  train loss: 0.0778819010
Epoch:  1200  |  train loss: 0.0778819025
Epoch:  1300  |  train loss: 0.0778819025
Epoch:  1400  |  train loss: 0.0778819010
Epoch:  1500  |  train loss: 0.0778818995
Epoch:  1600  |  train loss: 0.0778819025
Epoch:  1700  |  train loss: 0.0778819010
Epoch:  1800  |  train loss: 0.0778818995
Epoch:  1900  |  train loss: 0.0778819010
Epoch:  2000  |  train loss: 0.0778819025
Processing class: 58
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0770577878
Epoch:   200  |  train loss: 0.0770577878
Epoch:   300  |  train loss: 0.0770577878
Epoch:   400  |  train loss: 0.0770577908
Epoch:   500  |  train loss: 0.0770577908
Epoch:   600  |  train loss: 0.0770577863
Epoch:   700  |  train loss: 0.0770577893
Epoch:   800  |  train loss: 0.0770577893
Epoch:   900  |  train loss: 0.0770577848
Epoch:  1000  |  train loss: 0.0770577908
Epoch:  1100  |  train loss: 0.0770577922
Epoch:  1200  |  train loss: 0.0770577878
Epoch:  1300  |  train loss: 0.0770577878
Epoch:  1400  |  train loss: 0.0770577893
Epoch:  1500  |  train loss: 0.0770577893
Epoch:  1600  |  train loss: 0.0770577878
Epoch:  1700  |  train loss: 0.0770577893
Epoch:  1800  |  train loss: 0.0770577893
Epoch:  1900  |  train loss: 0.0770577893
Epoch:  2000  |  train loss: 0.0770577878
Processing class: 59
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0776399940
Epoch:   200  |  train loss: 0.0776399940
Epoch:   300  |  train loss: 0.0776399910
Epoch:   400  |  train loss: 0.0776399925
Epoch:   500  |  train loss: 0.0776399940
Epoch:   600  |  train loss: 0.0776399896
Epoch:   700  |  train loss: 0.0776399881
Epoch:   800  |  train loss: 0.0776399970
Epoch:   900  |  train loss: 0.0776399910
Epoch:  1000  |  train loss: 0.0776399940
Epoch:  1100  |  train loss: 0.0776399925
Epoch:  1200  |  train loss: 0.0776399881
Epoch:  1300  |  train loss: 0.0776399940
Epoch:  1400  |  train loss: 0.0776399896
Epoch:  1500  |  train loss: 0.0776399925
Epoch:  1600  |  train loss: 0.0776399896
Epoch:  1700  |  train loss: 0.0776399940
Epoch:  1800  |  train loss: 0.0776399925
Epoch:  1900  |  train loss: 0.0776399925
Epoch:  2000  |  train loss: 0.0776399910
Clasifying using reconstruction function cost
2024-04-01 20:43:52,689 [trainer.py] => CNN: {'total': 71.75, '00-09': 82.2, '10-19': 72.8, '20-29': 78.5, '30-39': 74.9, '40-49': 68.4, '50-59': 53.7, 'old': 75.36, 'new': 53.7}
2024-04-01 20:43:52,690 [trainer.py] => No NME accuracy
2024-04-01 20:43:52,690 [trainer.py] => FeCAM: {'total': 58.88, '00-09': 74.8, '10-19': 60.8, '20-29': 71.2, '30-39': 63.6, '40-49': 65.9, '50-59': 17.0, 'old': 67.26, 'new': 17.0}
2024-04-01 20:43:52,691 [trainer.py] => CNN top1 curve: [83.44, 71.75]
2024-04-01 20:43:52,691 [trainer.py] => CNN top5 curve: [96.5, 89.6]
2024-04-01 20:43:52,691 [trainer.py] => FeCAM top1 curve: [70.96, 58.88]
2024-04-01 20:43:52,691 [trainer.py] => FeCAM top5 curve: [86.38, 79.35]

2024-04-01 20:43:52,695 [fecam.py] => Learning on 60-70
Processing class: 60
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 61
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0714338049
Epoch:   200  |  train loss: 0.0714338034
Epoch:   300  |  train loss: 0.0714338049
Epoch:   400  |  train loss: 0.0714338019
Epoch:   500  |  train loss: 0.0714338064
Epoch:   600  |  train loss: 0.0714338049
Epoch:   700  |  train loss: 0.0714338049
Epoch:   800  |  train loss: 0.0714338049
Epoch:   900  |  train loss: 0.0714338019
Epoch:  1000  |  train loss: 0.0714338064
Epoch:  1100  |  train loss: 0.0714338049
Epoch:  1200  |  train loss: 0.0714338005
Epoch:  1300  |  train loss: 0.0714338064
Epoch:  1400  |  train loss: 0.0714338079
Epoch:  1500  |  train loss: 0.0714338064
Epoch:  1600  |  train loss: 0.0714338049
Epoch:  1700  |  train loss: 0.0714338049
Epoch:  1800  |  train loss: 0.0714338049
Epoch:  1900  |  train loss: 0.0714338064
Epoch:  2000  |  train loss: 0.0714338049
Processing class: 62
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0783718288
Epoch:   200  |  train loss: 0.0783718273
Epoch:   300  |  train loss: 0.0783718303
Epoch:   400  |  train loss: 0.0783718288
Epoch:   500  |  train loss: 0.0783718273
Epoch:   600  |  train loss: 0.0783718273
Epoch:   700  |  train loss: 0.0783718258
Epoch:   800  |  train loss: 0.0783718303
Epoch:   900  |  train loss: 0.0783718243
Epoch:  1000  |  train loss: 0.0783718258
Epoch:  1100  |  train loss: 0.0783718258
Epoch:  1200  |  train loss: 0.0783718273
Epoch:  1300  |  train loss: 0.0783718273
Epoch:  1400  |  train loss: 0.0783718303
Epoch:  1500  |  train loss: 0.0783718258
Epoch:  1600  |  train loss: 0.0783718288
Epoch:  1700  |  train loss: 0.0783718258
Epoch:  1800  |  train loss: 0.0783718258
Epoch:  1900  |  train loss: 0.0783718243
Epoch:  2000  |  train loss: 0.0783718258
Processing class: 63
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 64
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0759233311
Epoch:   200  |  train loss: 0.0759233296
Epoch:   300  |  train loss: 0.0759233281
Epoch:   400  |  train loss: 0.0759233281
Epoch:   500  |  train loss: 0.0759233296
Epoch:   600  |  train loss: 0.0759233281
Epoch:   700  |  train loss: 0.0759233296
Epoch:   800  |  train loss: 0.0759233281
Epoch:   900  |  train loss: 0.0759233266
Epoch:  1000  |  train loss: 0.0759233296
Epoch:  1100  |  train loss: 0.0759233296
Epoch:  1200  |  train loss: 0.0759233296
Epoch:  1300  |  train loss: 0.0759233311
Epoch:  1400  |  train loss: 0.0759233281
Epoch:  1500  |  train loss: 0.0759233281
Epoch:  1600  |  train loss: 0.0759233281
Epoch:  1700  |  train loss: 0.0759233281
Epoch:  1800  |  train loss: 0.0759233281
Epoch:  1900  |  train loss: 0.0759233281
Epoch:  2000  |  train loss: 0.0759233266
Processing class: 65
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0774029389
Epoch:   200  |  train loss: 0.0774029359
Epoch:   300  |  train loss: 0.0774029389
Epoch:   400  |  train loss: 0.0774029374
Epoch:   500  |  train loss: 0.0774029419
Epoch:   600  |  train loss: 0.0774029359
Epoch:   700  |  train loss: 0.0774029374
Epoch:   800  |  train loss: 0.0774029389
Epoch:   900  |  train loss: 0.0774029389
Epoch:  1000  |  train loss: 0.0774029344
Epoch:  1100  |  train loss: 0.0774029374
Epoch:  1200  |  train loss: 0.0774029344
Epoch:  1300  |  train loss: 0.0774029374
Epoch:  1400  |  train loss: 0.0774029404
Epoch:  1500  |  train loss: 0.0774029374
Epoch:  1600  |  train loss: 0.0774029389
Epoch:  1700  |  train loss: 0.0774029419
Epoch:  1800  |  train loss: 0.0774029404
Epoch:  1900  |  train loss: 0.0774029374
Epoch:  2000  |  train loss: 0.0774029374
Processing class: 66
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0785284594
Epoch:   200  |  train loss: 0.0785284564
Epoch:   300  |  train loss: 0.0785284564
Epoch:   400  |  train loss: 0.0785284564
Epoch:   500  |  train loss: 0.0785284564
Epoch:   600  |  train loss: 0.0785284564
Epoch:   700  |  train loss: 0.0785284564
Epoch:   800  |  train loss: 0.0785284564
Epoch:   900  |  train loss: 0.0785284549
Epoch:  1000  |  train loss: 0.0785284549
Epoch:  1100  |  train loss: 0.0785284579
Epoch:  1200  |  train loss: 0.0785284549
Epoch:  1300  |  train loss: 0.0785284579
Epoch:  1400  |  train loss: 0.0785284534
Epoch:  1500  |  train loss: 0.0785284549
Epoch:  1600  |  train loss: 0.0785284549
Epoch:  1700  |  train loss: 0.0785284564
Epoch:  1800  |  train loss: 0.0785284519
Epoch:  1900  |  train loss: 0.0785284564
Epoch:  2000  |  train loss: 0.0785284534
Processing class: 67
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0766513944
Epoch:   200  |  train loss: 0.0766513959
Epoch:   300  |  train loss: 0.0766513944
Epoch:   400  |  train loss: 0.0766513929
Epoch:   500  |  train loss: 0.0766513959
Epoch:   600  |  train loss: 0.0766513959
Epoch:   700  |  train loss: 0.0766513944
Epoch:   800  |  train loss: 0.0766513944
Epoch:   900  |  train loss: 0.0766513944
Epoch:  1000  |  train loss: 0.0766514018
Epoch:  1100  |  train loss: 0.0766513959
Epoch:  1200  |  train loss: 0.0766513973
Epoch:  1300  |  train loss: 0.0766513973
Epoch:  1400  |  train loss: 0.0766513988
Epoch:  1500  |  train loss: 0.0766513959
Epoch:  1600  |  train loss: 0.0766513988
Epoch:  1700  |  train loss: 0.0766513988
Epoch:  1800  |  train loss: 0.0766513959
Epoch:  1900  |  train loss: 0.0766513988
Epoch:  2000  |  train loss: 0.0766513959
Processing class: 68
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0769797638
Epoch:   200  |  train loss: 0.0769797638
Epoch:   300  |  train loss: 0.0769797608
Epoch:   400  |  train loss: 0.0769797564
Epoch:   500  |  train loss: 0.0769797608
Epoch:   600  |  train loss: 0.0769797593
Epoch:   700  |  train loss: 0.0769797593
Epoch:   800  |  train loss: 0.0769797593
Epoch:   900  |  train loss: 0.0769797608
Epoch:  1000  |  train loss: 0.0769797593
Epoch:  1100  |  train loss: 0.0769797623
Epoch:  1200  |  train loss: 0.0769797623
Epoch:  1300  |  train loss: 0.0769797578
Epoch:  1400  |  train loss: 0.0769797623
Epoch:  1500  |  train loss: 0.0769797638
Epoch:  1600  |  train loss: 0.0769797638
Epoch:  1700  |  train loss: 0.0769797608
Epoch:  1800  |  train loss: 0.0769797608
Epoch:  1900  |  train loss: 0.0769797653
Epoch:  2000  |  train loss: 0.0769797623
Processing class: 69
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0780252486
Epoch:   200  |  train loss: 0.0780252486
Epoch:   300  |  train loss: 0.0780252501
Epoch:   400  |  train loss: 0.0780252472
Epoch:   500  |  train loss: 0.0780252486
Epoch:   600  |  train loss: 0.0780252472
Epoch:   700  |  train loss: 0.0780252516
Epoch:   800  |  train loss: 0.0780252472
Epoch:   900  |  train loss: 0.0780252501
Epoch:  1000  |  train loss: 0.0780252472
Epoch:  1100  |  train loss: 0.0780252486
Epoch:  1200  |  train loss: 0.0780252516
Epoch:  1300  |  train loss: 0.0780252516
Epoch:  1400  |  train loss: 0.0780252457
Epoch:  1500  |  train loss: 0.0780252516
Epoch:  1600  |  train loss: 0.0780252457
Epoch:  1700  |  train loss: 0.0780252486
Epoch:  1800  |  train loss: 0.0780252501
Epoch:  1900  |  train loss: 0.0780252472
Epoch:  2000  |  train loss: 0.0780252457
Clasifying using reconstruction function cost
2024-04-01 21:43:18,391 [trainer.py] => CNN: {'total': 64.66, '00-09': 75.0, '10-19': 70.1, '20-29': 77.1, '30-39': 70.6, '40-49': 64.0, '50-59': 45.8, '60-69': 50.0, 'old': 67.1, 'new': 50.0}
2024-04-01 21:43:18,392 [trainer.py] => No NME accuracy
2024-04-01 21:43:18,392 [trainer.py] => FeCAM: {'total': 47.46, '00-09': 68.2, '10-19': 54.9, '20-29': 65.8, '30-39': 55.7, '40-49': 58.0, '50-59': 12.1, '60-69': 17.5, 'old': 52.45, 'new': 17.5}
2024-04-01 21:43:18,392 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66]
2024-04-01 21:43:18,392 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54]
2024-04-01 21:43:18,392 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.46]
2024-04-01 21:43:18,392 [trainer.py] => FeCAM top5 curve: [86.38, 79.35, 72.53]

2024-04-01 21:43:18,396 [fecam.py] => Learning on 70-80
Processing class: 70
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0752213940
Epoch:   200  |  train loss: 0.0752213940
Epoch:   300  |  train loss: 0.0752213925
Epoch:   400  |  train loss: 0.0752213985
Epoch:   500  |  train loss: 0.0752213955
Epoch:   600  |  train loss: 0.0752213955
Epoch:   700  |  train loss: 0.0752213940
Epoch:   800  |  train loss: 0.0752213955
Epoch:   900  |  train loss: 0.0752213940
Epoch:  1000  |  train loss: 0.0752213925
Epoch:  1100  |  train loss: 0.0752213895
Epoch:  1200  |  train loss: 0.0752213955
Epoch:  1300  |  train loss: 0.0752213925
Epoch:  1400  |  train loss: 0.0752213955
Epoch:  1500  |  train loss: 0.0752213925
Epoch:  1600  |  train loss: 0.0752213970
Epoch:  1700  |  train loss: 0.0752213910
Epoch:  1800  |  train loss: 0.0752213955
Epoch:  1900  |  train loss: 0.0752213910
Epoch:  2000  |  train loss: 0.0752213985
Processing class: 71
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782586083
Epoch:   200  |  train loss: 0.0782586053
Epoch:   300  |  train loss: 0.0782586068
Epoch:   400  |  train loss: 0.0782586038
Epoch:   500  |  train loss: 0.0782586068
Epoch:   600  |  train loss: 0.0782586038
Epoch:   700  |  train loss: 0.0782586038
Epoch:   800  |  train loss: 0.0782586068
Epoch:   900  |  train loss: 0.0782586068
Epoch:  1000  |  train loss: 0.0782586038
Epoch:  1100  |  train loss: 0.0782586038
Epoch:  1200  |  train loss: 0.0782586053
Epoch:  1300  |  train loss: 0.0782586053
Epoch:  1400  |  train loss: 0.0782586068
Epoch:  1500  |  train loss: 0.0782586053
Epoch:  1600  |  train loss: 0.0782586023
Epoch:  1700  |  train loss: 0.0782586038
Epoch:  1800  |  train loss: 0.0782586098
Epoch:  1900  |  train loss: 0.0782586008
Epoch:  2000  |  train loss: 0.0782586038
Processing class: 72
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0775515273
Epoch:   200  |  train loss: 0.0775515288
Epoch:   300  |  train loss: 0.0775515258
Epoch:   400  |  train loss: 0.0775515214
Epoch:   500  |  train loss: 0.0775515288
Epoch:   600  |  train loss: 0.0775515229
Epoch:   700  |  train loss: 0.0775515288
Epoch:   800  |  train loss: 0.0775515273
Epoch:   900  |  train loss: 0.0775515258
Epoch:  1000  |  train loss: 0.0775515288
Epoch:  1100  |  train loss: 0.0775515288
Epoch:  1200  |  train loss: 0.0775515288
Epoch:  1300  |  train loss: 0.0775515258
Epoch:  1400  |  train loss: 0.0775515288
Epoch:  1500  |  train loss: 0.0775515303
Epoch:  1600  |  train loss: 0.0775515258
Epoch:  1700  |  train loss: 0.0775515243
Epoch:  1800  |  train loss: 0.0775515273
Epoch:  1900  |  train loss: 0.0775515243
Epoch:  2000  |  train loss: 0.0775515258
Processing class: 73
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782376394
Epoch:   200  |  train loss: 0.0782376409
Epoch:   300  |  train loss: 0.0782376409
Epoch:   400  |  train loss: 0.0782376379
Epoch:   500  |  train loss: 0.0782376409
Epoch:   600  |  train loss: 0.0782376409
Epoch:   700  |  train loss: 0.0782376423
Epoch:   800  |  train loss: 0.0782376409
Epoch:   900  |  train loss: 0.0782376394
Epoch:  1000  |  train loss: 0.0782376423
Epoch:  1100  |  train loss: 0.0782376409
Epoch:  1200  |  train loss: 0.0782376423
Epoch:  1300  |  train loss: 0.0782376423
Epoch:  1400  |  train loss: 0.0782376409
Epoch:  1500  |  train loss: 0.0782376423
Epoch:  1600  |  train loss: 0.0782376423
Epoch:  1700  |  train loss: 0.0782376409
Epoch:  1800  |  train loss: 0.0782376409
Epoch:  1900  |  train loss: 0.0782376394
Epoch:  2000  |  train loss: 0.0782376394
Processing class: 74
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0776742980
Epoch:   200  |  train loss: 0.0776742980
Epoch:   300  |  train loss: 0.0776742980
Epoch:   400  |  train loss: 0.0776742980
Epoch:   500  |  train loss: 0.0776742995
Epoch:   600  |  train loss: 0.0776742995
Epoch:   700  |  train loss: 0.0776742950
Epoch:   800  |  train loss: 0.0776742995
Epoch:   900  |  train loss: 0.0776743010
Epoch:  1000  |  train loss: 0.0776743010
Epoch:  1100  |  train loss: 0.0776742965
Epoch:  1200  |  train loss: 0.0776742980
Epoch:  1300  |  train loss: 0.0776742980
Epoch:  1400  |  train loss: 0.0776742965
Epoch:  1500  |  train loss: 0.0776743010
Epoch:  1600  |  train loss: 0.0776742980
Epoch:  1700  |  train loss: 0.0776742995
Epoch:  1800  |  train loss: 0.0776742980
Epoch:  1900  |  train loss: 0.0776743010
Epoch:  2000  |  train loss: 0.0776743025
Processing class: 75
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 76
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0777714327
Epoch:   200  |  train loss: 0.0777714327
Epoch:   300  |  train loss: 0.0777714297
Epoch:   400  |  train loss: 0.0777714312
Epoch:   500  |  train loss: 0.0777714282
Epoch:   600  |  train loss: 0.0777714312
Epoch:   700  |  train loss: 0.0777714282
Epoch:   800  |  train loss: 0.0777714297
Epoch:   900  |  train loss: 0.0777714297
Epoch:  1000  |  train loss: 0.0777714327
Epoch:  1100  |  train loss: 0.0777714342
Epoch:  1200  |  train loss: 0.0777714297
Epoch:  1300  |  train loss: 0.0777714282
Epoch:  1400  |  train loss: 0.0777714297
Epoch:  1500  |  train loss: 0.0777714267
Epoch:  1600  |  train loss: 0.0777714312
Epoch:  1700  |  train loss: 0.0777714282
Epoch:  1800  |  train loss: 0.0777714297
Epoch:  1900  |  train loss: 0.0777714327
Epoch:  2000  |  train loss: 0.0777714312
Processing class: 77
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 78
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0777131736
Epoch:   200  |  train loss: 0.0777131751
Epoch:   300  |  train loss: 0.0777131751
Epoch:   400  |  train loss: 0.0777131766
Epoch:   500  |  train loss: 0.0777131751
Epoch:   600  |  train loss: 0.0777131736
Epoch:   700  |  train loss: 0.0777131751
Epoch:   800  |  train loss: 0.0777131751
Epoch:   900  |  train loss: 0.0777131736
Epoch:  1000  |  train loss: 0.0777131751
Epoch:  1100  |  train loss: 0.0777131781
Epoch:  1200  |  train loss: 0.0777131751
Epoch:  1300  |  train loss: 0.0777131766
Epoch:  1400  |  train loss: 0.0777131766
Epoch:  1500  |  train loss: 0.0777131781
Epoch:  1600  |  train loss: 0.0777131751
Epoch:  1700  |  train loss: 0.0777131766
Epoch:  1800  |  train loss: 0.0777131736
Epoch:  1900  |  train loss: 0.0777131736
Epoch:  2000  |  train loss: 0.0777131766
Processing class: 79
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0779550955
Epoch:   200  |  train loss: 0.0779550985
Epoch:   300  |  train loss: 0.0779550999
Epoch:   400  |  train loss: 0.0779550955
Epoch:   500  |  train loss: 0.0779550940
Epoch:   600  |  train loss: 0.0779550970
Epoch:   700  |  train loss: 0.0779550955
Epoch:   800  |  train loss: 0.0779551014
Epoch:   900  |  train loss: 0.0779550970
Epoch:  1000  |  train loss: 0.0779550985
Epoch:  1100  |  train loss: 0.0779550955
Epoch:  1200  |  train loss: 0.0779550940
Epoch:  1300  |  train loss: 0.0779550970
Epoch:  1400  |  train loss: 0.0779551014
Epoch:  1500  |  train loss: 0.0779550940
Epoch:  1600  |  train loss: 0.0779550970
Epoch:  1700  |  train loss: 0.0779550999
Epoch:  1800  |  train loss: 0.0779550970
Epoch:  1900  |  train loss: 0.0779550940
Epoch:  2000  |  train loss: 0.0779550985
Clasifying using reconstruction function cost
2024-04-01 22:45:02,024 [trainer.py] => CNN: {'total': 59.18, '00-09': 73.6, '10-19': 68.4, '20-29': 76.9, '30-39': 69.1, '40-49': 60.6, '50-59': 37.2, '60-69': 45.7, '70-79': 41.9, 'old': 61.64, 'new': 41.9}
2024-04-01 22:45:02,024 [trainer.py] => No NME accuracy
2024-04-01 22:45:02,024 [trainer.py] => FeCAM: {'total': 40.29, '00-09': 65.5, '10-19': 53.1, '20-29': 62.8, '30-39': 52.7, '40-49': 55.4, '50-59': 9.9, '60-69': 14.3, '70-79': 8.6, 'old': 44.81, 'new': 8.6}
2024-04-01 22:45:02,025 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18]
2024-04-01 22:45:02,025 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09]
2024-04-01 22:45:02,025 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.46, 40.29]
2024-04-01 22:45:02,025 [trainer.py] => FeCAM top5 curve: [86.38, 79.35, 72.53, 66.7]

2024-04-01 22:45:02,029 [fecam.py] => Learning on 80-90
Processing class: 80
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0767168254
Epoch:   200  |  train loss: 0.0767168224
Epoch:   300  |  train loss: 0.0767168254
Epoch:   400  |  train loss: 0.0767168209
Epoch:   500  |  train loss: 0.0767168239
Epoch:   600  |  train loss: 0.0767168239
Epoch:   700  |  train loss: 0.0767168239
Epoch:   800  |  train loss: 0.0767168239
Epoch:   900  |  train loss: 0.0767168254
Epoch:  1000  |  train loss: 0.0767168239
Epoch:  1100  |  train loss: 0.0767168239
Epoch:  1200  |  train loss: 0.0767168254
Epoch:  1300  |  train loss: 0.0767168239
Epoch:  1400  |  train loss: 0.0767168224
Epoch:  1500  |  train loss: 0.0767168254
Epoch:  1600  |  train loss: 0.0767168269
Epoch:  1700  |  train loss: 0.0767168239
Epoch:  1800  |  train loss: 0.0767168254
Epoch:  1900  |  train loss: 0.0767168209
Epoch:  2000  |  train loss: 0.0767168239
Processing class: 81
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778956205
Epoch:   200  |  train loss: 0.0778956264
Epoch:   300  |  train loss: 0.0778956220
Epoch:   400  |  train loss: 0.0778956249
Epoch:   500  |  train loss: 0.0778956249
Epoch:   600  |  train loss: 0.0778956220
Epoch:   700  |  train loss: 0.0778956234
Epoch:   800  |  train loss: 0.0778956234
Epoch:   900  |  train loss: 0.0778956264
Epoch:  1000  |  train loss: 0.0778956249
Epoch:  1100  |  train loss: 0.0778956264
Epoch:  1200  |  train loss: 0.0778956264
Epoch:  1300  |  train loss: 0.0778956264
Epoch:  1400  |  train loss: 0.0778956249
Epoch:  1500  |  train loss: 0.0778956264
Epoch:  1600  |  train loss: 0.0778956249
Epoch:  1700  |  train loss: 0.0778956249
Epoch:  1800  |  train loss: 0.0778956264
Epoch:  1900  |  train loss: 0.0778956279
Epoch:  2000  |  train loss: 0.0778956220
Processing class: 82
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0773294717
Epoch:   200  |  train loss: 0.0773294717
Epoch:   300  |  train loss: 0.0773294732
Epoch:   400  |  train loss: 0.0773294702
Epoch:   500  |  train loss: 0.0773294732
Epoch:   600  |  train loss: 0.0773294732
Epoch:   700  |  train loss: 0.0773294732
Epoch:   800  |  train loss: 0.0773294732
Epoch:   900  |  train loss: 0.0773294717
Epoch:  1000  |  train loss: 0.0773294732
Epoch:  1100  |  train loss: 0.0773294702
Epoch:  1200  |  train loss: 0.0773294747
Epoch:  1300  |  train loss: 0.0773294702
Epoch:  1400  |  train loss: 0.0773294717
Epoch:  1500  |  train loss: 0.0773294732
Epoch:  1600  |  train loss: 0.0773294747
Epoch:  1700  |  train loss: 0.0773294717
Epoch:  1800  |  train loss: 0.0773294702
Epoch:  1900  |  train loss: 0.0773294762
Epoch:  2000  |  train loss: 0.0773294747
Processing class: 83
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778529271
Epoch:   200  |  train loss: 0.0778529242
Epoch:   300  |  train loss: 0.0778529271
Epoch:   400  |  train loss: 0.0778529257
Epoch:   500  |  train loss: 0.0778529271
Epoch:   600  |  train loss: 0.0778529257
Epoch:   700  |  train loss: 0.0778529271
Epoch:   800  |  train loss: 0.0778529257
Epoch:   900  |  train loss: 0.0778529257
Epoch:  1000  |  train loss: 0.0778529286
Epoch:  1100  |  train loss: 0.0778529301
Epoch:  1200  |  train loss: 0.0778529286
Epoch:  1300  |  train loss: 0.0778529271
Epoch:  1400  |  train loss: 0.0778529301
Epoch:  1500  |  train loss: 0.0778529257
Epoch:  1600  |  train loss: 0.0778529271
Epoch:  1700  |  train loss: 0.0778529271
Epoch:  1800  |  train loss: 0.0778529301
Epoch:  1900  |  train loss: 0.0778529242
Epoch:  2000  |  train loss: 0.0778529271
Processing class: 84
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0779649913
Epoch:   200  |  train loss: 0.0779649928
Epoch:   300  |  train loss: 0.0779649958
Epoch:   400  |  train loss: 0.0779649958
Epoch:   500  |  train loss: 0.0779649973
Epoch:   600  |  train loss: 0.0779649958
Epoch:   700  |  train loss: 0.0779649943
Epoch:   800  |  train loss: 0.0779649943
Epoch:   900  |  train loss: 0.0779649958
Epoch:  1000  |  train loss: 0.0779649973
Epoch:  1100  |  train loss: 0.0779649913
Epoch:  1200  |  train loss: 0.0779649958
Epoch:  1300  |  train loss: 0.0779649943
Epoch:  1400  |  train loss: 0.0779649913
Epoch:  1500  |  train loss: 0.0779649928
Epoch:  1600  |  train loss: 0.0779649928
Epoch:  1700  |  train loss: 0.0779649973
Epoch:  1800  |  train loss: 0.0779649958
Epoch:  1900  |  train loss: 0.0779649943
Epoch:  2000  |  train loss: 0.0779649943
Processing class: 85
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0760360822
Epoch:   200  |  train loss: 0.0760360837
Epoch:   300  |  train loss: 0.0760360822
Epoch:   400  |  train loss: 0.0760360837
Epoch:   500  |  train loss: 0.0760360852
Epoch:   600  |  train loss: 0.0760360852
Epoch:   700  |  train loss: 0.0760360882
Epoch:   800  |  train loss: 0.0760360837
Epoch:   900  |  train loss: 0.0760360822
Epoch:  1000  |  train loss: 0.0760360837
Epoch:  1100  |  train loss: 0.0760360837
Epoch:  1200  |  train loss: 0.0760360822
Epoch:  1300  |  train loss: 0.0760360852
Epoch:  1400  |  train loss: 0.0760360837
Epoch:  1500  |  train loss: 0.0760360807
Epoch:  1600  |  train loss: 0.0760360822
Epoch:  1700  |  train loss: 0.0760360837
Epoch:  1800  |  train loss: 0.0760360867
Epoch:  1900  |  train loss: 0.0760360837
Epoch:  2000  |  train loss: 0.0760360807
Processing class: 86
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782932922
Epoch:   200  |  train loss: 0.0782932922
Epoch:   300  |  train loss: 0.0782932922
Epoch:   400  |  train loss: 0.0782932907
Epoch:   500  |  train loss: 0.0782932997
Epoch:   600  |  train loss: 0.0782932937
Epoch:   700  |  train loss: 0.0782932937
Epoch:   800  |  train loss: 0.0782932922
Epoch:   900  |  train loss: 0.0782932937
Epoch:  1000  |  train loss: 0.0782932922
Epoch:  1100  |  train loss: 0.0782932937
Epoch:  1200  |  train loss: 0.0782932952
Epoch:  1300  |  train loss: 0.0782932937
Epoch:  1400  |  train loss: 0.0782932907
Epoch:  1500  |  train loss: 0.0782932937
Epoch:  1600  |  train loss: 0.0782932922
Epoch:  1700  |  train loss: 0.0782932907
Epoch:  1800  |  train loss: 0.0782932937
Epoch:  1900  |  train loss: 0.0782932922
Epoch:  2000  |  train loss: 0.0782932937
Processing class: 87
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782940209
Epoch:   200  |  train loss: 0.0782940209
Epoch:   300  |  train loss: 0.0782940224
Epoch:   400  |  train loss: 0.0782940179
Epoch:   500  |  train loss: 0.0782940194
Epoch:   600  |  train loss: 0.0782940224
Epoch:   700  |  train loss: 0.0782940179
Epoch:   800  |  train loss: 0.0782940179
Epoch:   900  |  train loss: 0.0782940164
Epoch:  1000  |  train loss: 0.0782940209
Epoch:  1100  |  train loss: 0.0782940194
Epoch:  1200  |  train loss: 0.0782940179
Epoch:  1300  |  train loss: 0.0782940179
Epoch:  1400  |  train loss: 0.0782940209
Epoch:  1500  |  train loss: 0.0782940209
Epoch:  1600  |  train loss: 0.0782940239
Epoch:  1700  |  train loss: 0.0782940164
Epoch:  1800  |  train loss: 0.0782940194
Epoch:  1900  |  train loss: 0.0782940209
Epoch:  2000  |  train loss: 0.0782940209
Processing class: 88
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0776965320
Epoch:   200  |  train loss: 0.0776965335
Epoch:   300  |  train loss: 0.0776965335
Epoch:   400  |  train loss: 0.0776965335
Epoch:   500  |  train loss: 0.0776965335
Epoch:   600  |  train loss: 0.0776965320
Epoch:   700  |  train loss: 0.0776965320
Epoch:   800  |  train loss: 0.0776965365
Epoch:   900  |  train loss: 0.0776965320
Epoch:  1000  |  train loss: 0.0776965395
Epoch:  1100  |  train loss: 0.0776965350
Epoch:  1200  |  train loss: 0.0776965350
Epoch:  1300  |  train loss: 0.0776965335
Epoch:  1400  |  train loss: 0.0776965335
Epoch:  1500  |  train loss: 0.0776965350
Epoch:  1600  |  train loss: 0.0776965350
Epoch:  1700  |  train loss: 0.0776965350
Epoch:  1800  |  train loss: 0.0776965350
Epoch:  1900  |  train loss: 0.0776965350
Epoch:  2000  |  train loss: 0.0776965350
Processing class: 89
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0784112886
Epoch:   200  |  train loss: 0.0784112871
Epoch:   300  |  train loss: 0.0784112871
Epoch:   400  |  train loss: 0.0784112856
Epoch:   500  |  train loss: 0.0784112856
Epoch:   600  |  train loss: 0.0784112856
Epoch:   700  |  train loss: 0.0784112886
Epoch:   800  |  train loss: 0.0784112871
Epoch:   900  |  train loss: 0.0784112871
Epoch:  1000  |  train loss: 0.0784112900
Epoch:  1100  |  train loss: 0.0784112871
Epoch:  1200  |  train loss: 0.0784112841
Epoch:  1300  |  train loss: 0.0784112841
Epoch:  1400  |  train loss: 0.0784112856
Epoch:  1500  |  train loss: 0.0784112886
Epoch:  1600  |  train loss: 0.0784112826
Epoch:  1700  |  train loss: 0.0784112856
Epoch:  1800  |  train loss: 0.0784112856
Epoch:  1900  |  train loss: 0.0784112886
Epoch:  2000  |  train loss: 0.0784112856
Clasifying using reconstruction function cost
2024-04-01 23:48:40,205 [trainer.py] => CNN: {'total': 54.08, '00-09': 67.9, '10-19': 63.6, '20-29': 73.2, '30-39': 68.8, '40-49': 57.2, '50-59': 32.6, '60-69': 40.9, '70-79': 38.1, '80-89': 44.4, 'old': 55.29, 'new': 44.4}
2024-04-01 23:48:40,210 [trainer.py] => No NME accuracy
2024-04-01 23:48:40,210 [trainer.py] => FeCAM: {'total': 36.12, '00-09': 64.8, '10-19': 51.1, '20-29': 61.7, '30-39': 52.6, '40-49': 54.5, '50-59': 9.4, '60-69': 13.3, '70-79': 8.3, '80-89': 9.4, 'old': 39.46, 'new': 9.4}
2024-04-01 23:48:40,210 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08]
2024-04-01 23:48:40,210 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74]
2024-04-01 23:48:40,210 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.46, 40.29, 36.12]
2024-04-01 23:48:40,210 [trainer.py] => FeCAM top5 curve: [86.38, 79.35, 72.53, 66.7, 62.81]

2024-04-01 23:48:40,217 [fecam.py] => Learning on 90-100
Processing class: 90
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0772325248
Epoch:   200  |  train loss: 0.0772325233
Epoch:   300  |  train loss: 0.0772325218
Epoch:   400  |  train loss: 0.0772325262
Epoch:   500  |  train loss: 0.0772325248
Epoch:   600  |  train loss: 0.0772325248
Epoch:   700  |  train loss: 0.0772325233
Epoch:   800  |  train loss: 0.0772325262
Epoch:   900  |  train loss: 0.0772325233
Epoch:  1000  |  train loss: 0.0772325248
Epoch:  1100  |  train loss: 0.0772325277
Epoch:  1200  |  train loss: 0.0772325262
Epoch:  1300  |  train loss: 0.0772325248
Epoch:  1400  |  train loss: 0.0772325262
Epoch:  1500  |  train loss: 0.0772325218
Epoch:  1600  |  train loss: 0.0772325292
Epoch:  1700  |  train loss: 0.0772325233
Epoch:  1800  |  train loss: 0.0772325262
Epoch:  1900  |  train loss: 0.0772325277
Epoch:  2000  |  train loss: 0.0772325262
Processing class: 91
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0782079920
Epoch:   200  |  train loss: 0.0782079920
Epoch:   300  |  train loss: 0.0782079890
Epoch:   400  |  train loss: 0.0782079920
Epoch:   500  |  train loss: 0.0782079890
Epoch:   600  |  train loss: 0.0782079890
Epoch:   700  |  train loss: 0.0782079890
Epoch:   800  |  train loss: 0.0782079920
Epoch:   900  |  train loss: 0.0782079890
Epoch:  1000  |  train loss: 0.0782079920
Epoch:  1100  |  train loss: 0.0782079875
Epoch:  1200  |  train loss: 0.0782079890
Epoch:  1300  |  train loss: 0.0782079920
Epoch:  1400  |  train loss: 0.0782079920
Epoch:  1500  |  train loss: 0.0782079905
Epoch:  1600  |  train loss: 0.0782079890
Epoch:  1700  |  train loss: 0.0782079890
Epoch:  1800  |  train loss: 0.0782079890
Epoch:  1900  |  train loss: 0.0782079890
Epoch:  2000  |  train loss: 0.0782079905
Processing class: 92
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0775444090
Epoch:   200  |  train loss: 0.0775444105
Epoch:   300  |  train loss: 0.0775444090
Epoch:   400  |  train loss: 0.0775444090
Epoch:   500  |  train loss: 0.0775444090
Epoch:   600  |  train loss: 0.0775444105
Epoch:   700  |  train loss: 0.0775444090
Epoch:   800  |  train loss: 0.0775444090
Epoch:   900  |  train loss: 0.0775444120
Epoch:  1000  |  train loss: 0.0775444105
Epoch:  1100  |  train loss: 0.0775444105
Epoch:  1200  |  train loss: 0.0775444105
Epoch:  1300  |  train loss: 0.0775444105
Epoch:  1400  |  train loss: 0.0775444061
Epoch:  1500  |  train loss: 0.0775444150
Epoch:  1600  |  train loss: 0.0775444120
Epoch:  1700  |  train loss: 0.0775444075
Epoch:  1800  |  train loss: 0.0775444075
Epoch:  1900  |  train loss: 0.0775444090
Epoch:  2000  |  train loss: 0.0775444150
Processing class: 93
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0781641066
Epoch:   200  |  train loss: 0.0781641096
Epoch:   300  |  train loss: 0.0781641096
Epoch:   400  |  train loss: 0.0781641066
Epoch:   500  |  train loss: 0.0781641096
Epoch:   600  |  train loss: 0.0781641081
Epoch:   700  |  train loss: 0.0781641081
Epoch:   800  |  train loss: 0.0781641081
Epoch:   900  |  train loss: 0.0781641081
Epoch:  1000  |  train loss: 0.0781641081
Epoch:  1100  |  train loss: 0.0781641081
Epoch:  1200  |  train loss: 0.0781641096
Epoch:  1300  |  train loss: 0.0781641066
Epoch:  1400  |  train loss: 0.0781641111
Epoch:  1500  |  train loss: 0.0781641096
Epoch:  1600  |  train loss: 0.0781641051
Epoch:  1700  |  train loss: 0.0781641096
Epoch:  1800  |  train loss: 0.0781641066
Epoch:  1900  |  train loss: 0.0781641126
Epoch:  2000  |  train loss: 0.0781641081
Processing class: 94
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0763317674
Epoch:   200  |  train loss: 0.0763317630
Epoch:   300  |  train loss: 0.0763317674
Epoch:   400  |  train loss: 0.0763317659
Epoch:   500  |  train loss: 0.0763317689
Epoch:   600  |  train loss: 0.0763317659
Epoch:   700  |  train loss: 0.0763317659
Epoch:   800  |  train loss: 0.0763317645
Epoch:   900  |  train loss: 0.0763317704
Epoch:  1000  |  train loss: 0.0763317674
Epoch:  1100  |  train loss: 0.0763317659
Epoch:  1200  |  train loss: 0.0763317630
Epoch:  1300  |  train loss: 0.0763317689
Epoch:  1400  |  train loss: 0.0763317659
Epoch:  1500  |  train loss: 0.0763317659
Epoch:  1600  |  train loss: 0.0763317645
Epoch:  1700  |  train loss: 0.0763317674
Epoch:  1800  |  train loss: 0.0763317689
Epoch:  1900  |  train loss: 0.0763317645
Epoch:  2000  |  train loss: 0.0763317689
Processing class: 95
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778490886
Epoch:   200  |  train loss: 0.0778490901
Epoch:   300  |  train loss: 0.0778490901
Epoch:   400  |  train loss: 0.0778490901
Epoch:   500  |  train loss: 0.0778490871
Epoch:   600  |  train loss: 0.0778490901
Epoch:   700  |  train loss: 0.0778490886
Epoch:   800  |  train loss: 0.0778490901
Epoch:   900  |  train loss: 0.0778490886
Epoch:  1000  |  train loss: 0.0778490886
Epoch:  1100  |  train loss: 0.0778490871
Epoch:  1200  |  train loss: 0.0778490901
Epoch:  1300  |  train loss: 0.0778490901
Epoch:  1400  |  train loss: 0.0778490886
Epoch:  1500  |  train loss: 0.0778490886
Epoch:  1600  |  train loss: 0.0778490901
Epoch:  1700  |  train loss: 0.0778490871
Epoch:  1800  |  train loss: 0.0778490931
Epoch:  1900  |  train loss: 0.0778490871
Epoch:  2000  |  train loss: 0.0778490886
Processing class: 96
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0778179646
Epoch:   200  |  train loss: 0.0778179616
Epoch:   300  |  train loss: 0.0778179631
Epoch:   400  |  train loss: 0.0778179616
Epoch:   500  |  train loss: 0.0778179586
Epoch:   600  |  train loss: 0.0778179601
Epoch:   700  |  train loss: 0.0778179586
Epoch:   800  |  train loss: 0.0778179601
Epoch:   900  |  train loss: 0.0778179631
Epoch:  1000  |  train loss: 0.0778179631
Epoch:  1100  |  train loss: 0.0778179601
Epoch:  1200  |  train loss: 0.0778179616
Epoch:  1300  |  train loss: 0.0778179631
Epoch:  1400  |  train loss: 0.0778179616
Epoch:  1500  |  train loss: 0.0778179601
Epoch:  1600  |  train loss: 0.0778179616
Epoch:  1700  |  train loss: 0.0778179586
Epoch:  1800  |  train loss: 0.0778179571
Epoch:  1900  |  train loss: 0.0778179616
Epoch:  2000  |  train loss: 0.0778179616
Processing class: 97
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0756913647
Epoch:   200  |  train loss: 0.0756913677
Epoch:   300  |  train loss: 0.0756913647
Epoch:   400  |  train loss: 0.0756913647
Epoch:   500  |  train loss: 0.0756913662
Epoch:   600  |  train loss: 0.0756913662
Epoch:   700  |  train loss: 0.0756913677
Epoch:   800  |  train loss: 0.0756913647
Epoch:   900  |  train loss: 0.0756913647
Epoch:  1000  |  train loss: 0.0756913662
Epoch:  1100  |  train loss: 0.0756913662
Epoch:  1200  |  train loss: 0.0756913647
Epoch:  1300  |  train loss: 0.0756913617
Epoch:  1400  |  train loss: 0.0756913647
Epoch:  1500  |  train loss: 0.0756913647
Epoch:  1600  |  train loss: 0.0756913662
Epoch:  1700  |  train loss: 0.0756913662
Epoch:  1800  |  train loss: 0.0756913662
Epoch:  1900  |  train loss: 0.0756913632
Epoch:  2000  |  train loss: 0.0756913662
Processing class: 98
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 99
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.0776748955
Epoch:   200  |  train loss: 0.0776748925
Epoch:   300  |  train loss: 0.0776748911
Epoch:   400  |  train loss: 0.0776748925
Epoch:   500  |  train loss: 0.0776748911
Epoch:   600  |  train loss: 0.0776748896
Epoch:   700  |  train loss: 0.0776748911
Epoch:   800  |  train loss: 0.0776748881
Epoch:   900  |  train loss: 0.0776748896
Epoch:  1000  |  train loss: 0.0776748896
Epoch:  1100  |  train loss: 0.0776748925
Epoch:  1200  |  train loss: 0.0776748925
Epoch:  1300  |  train loss: 0.0776748896
Epoch:  1400  |  train loss: 0.0776748866
Epoch:  1500  |  train loss: 0.0776748911
Epoch:  1600  |  train loss: 0.0776748911
Epoch:  1700  |  train loss: 0.0776748896
Epoch:  1800  |  train loss: 0.0776748881
Epoch:  1900  |  train loss: 0.0776748896
Epoch:  2000  |  train loss: 0.0776748896
Clasifying using reconstruction function cost
2024-04-02 00:55:02,822 [trainer.py] => CNN: {'total': 50.36, '00-09': 57.7, '10-19': 63.6, '20-29': 71.4, '30-39': 68.5, '40-49': 56.8, '50-59': 29.6, '60-69': 38.9, '70-79': 36.6, '80-89': 42.7, '90-99': 37.8, 'old': 51.76, 'new': 37.8}
2024-04-02 00:55:02,822 [trainer.py] => No NME accuracy
2024-04-02 00:55:02,822 [trainer.py] => FeCAM: {'total': 31.69, '00-09': 62.1, '10-19': 48.6, '20-29': 59.8, '30-39': 50.0, '40-49': 53.3, '50-59': 8.5, '60-69': 11.8, '70-79': 6.9, '80-89': 8.4, '90-99': 7.5, 'old': 34.38, 'new': 7.5}
2024-04-02 00:55:02,823 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08, 50.36]
2024-04-02 00:55:02,823 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74, 79.63]
2024-04-02 00:55:02,823 [trainer.py] => FeCAM top1 curve: [70.96, 58.88, 47.46, 40.29, 36.12, 31.69]
2024-04-02 00:55:02,823 [trainer.py] => FeCAM top5 curve: [86.38, 79.35, 72.53, 66.7, 62.81, 58.69]

=========================================
2024-04-02 00:55:20,872 [trainer.py] => config: ./exps/FeCAM_cifar100.json
2024-04-02 00:55:20,872 [trainer.py] => prefix: train
2024-04-02 00:55:20,872 [trainer.py] => dataset: cifar100
2024-04-02 00:55:20,872 [trainer.py] => memory_size: 0
2024-04-02 00:55:20,872 [trainer.py] => shuffle: True
2024-04-02 00:55:20,872 [trainer.py] => init_cls: 50
2024-04-02 00:55:20,872 [trainer.py] => increment: 10
2024-04-02 00:55:20,872 [trainer.py] => model_name: fecam
2024-04-02 00:55:20,872 [trainer.py] => convnet_type: resnet18
2024-04-02 00:55:20,872 [trainer.py] => device: [device(type='cuda', index=0)]
2024-04-02 00:55:20,872 [trainer.py] => seed: 1993
2024-04-02 00:55:20,872 [trainer.py] => init_epochs: 200
2024-04-02 00:55:20,872 [trainer.py] => init_lr: 0.1
2024-04-02 00:55:20,872 [trainer.py] => init_weight_decay: 0.0005
2024-04-02 00:55:20,872 [trainer.py] => batch_size: 128
2024-04-02 00:55:20,872 [trainer.py] => num_workers: 8
2024-04-02 00:55:20,872 [trainer.py] => T: 5
2024-04-02 00:55:20,872 [trainer.py] => beta: 0.5
2024-04-02 00:55:20,872 [trainer.py] => alpha1: 1
2024-04-02 00:55:20,872 [trainer.py] => alpha2: 1
2024-04-02 00:55:20,873 [trainer.py] => ncm: False
2024-04-02 00:55:20,873 [trainer.py] => tukey: False
2024-04-02 00:55:20,873 [trainer.py] => diagonal: False
2024-04-02 00:55:20,873 [trainer.py] => per_class: True
2024-04-02 00:55:20,873 [trainer.py] => full_cov: True
2024-04-02 00:55:20,873 [trainer.py] => shrink: True
2024-04-02 00:55:20,873 [trainer.py] => norm_cov: False
2024-04-02 00:55:20,873 [trainer.py] => epochs: 2000
2024-04-02 00:55:20,873 [trainer.py] => vecnorm: False
2024-04-02 00:55:20,873 [trainer.py] => ae_type: ae
2024-04-02 00:55:20,873 [trainer.py] => ae_latent_dim: 32
2024-04-02 00:55:20,873 [trainer.py] => ae_n: 1
2024-04-02 00:55:20,873 [trainer.py] => wae_sigma: 10
2024-04-02 00:55:20,873 [trainer.py] => wae_C: 0.1
2024-04-02 00:55:20,873 [trainer.py] => ae_standarization: False
2024-04-02 00:55:20,873 [trainer.py] => ae_pca: False
2024-04-02 00:55:20,873 [trainer.py] => ae_pca_components: 500
2024-04-02 00:55:20,873 [trainer.py] => ae_clsf: maha-recon-cost
2024-04-02 00:55:20,873 [trainer.py] => maha_alpha: 0.01
2024-04-02 00:55:20,873 [trainer.py] => maha_beta: 0.3
Files already downloaded and verified
Files already downloaded and verified
2024-04-02 00:55:22,591 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-04-02 00:55:22,857 [fecam.py] => Learning on 0-50
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Processing class: 0
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1263461813
Epoch:   200  |  train loss: 0.1263461649
Epoch:   300  |  train loss: 0.1263461754
Epoch:   400  |  train loss: 0.1263461754
Epoch:   500  |  train loss: 0.1263461739
Epoch:   600  |  train loss: 0.1263461709
Epoch:   700  |  train loss: 0.1263461739
Epoch:   800  |  train loss: 0.1263461739
Epoch:   900  |  train loss: 0.1263461769
Epoch:  1000  |  train loss: 0.1263461739
Epoch:  1100  |  train loss: 0.1263461739
Epoch:  1200  |  train loss: 0.1263461739
Epoch:  1300  |  train loss: 0.1263461754
Epoch:  1400  |  train loss: 0.1263461709
Epoch:  1500  |  train loss: 0.1263461754
Epoch:  1600  |  train loss: 0.1263461798
Epoch:  1700  |  train loss: 0.1263461798
Epoch:  1800  |  train loss: 0.1263461739
Epoch:  1900  |  train loss: 0.1263461769
Epoch:  2000  |  train loss: 0.1263461754
Processing class: 1
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1258740202
Epoch:   200  |  train loss: 0.1258740157
Epoch:   300  |  train loss: 0.1258740187
Epoch:   400  |  train loss: 0.1258740202
Epoch:   500  |  train loss: 0.1258740246
Epoch:   600  |  train loss: 0.1258740202
Epoch:   700  |  train loss: 0.1258740216
Epoch:   800  |  train loss: 0.1258740187
Epoch:   900  |  train loss: 0.1258740216
Epoch:  1000  |  train loss: 0.1258740187
Epoch:  1100  |  train loss: 0.1258740157
Epoch:  1200  |  train loss: 0.1258740187
Epoch:  1300  |  train loss: 0.1258740172
Epoch:  1400  |  train loss: 0.1258740157
Epoch:  1500  |  train loss: 0.1258740187
Epoch:  1600  |  train loss: 0.1258740202
Epoch:  1700  |  train loss: 0.1258740246
Epoch:  1800  |  train loss: 0.1258740187
Epoch:  1900  |  train loss: 0.1258740202
Epoch:  2000  |  train loss: 0.1258740142
Processing class: 2
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1230868563
Epoch:   200  |  train loss: 0.1230868593
Epoch:   300  |  train loss: 0.1230868548
Epoch:   400  |  train loss: 0.1230868518
Epoch:   500  |  train loss: 0.1230868563
Epoch:   600  |  train loss: 0.1230868563
Epoch:   700  |  train loss: 0.1230868503
Epoch:   800  |  train loss: 0.1230868548
Epoch:   900  |  train loss: 0.1230868503
Epoch:  1000  |  train loss: 0.1230868548
Epoch:  1100  |  train loss: 0.1230868533
Epoch:  1200  |  train loss: 0.1230868533
Epoch:  1300  |  train loss: 0.1230868563
Epoch:  1400  |  train loss: 0.1230868563
Epoch:  1500  |  train loss: 0.1230868533
Epoch:  1600  |  train loss: 0.1230868474
Epoch:  1700  |  train loss: 0.1230868518
Epoch:  1800  |  train loss: 0.1230868578
Epoch:  1900  |  train loss: 0.1230868533
Epoch:  2000  |  train loss: 0.1230868533
Processing class: 3
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1252933726
Epoch:   200  |  train loss: 0.1252933756
Epoch:   300  |  train loss: 0.1252933726
Epoch:   400  |  train loss: 0.1252933711
Epoch:   500  |  train loss: 0.1252933785
Epoch:   600  |  train loss: 0.1252933726
Epoch:   700  |  train loss: 0.1252933770
Epoch:   800  |  train loss: 0.1252933636
Epoch:   900  |  train loss: 0.1252933726
Epoch:  1000  |  train loss: 0.1252933651
Epoch:  1100  |  train loss: 0.1252933726
Epoch:  1200  |  train loss: 0.1252933711
Epoch:  1300  |  train loss: 0.1252933741
Epoch:  1400  |  train loss: 0.1252933726
Epoch:  1500  |  train loss: 0.1252933741
Epoch:  1600  |  train loss: 0.1252933696
Epoch:  1700  |  train loss: 0.1252933741
Epoch:  1800  |  train loss: 0.1252933741
Epoch:  1900  |  train loss: 0.1252933696
Epoch:  2000  |  train loss: 0.1252933681
Processing class: 4
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1258236781
Epoch:   200  |  train loss: 0.1258236781
Epoch:   300  |  train loss: 0.1258236736
Epoch:   400  |  train loss: 0.1258236676
Epoch:   500  |  train loss: 0.1258236811
Epoch:   600  |  train loss: 0.1258236736
Epoch:   700  |  train loss: 0.1258236811
Epoch:   800  |  train loss: 0.1258236781
Epoch:   900  |  train loss: 0.1258236796
Epoch:  1000  |  train loss: 0.1258236766
Epoch:  1100  |  train loss: 0.1258236736
Epoch:  1200  |  train loss: 0.1258236751
Epoch:  1300  |  train loss: 0.1258236766
Epoch:  1400  |  train loss: 0.1258236766
Epoch:  1500  |  train loss: 0.1258236691
Epoch:  1600  |  train loss: 0.1258236676
Epoch:  1700  |  train loss: 0.1258236766
Epoch:  1800  |  train loss: 0.1258236781
Epoch:  1900  |  train loss: 0.1258236796
Epoch:  2000  |  train loss: 0.1258236781
Processing class: 5
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 6
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261987597
Epoch:   200  |  train loss: 0.1261987597
Epoch:   300  |  train loss: 0.1261987627
Epoch:   400  |  train loss: 0.1261987686
Epoch:   500  |  train loss: 0.1261987582
Epoch:   600  |  train loss: 0.1261987597
Epoch:   700  |  train loss: 0.1261987537
Epoch:   800  |  train loss: 0.1261987567
Epoch:   900  |  train loss: 0.1261987537
Epoch:  1000  |  train loss: 0.1261987627
Epoch:  1100  |  train loss: 0.1261987612
Epoch:  1200  |  train loss: 0.1261987567
Epoch:  1300  |  train loss: 0.1261987567
Epoch:  1400  |  train loss: 0.1261987567
Epoch:  1500  |  train loss: 0.1261987582
Epoch:  1600  |  train loss: 0.1261987597
Epoch:  1700  |  train loss: 0.1261987627
Epoch:  1800  |  train loss: 0.1261987567
Epoch:  1900  |  train loss: 0.1261987612
Epoch:  2000  |  train loss: 0.1261987597
Processing class: 7
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1260909751
Epoch:   200  |  train loss: 0.1260909736
Epoch:   300  |  train loss: 0.1260909826
Epoch:   400  |  train loss: 0.1260909706
Epoch:   500  |  train loss: 0.1260909751
Epoch:   600  |  train loss: 0.1260909796
Epoch:   700  |  train loss: 0.1260909766
Epoch:   800  |  train loss: 0.1260909766
Epoch:   900  |  train loss: 0.1260909736
Epoch:  1000  |  train loss: 0.1260909811
Epoch:  1100  |  train loss: 0.1260909751
Epoch:  1200  |  train loss: 0.1260909751
Epoch:  1300  |  train loss: 0.1260909826
Epoch:  1400  |  train loss: 0.1260909796
Epoch:  1500  |  train loss: 0.1260909796
Epoch:  1600  |  train loss: 0.1260909751
Epoch:  1700  |  train loss: 0.1260909840
Epoch:  1800  |  train loss: 0.1260909826
Epoch:  1900  |  train loss: 0.1260909826
Epoch:  2000  |  train loss: 0.1260909781
Processing class: 8
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1257324368
Epoch:   200  |  train loss: 0.1257324338
Epoch:   300  |  train loss: 0.1257324398
Epoch:   400  |  train loss: 0.1257324338
Epoch:   500  |  train loss: 0.1257324398
Epoch:   600  |  train loss: 0.1257324308
Epoch:   700  |  train loss: 0.1257324323
Epoch:   800  |  train loss: 0.1257324368
Epoch:   900  |  train loss: 0.1257324353
Epoch:  1000  |  train loss: 0.1257324293
Epoch:  1100  |  train loss: 0.1257324323
Epoch:  1200  |  train loss: 0.1257324383
Epoch:  1300  |  train loss: 0.1257324368
Epoch:  1400  |  train loss: 0.1257324383
Epoch:  1500  |  train loss: 0.1257324398
Epoch:  1600  |  train loss: 0.1257324427
Epoch:  1700  |  train loss: 0.1257324353
Epoch:  1800  |  train loss: 0.1257324353
Epoch:  1900  |  train loss: 0.1257324383
Epoch:  2000  |  train loss: 0.1257324368
Processing class: 9
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1244437024
Epoch:   200  |  train loss: 0.1244437069
Epoch:   300  |  train loss: 0.1244437039
Epoch:   400  |  train loss: 0.1244437009
Epoch:   500  |  train loss: 0.1244437143
Epoch:   600  |  train loss: 0.1244437084
Epoch:   700  |  train loss: 0.1244437054
Epoch:   800  |  train loss: 0.1244437069
Epoch:   900  |  train loss: 0.1244437069
Epoch:  1000  |  train loss: 0.1244437024
Epoch:  1100  |  train loss: 0.1244437024
Epoch:  1200  |  train loss: 0.1244437039
Epoch:  1300  |  train loss: 0.1244437084
Epoch:  1400  |  train loss: 0.1244437024
Epoch:  1500  |  train loss: 0.1244437024
Epoch:  1600  |  train loss: 0.1244437054
Epoch:  1700  |  train loss: 0.1244437039
Epoch:  1800  |  train loss: 0.1244437054
Epoch:  1900  |  train loss: 0.1244437009
Epoch:  2000  |  train loss: 0.1244437039
Processing class: 10
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1266015708
Epoch:   200  |  train loss: 0.1266015753
Epoch:   300  |  train loss: 0.1266015619
Epoch:   400  |  train loss: 0.1266015679
Epoch:   500  |  train loss: 0.1266015738
Epoch:   600  |  train loss: 0.1266015723
Epoch:   700  |  train loss: 0.1266015619
Epoch:   800  |  train loss: 0.1266015694
Epoch:   900  |  train loss: 0.1266015738
Epoch:  1000  |  train loss: 0.1266015679
Epoch:  1100  |  train loss: 0.1266015664
Epoch:  1200  |  train loss: 0.1266015634
Epoch:  1300  |  train loss: 0.1266015679
Epoch:  1400  |  train loss: 0.1266015664
Epoch:  1500  |  train loss: 0.1266015679
Epoch:  1600  |  train loss: 0.1266015679
Epoch:  1700  |  train loss: 0.1266015694
Epoch:  1800  |  train loss: 0.1266015619
Epoch:  1900  |  train loss: 0.1266015708
Epoch:  2000  |  train loss: 0.1266015649
Processing class: 11
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1254066810
Epoch:   200  |  train loss: 0.1254066855
Epoch:   300  |  train loss: 0.1254066825
Epoch:   400  |  train loss: 0.1254066840
Epoch:   500  |  train loss: 0.1254066736
Epoch:   600  |  train loss: 0.1254066780
Epoch:   700  |  train loss: 0.1254066750
Epoch:   800  |  train loss: 0.1254066825
Epoch:   900  |  train loss: 0.1254066780
Epoch:  1000  |  train loss: 0.1254066765
Epoch:  1100  |  train loss: 0.1254066765
Epoch:  1200  |  train loss: 0.1254066870
Epoch:  1300  |  train loss: 0.1254066840
Epoch:  1400  |  train loss: 0.1254066780
Epoch:  1500  |  train loss: 0.1254066780
Epoch:  1600  |  train loss: 0.1254066810
Epoch:  1700  |  train loss: 0.1254066840
Epoch:  1800  |  train loss: 0.1254066795
Epoch:  1900  |  train loss: 0.1254066765
Epoch:  2000  |  train loss: 0.1254066825
Processing class: 12
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262208745
Epoch:   200  |  train loss: 0.1262208700
Epoch:   300  |  train loss: 0.1262208700
Epoch:   400  |  train loss: 0.1262208730
Epoch:   500  |  train loss: 0.1262208685
Epoch:   600  |  train loss: 0.1262208760
Epoch:   700  |  train loss: 0.1262208730
Epoch:   800  |  train loss: 0.1262208760
Epoch:   900  |  train loss: 0.1262208700
Epoch:  1000  |  train loss: 0.1262208760
Epoch:  1100  |  train loss: 0.1262208730
Epoch:  1200  |  train loss: 0.1262208760
Epoch:  1300  |  train loss: 0.1262208760
Epoch:  1400  |  train loss: 0.1262208730
Epoch:  1500  |  train loss: 0.1262208700
Epoch:  1600  |  train loss: 0.1262208760
Epoch:  1700  |  train loss: 0.1262208745
Epoch:  1800  |  train loss: 0.1262208655
Epoch:  1900  |  train loss: 0.1262208700
Epoch:  2000  |  train loss: 0.1262208730
Processing class: 13
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1251855105
Epoch:   200  |  train loss: 0.1251855046
Epoch:   300  |  train loss: 0.1251855105
Epoch:   400  |  train loss: 0.1251855060
Epoch:   500  |  train loss: 0.1251855075
Epoch:   600  |  train loss: 0.1251855046
Epoch:   700  |  train loss: 0.1251855105
Epoch:   800  |  train loss: 0.1251855060
Epoch:   900  |  train loss: 0.1251855135
Epoch:  1000  |  train loss: 0.1251855075
Epoch:  1100  |  train loss: 0.1251855105
Epoch:  1200  |  train loss: 0.1251855120
Epoch:  1300  |  train loss: 0.1251855060
Epoch:  1400  |  train loss: 0.1251855031
Epoch:  1500  |  train loss: 0.1251855016
Epoch:  1600  |  train loss: 0.1251855135
Epoch:  1700  |  train loss: 0.1251855075
Epoch:  1800  |  train loss: 0.1251855060
Epoch:  1900  |  train loss: 0.1251855150
Epoch:  2000  |  train loss: 0.1251855105
Processing class: 14
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1265516430
Epoch:   200  |  train loss: 0.1265516385
Epoch:   300  |  train loss: 0.1265516490
Epoch:   400  |  train loss: 0.1265516371
Epoch:   500  |  train loss: 0.1265516430
Epoch:   600  |  train loss: 0.1265516400
Epoch:   700  |  train loss: 0.1265516356
Epoch:   800  |  train loss: 0.1265516341
Epoch:   900  |  train loss: 0.1265516400
Epoch:  1000  |  train loss: 0.1265516490
Epoch:  1100  |  train loss: 0.1265516371
Epoch:  1200  |  train loss: 0.1265516490
Epoch:  1300  |  train loss: 0.1265516460
Epoch:  1400  |  train loss: 0.1265516460
Epoch:  1500  |  train loss: 0.1265516326
Epoch:  1600  |  train loss: 0.1265516400
Epoch:  1700  |  train loss: 0.1265516430
Epoch:  1800  |  train loss: 0.1265516430
Epoch:  1900  |  train loss: 0.1265516371
Epoch:  2000  |  train loss: 0.1265516430
Processing class: 15
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1249787256
Epoch:   200  |  train loss: 0.1249787152
Epoch:   300  |  train loss: 0.1249787197
Epoch:   400  |  train loss: 0.1249787167
Epoch:   500  |  train loss: 0.1249787167
Epoch:   600  |  train loss: 0.1249787286
Epoch:   700  |  train loss: 0.1249787197
Epoch:   800  |  train loss: 0.1249787182
Epoch:   900  |  train loss: 0.1249787211
Epoch:  1000  |  train loss: 0.1249787197
Epoch:  1100  |  train loss: 0.1249787167
Epoch:  1200  |  train loss: 0.1249787182
Epoch:  1300  |  train loss: 0.1249787241
Epoch:  1400  |  train loss: 0.1249787301
Epoch:  1500  |  train loss: 0.1249787226
Epoch:  1600  |  train loss: 0.1249787286
Epoch:  1700  |  train loss: 0.1249787167
Epoch:  1800  |  train loss: 0.1249787241
Epoch:  1900  |  train loss: 0.1249787211
Epoch:  2000  |  train loss: 0.1249787167
Processing class: 16
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1259115860
Epoch:   200  |  train loss: 0.1259115964
Epoch:   300  |  train loss: 0.1259115905
Epoch:   400  |  train loss: 0.1259115919
Epoch:   500  |  train loss: 0.1259115890
Epoch:   600  |  train loss: 0.1259115964
Epoch:   700  |  train loss: 0.1259115905
Epoch:   800  |  train loss: 0.1259115875
Epoch:   900  |  train loss: 0.1259115919
Epoch:  1000  |  train loss: 0.1259115890
Epoch:  1100  |  train loss: 0.1259115919
Epoch:  1200  |  train loss: 0.1259115875
Epoch:  1300  |  train loss: 0.1259115890
Epoch:  1400  |  train loss: 0.1259115860
Epoch:  1500  |  train loss: 0.1259115905
Epoch:  1600  |  train loss: 0.1259115964
Epoch:  1700  |  train loss: 0.1259115919
Epoch:  1800  |  train loss: 0.1259115905
Epoch:  1900  |  train loss: 0.1259115905
Epoch:  2000  |  train loss: 0.1259115934
Processing class: 17
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 18
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1252879411
Epoch:   200  |  train loss: 0.1252879456
Epoch:   300  |  train loss: 0.1252879515
Epoch:   400  |  train loss: 0.1252879500
Epoch:   500  |  train loss: 0.1252879500
Epoch:   600  |  train loss: 0.1252879441
Epoch:   700  |  train loss: 0.1252879500
Epoch:   800  |  train loss: 0.1252879530
Epoch:   900  |  train loss: 0.1252879515
Epoch:  1000  |  train loss: 0.1252879456
Epoch:  1100  |  train loss: 0.1252879471
Epoch:  1200  |  train loss: 0.1252879530
Epoch:  1300  |  train loss: 0.1252879426
Epoch:  1400  |  train loss: 0.1252879471
Epoch:  1500  |  train loss: 0.1252879441
Epoch:  1600  |  train loss: 0.1252879471
Epoch:  1700  |  train loss: 0.1252879485
Epoch:  1800  |  train loss: 0.1252879530
Epoch:  1900  |  train loss: 0.1252879515
Epoch:  2000  |  train loss: 0.1252879471
Processing class: 19
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1219928533
Epoch:   200  |  train loss: 0.1219928488
Epoch:   300  |  train loss: 0.1219928578
Epoch:   400  |  train loss: 0.1219928592
Epoch:   500  |  train loss: 0.1219928607
Epoch:   600  |  train loss: 0.1219928592
Epoch:   700  |  train loss: 0.1219928578
Epoch:   800  |  train loss: 0.1219928548
Epoch:   900  |  train loss: 0.1219928622
Epoch:  1000  |  train loss: 0.1219928548
Epoch:  1100  |  train loss: 0.1219928518
Epoch:  1200  |  train loss: 0.1219928607
Epoch:  1300  |  train loss: 0.1219928533
Epoch:  1400  |  train loss: 0.1219928518
Epoch:  1500  |  train loss: 0.1219928518
Epoch:  1600  |  train loss: 0.1219928578
Epoch:  1700  |  train loss: 0.1219928473
Epoch:  1800  |  train loss: 0.1219928622
Epoch:  1900  |  train loss: 0.1219928548
Epoch:  2000  |  train loss: 0.1219928563
Processing class: 20
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1248881161
Epoch:   200  |  train loss: 0.1248881117
Epoch:   300  |  train loss: 0.1248881087
Epoch:   400  |  train loss: 0.1248881102
Epoch:   500  |  train loss: 0.1248881131
Epoch:   600  |  train loss: 0.1248881102
Epoch:   700  |  train loss: 0.1248881117
Epoch:   800  |  train loss: 0.1248881072
Epoch:   900  |  train loss: 0.1248881206
Epoch:  1000  |  train loss: 0.1248881176
Epoch:  1100  |  train loss: 0.1248881087
Epoch:  1200  |  train loss: 0.1248881087
Epoch:  1300  |  train loss: 0.1248881146
Epoch:  1400  |  train loss: 0.1248881087
Epoch:  1500  |  train loss: 0.1248881206
Epoch:  1600  |  train loss: 0.1248881146
Epoch:  1700  |  train loss: 0.1248881131
Epoch:  1800  |  train loss: 0.1248881146
Epoch:  1900  |  train loss: 0.1248881176
Epoch:  2000  |  train loss: 0.1248881102
Processing class: 21
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 22
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1266234815
Epoch:   200  |  train loss: 0.1266234830
Epoch:   300  |  train loss: 0.1266234905
Epoch:   400  |  train loss: 0.1266234845
Epoch:   500  |  train loss: 0.1266234934
Epoch:   600  |  train loss: 0.1266234860
Epoch:   700  |  train loss: 0.1266234875
Epoch:   800  |  train loss: 0.1266234890
Epoch:   900  |  train loss: 0.1266234875
Epoch:  1000  |  train loss: 0.1266234875
Epoch:  1100  |  train loss: 0.1266234905
Epoch:  1200  |  train loss: 0.1266234815
Epoch:  1300  |  train loss: 0.1266234815
Epoch:  1400  |  train loss: 0.1266234905
Epoch:  1500  |  train loss: 0.1266234785
Epoch:  1600  |  train loss: 0.1266234815
Epoch:  1700  |  train loss: 0.1266234845
Epoch:  1800  |  train loss: 0.1266234875
Epoch:  1900  |  train loss: 0.1266234770
Epoch:  2000  |  train loss: 0.1266234875
Processing class: 23
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1255778253
Epoch:   200  |  train loss: 0.1255778298
Epoch:   300  |  train loss: 0.1255778313
Epoch:   400  |  train loss: 0.1255778223
Epoch:   500  |  train loss: 0.1255778298
Epoch:   600  |  train loss: 0.1255778268
Epoch:   700  |  train loss: 0.1255778238
Epoch:   800  |  train loss: 0.1255778283
Epoch:   900  |  train loss: 0.1255778208
Epoch:  1000  |  train loss: 0.1255778328
Epoch:  1100  |  train loss: 0.1255778268
Epoch:  1200  |  train loss: 0.1255778298
Epoch:  1300  |  train loss: 0.1255778313
Epoch:  1400  |  train loss: 0.1255778298
Epoch:  1500  |  train loss: 0.1255778268
Epoch:  1600  |  train loss: 0.1255778313
Epoch:  1700  |  train loss: 0.1255778253
Epoch:  1800  |  train loss: 0.1255778253
Epoch:  1900  |  train loss: 0.1255778298
Epoch:  2000  |  train loss: 0.1255778283
Processing class: 24
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1258374661
Epoch:   200  |  train loss: 0.1258374646
Epoch:   300  |  train loss: 0.1258374617
Epoch:   400  |  train loss: 0.1258374617
Epoch:   500  |  train loss: 0.1258374631
Epoch:   600  |  train loss: 0.1258374631
Epoch:   700  |  train loss: 0.1258374602
Epoch:   800  |  train loss: 0.1258374631
Epoch:   900  |  train loss: 0.1258374676
Epoch:  1000  |  train loss: 0.1258374661
Epoch:  1100  |  train loss: 0.1258374646
Epoch:  1200  |  train loss: 0.1258374602
Epoch:  1300  |  train loss: 0.1258374617
Epoch:  1400  |  train loss: 0.1258374646
Epoch:  1500  |  train loss: 0.1258374676
Epoch:  1600  |  train loss: 0.1258374587
Epoch:  1700  |  train loss: 0.1258374646
Epoch:  1800  |  train loss: 0.1258374631
Epoch:  1900  |  train loss: 0.1258374661
Epoch:  2000  |  train loss: 0.1258374661
Processing class: 25
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1257242247
Epoch:   200  |  train loss: 0.1257242188
Epoch:   300  |  train loss: 0.1257242233
Epoch:   400  |  train loss: 0.1257242188
Epoch:   500  |  train loss: 0.1257242247
Epoch:   600  |  train loss: 0.1257242247
Epoch:   700  |  train loss: 0.1257242247
Epoch:   800  |  train loss: 0.1257242277
Epoch:   900  |  train loss: 0.1257242218
Epoch:  1000  |  train loss: 0.1257242247
Epoch:  1100  |  train loss: 0.1257242203
Epoch:  1200  |  train loss: 0.1257242188
Epoch:  1300  |  train loss: 0.1257242307
Epoch:  1400  |  train loss: 0.1257242307
Epoch:  1500  |  train loss: 0.1257242262
Epoch:  1600  |  train loss: 0.1257242233
Epoch:  1700  |  train loss: 0.1257242203
Epoch:  1800  |  train loss: 0.1257242292
Epoch:  1900  |  train loss: 0.1257242233
Epoch:  2000  |  train loss: 0.1257242173
Processing class: 26
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1266202420
Epoch:   200  |  train loss: 0.1266202390
Epoch:   300  |  train loss: 0.1266202360
Epoch:   400  |  train loss: 0.1266202390
Epoch:   500  |  train loss: 0.1266202331
Epoch:   600  |  train loss: 0.1266202450
Epoch:   700  |  train loss: 0.1266202360
Epoch:   800  |  train loss: 0.1266202360
Epoch:   900  |  train loss: 0.1266202450
Epoch:  1000  |  train loss: 0.1266202420
Epoch:  1100  |  train loss: 0.1266202405
Epoch:  1200  |  train loss: 0.1266202345
Epoch:  1300  |  train loss: 0.1266202390
Epoch:  1400  |  train loss: 0.1266202390
Epoch:  1500  |  train loss: 0.1266202405
Epoch:  1600  |  train loss: 0.1266202360
Epoch:  1700  |  train loss: 0.1266202420
Epoch:  1800  |  train loss: 0.1266202360
Epoch:  1900  |  train loss: 0.1266202420
Epoch:  2000  |  train loss: 0.1266202360
Processing class: 27
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1243224531
Epoch:   200  |  train loss: 0.1243224651
Epoch:   300  |  train loss: 0.1243224621
Epoch:   400  |  train loss: 0.1243224651
Epoch:   500  |  train loss: 0.1243224636
Epoch:   600  |  train loss: 0.1243224621
Epoch:   700  |  train loss: 0.1243224651
Epoch:   800  |  train loss: 0.1243224636
Epoch:   900  |  train loss: 0.1243224621
Epoch:  1000  |  train loss: 0.1243224666
Epoch:  1100  |  train loss: 0.1243224591
Epoch:  1200  |  train loss: 0.1243224606
Epoch:  1300  |  train loss: 0.1243224621
Epoch:  1400  |  train loss: 0.1243224606
Epoch:  1500  |  train loss: 0.1243224636
Epoch:  1600  |  train loss: 0.1243224651
Epoch:  1700  |  train loss: 0.1243224636
Epoch:  1800  |  train loss: 0.1243224561
Epoch:  1900  |  train loss: 0.1243224621
Epoch:  2000  |  train loss: 0.1243224606
Processing class: 28
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262274832
Epoch:   200  |  train loss: 0.1262274936
Epoch:   300  |  train loss: 0.1262274921
Epoch:   400  |  train loss: 0.1262274951
Epoch:   500  |  train loss: 0.1262274936
Epoch:   600  |  train loss: 0.1262274951
Epoch:   700  |  train loss: 0.1262274921
Epoch:   800  |  train loss: 0.1262274891
Epoch:   900  |  train loss: 0.1262274951
Epoch:  1000  |  train loss: 0.1262274921
Epoch:  1100  |  train loss: 0.1262274921
Epoch:  1200  |  train loss: 0.1262274936
Epoch:  1300  |  train loss: 0.1262274891
Epoch:  1400  |  train loss: 0.1262274936
Epoch:  1500  |  train loss: 0.1262274891
Epoch:  1600  |  train loss: 0.1262274921
Epoch:  1700  |  train loss: 0.1262274861
Epoch:  1800  |  train loss: 0.1262274891
Epoch:  1900  |  train loss: 0.1262274921
Epoch:  2000  |  train loss: 0.1262274966
Processing class: 29
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1251156524
Epoch:   200  |  train loss: 0.1251156494
Epoch:   300  |  train loss: 0.1251156479
Epoch:   400  |  train loss: 0.1251156479
Epoch:   500  |  train loss: 0.1251156494
Epoch:   600  |  train loss: 0.1251156479
Epoch:   700  |  train loss: 0.1251156464
Epoch:   800  |  train loss: 0.1251156524
Epoch:   900  |  train loss: 0.1251156494
Epoch:  1000  |  train loss: 0.1251156434
Epoch:  1100  |  train loss: 0.1251156509
Epoch:  1200  |  train loss: 0.1251156494
Epoch:  1300  |  train loss: 0.1251156539
Epoch:  1400  |  train loss: 0.1251156554
Epoch:  1500  |  train loss: 0.1251156524
Epoch:  1600  |  train loss: 0.1251156479
Epoch:  1700  |  train loss: 0.1251156479
Epoch:  1800  |  train loss: 0.1251156524
Epoch:  1900  |  train loss: 0.1251156524
Epoch:  2000  |  train loss: 0.1251156434
Processing class: 30
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1253981680
Epoch:   200  |  train loss: 0.1253981680
Epoch:   300  |  train loss: 0.1253981695
Epoch:   400  |  train loss: 0.1253981590
Epoch:   500  |  train loss: 0.1253981620
Epoch:   600  |  train loss: 0.1253981635
Epoch:   700  |  train loss: 0.1253981695
Epoch:   800  |  train loss: 0.1253981650
Epoch:   900  |  train loss: 0.1253981695
Epoch:  1000  |  train loss: 0.1253981695
Epoch:  1100  |  train loss: 0.1253981635
Epoch:  1200  |  train loss: 0.1253981635
Epoch:  1300  |  train loss: 0.1253981665
Epoch:  1400  |  train loss: 0.1253981650
Epoch:  1500  |  train loss: 0.1253981665
Epoch:  1600  |  train loss: 0.1253981650
Epoch:  1700  |  train loss: 0.1253981665
Epoch:  1800  |  train loss: 0.1253981560
Epoch:  1900  |  train loss: 0.1253981635
Epoch:  2000  |  train loss: 0.1253981650
Processing class: 31
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 32
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262165338
Epoch:   200  |  train loss: 0.1262165368
Epoch:   300  |  train loss: 0.1262165368
Epoch:   400  |  train loss: 0.1262165383
Epoch:   500  |  train loss: 0.1262165383
Epoch:   600  |  train loss: 0.1262165353
Epoch:   700  |  train loss: 0.1262165368
Epoch:   800  |  train loss: 0.1262165397
Epoch:   900  |  train loss: 0.1262165383
Epoch:  1000  |  train loss: 0.1262165368
Epoch:  1100  |  train loss: 0.1262165323
Epoch:  1200  |  train loss: 0.1262165397
Epoch:  1300  |  train loss: 0.1262165308
Epoch:  1400  |  train loss: 0.1262165427
Epoch:  1500  |  train loss: 0.1262165368
Epoch:  1600  |  train loss: 0.1262165397
Epoch:  1700  |  train loss: 0.1262165368
Epoch:  1800  |  train loss: 0.1262165412
Epoch:  1900  |  train loss: 0.1262165397
Epoch:  2000  |  train loss: 0.1262165397
Processing class: 33
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 34
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1253545672
Epoch:   200  |  train loss: 0.1253545687
Epoch:   300  |  train loss: 0.1253545657
Epoch:   400  |  train loss: 0.1253545687
Epoch:   500  |  train loss: 0.1253545672
Epoch:   600  |  train loss: 0.1253545642
Epoch:   700  |  train loss: 0.1253545672
Epoch:   800  |  train loss: 0.1253545657
Epoch:   900  |  train loss: 0.1253545702
Epoch:  1000  |  train loss: 0.1253545657
Epoch:  1100  |  train loss: 0.1253545716
Epoch:  1200  |  train loss: 0.1253545687
Epoch:  1300  |  train loss: 0.1253545642
Epoch:  1400  |  train loss: 0.1253545687
Epoch:  1500  |  train loss: 0.1253545687
Epoch:  1600  |  train loss: 0.1253545672
Epoch:  1700  |  train loss: 0.1253545597
Epoch:  1800  |  train loss: 0.1253545627
Epoch:  1900  |  train loss: 0.1253545702
Epoch:  2000  |  train loss: 0.1253545627
Processing class: 35
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 36
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1255585775
Epoch:   200  |  train loss: 0.1255585700
Epoch:   300  |  train loss: 0.1255585790
Epoch:   400  |  train loss: 0.1255585760
Epoch:   500  |  train loss: 0.1255585745
Epoch:   600  |  train loss: 0.1255585775
Epoch:   700  |  train loss: 0.1255585805
Epoch:   800  |  train loss: 0.1255585775
Epoch:   900  |  train loss: 0.1255585760
Epoch:  1000  |  train loss: 0.1255585745
Epoch:  1100  |  train loss: 0.1255585685
Epoch:  1200  |  train loss: 0.1255585730
Epoch:  1300  |  train loss: 0.1255585775
Epoch:  1400  |  train loss: 0.1255585760
Epoch:  1500  |  train loss: 0.1255585819
Epoch:  1600  |  train loss: 0.1255585760
Epoch:  1700  |  train loss: 0.1255585775
Epoch:  1800  |  train loss: 0.1255585849
Epoch:  1900  |  train loss: 0.1255585760
Epoch:  2000  |  train loss: 0.1255585700
Processing class: 37
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1259172276
Epoch:   200  |  train loss: 0.1259172291
Epoch:   300  |  train loss: 0.1259172276
Epoch:   400  |  train loss: 0.1259172276
Epoch:   500  |  train loss: 0.1259172276
Epoch:   600  |  train loss: 0.1259172246
Epoch:   700  |  train loss: 0.1259172246
Epoch:   800  |  train loss: 0.1259172276
Epoch:   900  |  train loss: 0.1259172231
Epoch:  1000  |  train loss: 0.1259172261
Epoch:  1100  |  train loss: 0.1259172320
Epoch:  1200  |  train loss: 0.1259172261
Epoch:  1300  |  train loss: 0.1259172276
Epoch:  1400  |  train loss: 0.1259172305
Epoch:  1500  |  train loss: 0.1259172231
Epoch:  1600  |  train loss: 0.1259172261
Epoch:  1700  |  train loss: 0.1259172305
Epoch:  1800  |  train loss: 0.1259172335
Epoch:  1900  |  train loss: 0.1259172246
Epoch:  2000  |  train loss: 0.1259172291
Processing class: 38
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1248591736
Epoch:   200  |  train loss: 0.1248591736
Epoch:   300  |  train loss: 0.1248591706
Epoch:   400  |  train loss: 0.1248591721
Epoch:   500  |  train loss: 0.1248591721
Epoch:   600  |  train loss: 0.1248591706
Epoch:   700  |  train loss: 0.1248591736
Epoch:   800  |  train loss: 0.1248591766
Epoch:   900  |  train loss: 0.1248591736
Epoch:  1000  |  train loss: 0.1248591766
Epoch:  1100  |  train loss: 0.1248591751
Epoch:  1200  |  train loss: 0.1248591721
Epoch:  1300  |  train loss: 0.1248591766
Epoch:  1400  |  train loss: 0.1248591721
Epoch:  1500  |  train loss: 0.1248591810
Epoch:  1600  |  train loss: 0.1248591691
Epoch:  1700  |  train loss: 0.1248591736
Epoch:  1800  |  train loss: 0.1248591796
Epoch:  1900  |  train loss: 0.1248591736
Epoch:  2000  |  train loss: 0.1248591810
Processing class: 39
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261693120
Epoch:   200  |  train loss: 0.1261693195
Epoch:   300  |  train loss: 0.1261693180
Epoch:   400  |  train loss: 0.1261693165
Epoch:   500  |  train loss: 0.1261693120
Epoch:   600  |  train loss: 0.1261693075
Epoch:   700  |  train loss: 0.1261693180
Epoch:   800  |  train loss: 0.1261693075
Epoch:   900  |  train loss: 0.1261693165
Epoch:  1000  |  train loss: 0.1261693165
Epoch:  1100  |  train loss: 0.1261693165
Epoch:  1200  |  train loss: 0.1261693209
Epoch:  1300  |  train loss: 0.1261693120
Epoch:  1400  |  train loss: 0.1261693209
Epoch:  1500  |  train loss: 0.1261693135
Epoch:  1600  |  train loss: 0.1261693224
Epoch:  1700  |  train loss: 0.1261693090
Epoch:  1800  |  train loss: 0.1261693135
Epoch:  1900  |  train loss: 0.1261693224
Epoch:  2000  |  train loss: 0.1261693150
Processing class: 40
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1260821640
Epoch:   200  |  train loss: 0.1260821626
Epoch:   300  |  train loss: 0.1260821566
Epoch:   400  |  train loss: 0.1260821581
Epoch:   500  |  train loss: 0.1260821715
Epoch:   600  |  train loss: 0.1260821640
Epoch:   700  |  train loss: 0.1260821640
Epoch:   800  |  train loss: 0.1260821655
Epoch:   900  |  train loss: 0.1260821655
Epoch:  1000  |  train loss: 0.1260821611
Epoch:  1100  |  train loss: 0.1260821670
Epoch:  1200  |  train loss: 0.1260821596
Epoch:  1300  |  train loss: 0.1260821626
Epoch:  1400  |  train loss: 0.1260821611
Epoch:  1500  |  train loss: 0.1260821581
Epoch:  1600  |  train loss: 0.1260821611
Epoch:  1700  |  train loss: 0.1260821640
Epoch:  1800  |  train loss: 0.1260821596
Epoch:  1900  |  train loss: 0.1260821670
Epoch:  2000  |  train loss: 0.1260821611
Processing class: 41
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1256636560
Epoch:   200  |  train loss: 0.1256636500
Epoch:   300  |  train loss: 0.1256636500
Epoch:   400  |  train loss: 0.1256636545
Epoch:   500  |  train loss: 0.1256636456
Epoch:   600  |  train loss: 0.1256636515
Epoch:   700  |  train loss: 0.1256636485
Epoch:   800  |  train loss: 0.1256636515
Epoch:   900  |  train loss: 0.1256636515
Epoch:  1000  |  train loss: 0.1256636500
Epoch:  1100  |  train loss: 0.1256636530
Epoch:  1200  |  train loss: 0.1256636485
Epoch:  1300  |  train loss: 0.1256636485
Epoch:  1400  |  train loss: 0.1256636575
Epoch:  1500  |  train loss: 0.1256636515
Epoch:  1600  |  train loss: 0.1256636500
Epoch:  1700  |  train loss: 0.1256636500
Epoch:  1800  |  train loss: 0.1256636471
Epoch:  1900  |  train loss: 0.1256636500
Epoch:  2000  |  train loss: 0.1256636530
Processing class: 42
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1255487442
Epoch:   200  |  train loss: 0.1255487457
Epoch:   300  |  train loss: 0.1255487382
Epoch:   400  |  train loss: 0.1255487368
Epoch:   500  |  train loss: 0.1255487457
Epoch:   600  |  train loss: 0.1255487382
Epoch:   700  |  train loss: 0.1255487427
Epoch:   800  |  train loss: 0.1255487397
Epoch:   900  |  train loss: 0.1255487442
Epoch:  1000  |  train loss: 0.1255487382
Epoch:  1100  |  train loss: 0.1255487412
Epoch:  1200  |  train loss: 0.1255487442
Epoch:  1300  |  train loss: 0.1255487397
Epoch:  1400  |  train loss: 0.1255487442
Epoch:  1500  |  train loss: 0.1255487412
Epoch:  1600  |  train loss: 0.1255487427
Epoch:  1700  |  train loss: 0.1255487412
Epoch:  1800  |  train loss: 0.1255487412
Epoch:  1900  |  train loss: 0.1255487487
Epoch:  2000  |  train loss: 0.1255487442
Processing class: 43
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1268294036
Epoch:   200  |  train loss: 0.1268294066
Epoch:   300  |  train loss: 0.1268294007
Epoch:   400  |  train loss: 0.1268294007
Epoch:   500  |  train loss: 0.1268294066
Epoch:   600  |  train loss: 0.1268293977
Epoch:   700  |  train loss: 0.1268294036
Epoch:   800  |  train loss: 0.1268294007
Epoch:   900  |  train loss: 0.1268293977
Epoch:  1000  |  train loss: 0.1268294007
Epoch:  1100  |  train loss: 0.1268294051
Epoch:  1200  |  train loss: 0.1268294096
Epoch:  1300  |  train loss: 0.1268294036
Epoch:  1400  |  train loss: 0.1268294036
Epoch:  1500  |  train loss: 0.1268294036
Epoch:  1600  |  train loss: 0.1268294066
Epoch:  1700  |  train loss: 0.1268294007
Epoch:  1800  |  train loss: 0.1268294036
Epoch:  1900  |  train loss: 0.1268294036
Epoch:  2000  |  train loss: 0.1268293917
Processing class: 44
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261474848
Epoch:   200  |  train loss: 0.1261474848
Epoch:   300  |  train loss: 0.1261474907
Epoch:   400  |  train loss: 0.1261474833
Epoch:   500  |  train loss: 0.1261474788
Epoch:   600  |  train loss: 0.1261474892
Epoch:   700  |  train loss: 0.1261474907
Epoch:   800  |  train loss: 0.1261474952
Epoch:   900  |  train loss: 0.1261474878
Epoch:  1000  |  train loss: 0.1261474848
Epoch:  1100  |  train loss: 0.1261474803
Epoch:  1200  |  train loss: 0.1261474878
Epoch:  1300  |  train loss: 0.1261474818
Epoch:  1400  |  train loss: 0.1261474848
Epoch:  1500  |  train loss: 0.1261474863
Epoch:  1600  |  train loss: 0.1261474848
Epoch:  1700  |  train loss: 0.1261474833
Epoch:  1800  |  train loss: 0.1261474878
Epoch:  1900  |  train loss: 0.1261474892
Epoch:  2000  |  train loss: 0.1261474907
Processing class: 45
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1259788066
Epoch:   200  |  train loss: 0.1259788066
Epoch:   300  |  train loss: 0.1259788036
Epoch:   400  |  train loss: 0.1259788156
Epoch:   500  |  train loss: 0.1259788036
Epoch:   600  |  train loss: 0.1259788051
Epoch:   700  |  train loss: 0.1259788007
Epoch:   800  |  train loss: 0.1259788096
Epoch:   900  |  train loss: 0.1259788066
Epoch:  1000  |  train loss: 0.1259788036
Epoch:  1100  |  train loss: 0.1259788036
Epoch:  1200  |  train loss: 0.1259788081
Epoch:  1300  |  train loss: 0.1259788126
Epoch:  1400  |  train loss: 0.1259788081
Epoch:  1500  |  train loss: 0.1259788066
Epoch:  1600  |  train loss: 0.1259788126
Epoch:  1700  |  train loss: 0.1259787977
Epoch:  1800  |  train loss: 0.1259788051
Epoch:  1900  |  train loss: 0.1259788066
Epoch:  2000  |  train loss: 0.1259788096
Processing class: 46
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1259184524
Epoch:   200  |  train loss: 0.1259184495
Epoch:   300  |  train loss: 0.1259184480
Epoch:   400  |  train loss: 0.1259184539
Epoch:   500  |  train loss: 0.1259184539
Epoch:   600  |  train loss: 0.1259184599
Epoch:   700  |  train loss: 0.1259184510
Epoch:   800  |  train loss: 0.1259184480
Epoch:   900  |  train loss: 0.1259184539
Epoch:  1000  |  train loss: 0.1259184554
Epoch:  1100  |  train loss: 0.1259184495
Epoch:  1200  |  train loss: 0.1259184554
Epoch:  1300  |  train loss: 0.1259184584
Epoch:  1400  |  train loss: 0.1259184510
Epoch:  1500  |  train loss: 0.1259184539
Epoch:  1600  |  train loss: 0.1259184510
Epoch:  1700  |  train loss: 0.1259184495
Epoch:  1800  |  train loss: 0.1259184510
Epoch:  1900  |  train loss: 0.1259184524
Epoch:  2000  |  train loss: 0.1259184539
Processing class: 47
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1256756783
Epoch:   200  |  train loss: 0.1256756693
Epoch:   300  |  train loss: 0.1256756842
Epoch:   400  |  train loss: 0.1256756753
Epoch:   500  |  train loss: 0.1256756783
Epoch:   600  |  train loss: 0.1256756783
Epoch:   700  |  train loss: 0.1256756753
Epoch:   800  |  train loss: 0.1256756783
Epoch:   900  |  train loss: 0.1256756708
Epoch:  1000  |  train loss: 0.1256756783
Epoch:  1100  |  train loss: 0.1256756768
Epoch:  1200  |  train loss: 0.1256756842
Epoch:  1300  |  train loss: 0.1256756783
Epoch:  1400  |  train loss: 0.1256756768
Epoch:  1500  |  train loss: 0.1256756768
Epoch:  1600  |  train loss: 0.1256756827
Epoch:  1700  |  train loss: 0.1256756812
Epoch:  1800  |  train loss: 0.1256756753
Epoch:  1900  |  train loss: 0.1256756783
Epoch:  2000  |  train loss: 0.1256756738
Processing class: 48
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1256415069
Epoch:   200  |  train loss: 0.1256415114
Epoch:   300  |  train loss: 0.1256415144
Epoch:   400  |  train loss: 0.1256415084
Epoch:   500  |  train loss: 0.1256415144
Epoch:   600  |  train loss: 0.1256415069
Epoch:   700  |  train loss: 0.1256415129
Epoch:   800  |  train loss: 0.1256415099
Epoch:   900  |  train loss: 0.1256415144
Epoch:  1000  |  train loss: 0.1256415084
Epoch:  1100  |  train loss: 0.1256415069
Epoch:  1200  |  train loss: 0.1256415039
Epoch:  1300  |  train loss: 0.1256415114
Epoch:  1400  |  train loss: 0.1256415159
Epoch:  1500  |  train loss: 0.1256415069
Epoch:  1600  |  train loss: 0.1256415084
Epoch:  1700  |  train loss: 0.1256415099
Epoch:  1800  |  train loss: 0.1256415084
Epoch:  1900  |  train loss: 0.1256415069
Epoch:  2000  |  train loss: 0.1256415114
Processing class: 49
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Clasifying using reconstruction function cost
/home/z1165703/FeCAM/models/base.py:195: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data_point = torch.tensor(data_point).float().cuda()
2024-04-02 05:22:41,023 [trainer.py] => CNN: {'total': 83.44, '00-09': 87.7, '10-19': 79.6, '20-29': 84.9, '30-39': 81.0, '40-49': 84.0, 'old': 0, 'new': 83.44}
2024-04-02 05:22:41,024 [trainer.py] => No NME accuracy
2024-04-02 05:22:41,024 [trainer.py] => FeCAM: {'total': 71.08, '00-09': 78.1, '10-19': 65.1, '20-29': 73.8, '30-39': 66.3, '40-49': 72.1, 'old': 0, 'new': 71.08}
2024-04-02 05:22:41,024 [trainer.py] => CNN top1 curve: [83.44]
2024-04-02 05:22:41,024 [trainer.py] => CNN top5 curve: [96.5]
2024-04-02 05:22:41,024 [trainer.py] => FeCAM top1 curve: [71.08]
2024-04-02 05:22:41,024 [trainer.py] => FeCAM top5 curve: [86.36]

2024-04-02 05:22:41,028 [fecam.py] => Learning on 50-60
Processing class: 50
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1263086542
Epoch:   200  |  train loss: 0.1263086602
Epoch:   300  |  train loss: 0.1263086528
Epoch:   400  |  train loss: 0.1263086528
Epoch:   500  |  train loss: 0.1263086587
Epoch:   600  |  train loss: 0.1263086528
Epoch:   700  |  train loss: 0.1263086602
Epoch:   800  |  train loss: 0.1263086587
Epoch:   900  |  train loss: 0.1263086542
Epoch:  1000  |  train loss: 0.1263086587
Epoch:  1100  |  train loss: 0.1263086617
Epoch:  1200  |  train loss: 0.1263086587
Epoch:  1300  |  train loss: 0.1263086557
Epoch:  1400  |  train loss: 0.1263086542
Epoch:  1500  |  train loss: 0.1263086542
Epoch:  1600  |  train loss: 0.1263086557
Epoch:  1700  |  train loss: 0.1263086617
Epoch:  1800  |  train loss: 0.1263086498
Epoch:  1900  |  train loss: 0.1263086587
Epoch:  2000  |  train loss: 0.1263086557
Processing class: 51
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1268122897
Epoch:   200  |  train loss: 0.1268122911
Epoch:   300  |  train loss: 0.1268122941
Epoch:   400  |  train loss: 0.1268122911
Epoch:   500  |  train loss: 0.1268122867
Epoch:   600  |  train loss: 0.1268122911
Epoch:   700  |  train loss: 0.1268122882
Epoch:   800  |  train loss: 0.1268122941
Epoch:   900  |  train loss: 0.1268122897
Epoch:  1000  |  train loss: 0.1268122822
Epoch:  1100  |  train loss: 0.1268122882
Epoch:  1200  |  train loss: 0.1268122941
Epoch:  1300  |  train loss: 0.1268122897
Epoch:  1400  |  train loss: 0.1268122897
Epoch:  1500  |  train loss: 0.1268122941
Epoch:  1600  |  train loss: 0.1268122897
Epoch:  1700  |  train loss: 0.1268122897
Epoch:  1800  |  train loss: 0.1268122822
Epoch:  1900  |  train loss: 0.1268122911
Epoch:  2000  |  train loss: 0.1268122867
Processing class: 52
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1263964370
Epoch:   200  |  train loss: 0.1263964385
Epoch:   300  |  train loss: 0.1263964400
Epoch:   400  |  train loss: 0.1263964415
Epoch:   500  |  train loss: 0.1263964325
Epoch:   600  |  train loss: 0.1263964385
Epoch:   700  |  train loss: 0.1263964325
Epoch:   800  |  train loss: 0.1263964355
Epoch:   900  |  train loss: 0.1263964400
Epoch:  1000  |  train loss: 0.1263964370
Epoch:  1100  |  train loss: 0.1263964355
Epoch:  1200  |  train loss: 0.1263964400
Epoch:  1300  |  train loss: 0.1263964429
Epoch:  1400  |  train loss: 0.1263964385
Epoch:  1500  |  train loss: 0.1263964325
Epoch:  1600  |  train loss: 0.1263964385
Epoch:  1700  |  train loss: 0.1263964400
Epoch:  1800  |  train loss: 0.1263964385
Epoch:  1900  |  train loss: 0.1263964385
Epoch:  2000  |  train loss: 0.1263964385
Processing class: 53
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261929601
Epoch:   200  |  train loss: 0.1261929572
Epoch:   300  |  train loss: 0.1261929661
Epoch:   400  |  train loss: 0.1261929676
Epoch:   500  |  train loss: 0.1261929631
Epoch:   600  |  train loss: 0.1261929661
Epoch:   700  |  train loss: 0.1261929661
Epoch:   800  |  train loss: 0.1261929631
Epoch:   900  |  train loss: 0.1261929706
Epoch:  1000  |  train loss: 0.1261929601
Epoch:  1100  |  train loss: 0.1261929646
Epoch:  1200  |  train loss: 0.1261929631
Epoch:  1300  |  train loss: 0.1261929631
Epoch:  1400  |  train loss: 0.1261929661
Epoch:  1500  |  train loss: 0.1261929706
Epoch:  1600  |  train loss: 0.1261929721
Epoch:  1700  |  train loss: 0.1261929631
Epoch:  1800  |  train loss: 0.1261929646
Epoch:  1900  |  train loss: 0.1261929631
Epoch:  2000  |  train loss: 0.1261929646
Processing class: 54
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1189526796
Epoch:   200  |  train loss: 0.1189526811
Epoch:   300  |  train loss: 0.1189526767
Epoch:   400  |  train loss: 0.1189526796
Epoch:   500  |  train loss: 0.1189526871
Epoch:   600  |  train loss: 0.1189526871
Epoch:   700  |  train loss: 0.1189526796
Epoch:   800  |  train loss: 0.1189526871
Epoch:   900  |  train loss: 0.1189526811
Epoch:  1000  |  train loss: 0.1189526796
Epoch:  1100  |  train loss: 0.1189526856
Epoch:  1200  |  train loss: 0.1189526841
Epoch:  1300  |  train loss: 0.1189526826
Epoch:  1400  |  train loss: 0.1189526841
Epoch:  1500  |  train loss: 0.1189526811
Epoch:  1600  |  train loss: 0.1189526796
Epoch:  1700  |  train loss: 0.1189526826
Epoch:  1800  |  train loss: 0.1189526796
Epoch:  1900  |  train loss: 0.1189526841
Epoch:  2000  |  train loss: 0.1189526871
Processing class: 55
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 56
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262668386
Epoch:   200  |  train loss: 0.1262668386
Epoch:   300  |  train loss: 0.1262668401
Epoch:   400  |  train loss: 0.1262668505
Epoch:   500  |  train loss: 0.1262668490
Epoch:   600  |  train loss: 0.1262668371
Epoch:   700  |  train loss: 0.1262668371
Epoch:   800  |  train loss: 0.1262668386
Epoch:   900  |  train loss: 0.1262668356
Epoch:  1000  |  train loss: 0.1262668416
Epoch:  1100  |  train loss: 0.1262668341
Epoch:  1200  |  train loss: 0.1262668490
Epoch:  1300  |  train loss: 0.1262668461
Epoch:  1400  |  train loss: 0.1262668356
Epoch:  1500  |  train loss: 0.1262668401
Epoch:  1600  |  train loss: 0.1262668490
Epoch:  1700  |  train loss: 0.1262668401
Epoch:  1800  |  train loss: 0.1262668401
Epoch:  1900  |  train loss: 0.1262668446
Epoch:  2000  |  train loss: 0.1262668416
Processing class: 57
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1266195476
Epoch:   200  |  train loss: 0.1266195491
Epoch:   300  |  train loss: 0.1266195491
Epoch:   400  |  train loss: 0.1266195446
Epoch:   500  |  train loss: 0.1266195446
Epoch:   600  |  train loss: 0.1266195446
Epoch:   700  |  train loss: 0.1266195506
Epoch:   800  |  train loss: 0.1266195402
Epoch:   900  |  train loss: 0.1266195446
Epoch:  1000  |  train loss: 0.1266195387
Epoch:  1100  |  train loss: 0.1266195565
Epoch:  1200  |  train loss: 0.1266195446
Epoch:  1300  |  train loss: 0.1266195491
Epoch:  1400  |  train loss: 0.1266195461
Epoch:  1500  |  train loss: 0.1266195476
Epoch:  1600  |  train loss: 0.1266195416
Epoch:  1700  |  train loss: 0.1266195416
Epoch:  1800  |  train loss: 0.1266195416
Epoch:  1900  |  train loss: 0.1266195416
Epoch:  2000  |  train loss: 0.1266195461
Processing class: 58
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1253380388
Epoch:   200  |  train loss: 0.1253380463
Epoch:   300  |  train loss: 0.1253380448
Epoch:   400  |  train loss: 0.1253380433
Epoch:   500  |  train loss: 0.1253380477
Epoch:   600  |  train loss: 0.1253380448
Epoch:   700  |  train loss: 0.1253380358
Epoch:   800  |  train loss: 0.1253380388
Epoch:   900  |  train loss: 0.1253380418
Epoch:  1000  |  train loss: 0.1253380463
Epoch:  1100  |  train loss: 0.1253380448
Epoch:  1200  |  train loss: 0.1253380418
Epoch:  1300  |  train loss: 0.1253380477
Epoch:  1400  |  train loss: 0.1253380463
Epoch:  1500  |  train loss: 0.1253380388
Epoch:  1600  |  train loss: 0.1253380492
Epoch:  1700  |  train loss: 0.1253380373
Epoch:  1800  |  train loss: 0.1253380388
Epoch:  1900  |  train loss: 0.1253380418
Epoch:  2000  |  train loss: 0.1253380448
Processing class: 59
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261526227
Epoch:   200  |  train loss: 0.1261526182
Epoch:   300  |  train loss: 0.1261526227
Epoch:   400  |  train loss: 0.1261526227
Epoch:   500  |  train loss: 0.1261526197
Epoch:   600  |  train loss: 0.1261526227
Epoch:   700  |  train loss: 0.1261526257
Epoch:   800  |  train loss: 0.1261526242
Epoch:   900  |  train loss: 0.1261526212
Epoch:  1000  |  train loss: 0.1261526242
Epoch:  1100  |  train loss: 0.1261526138
Epoch:  1200  |  train loss: 0.1261526167
Epoch:  1300  |  train loss: 0.1261526242
Epoch:  1400  |  train loss: 0.1261526197
Epoch:  1500  |  train loss: 0.1261526257
Epoch:  1600  |  train loss: 0.1261526167
Epoch:  1700  |  train loss: 0.1261526197
Epoch:  1800  |  train loss: 0.1261526257
Epoch:  1900  |  train loss: 0.1261526182
Epoch:  2000  |  train loss: 0.1261526257
Clasifying using reconstruction function cost
2024-04-02 06:20:26,425 [trainer.py] => CNN: {'total': 71.75, '00-09': 82.2, '10-19': 72.8, '20-29': 78.5, '30-39': 74.9, '40-49': 68.4, '50-59': 53.7, 'old': 75.36, 'new': 53.7}
2024-04-02 06:20:26,425 [trainer.py] => No NME accuracy
2024-04-02 06:20:26,425 [trainer.py] => FeCAM: {'total': 58.93, '00-09': 74.7, '10-19': 60.9, '20-29': 71.2, '30-39': 63.6, '40-49': 66.2, '50-59': 17.0, 'old': 67.32, 'new': 17.0}
2024-04-02 06:20:26,425 [trainer.py] => CNN top1 curve: [83.44, 71.75]
2024-04-02 06:20:26,426 [trainer.py] => CNN top5 curve: [96.5, 89.6]
2024-04-02 06:20:26,426 [trainer.py] => FeCAM top1 curve: [71.08, 58.93]
2024-04-02 06:20:26,426 [trainer.py] => FeCAM top5 curve: [86.36, 79.4]

2024-04-02 06:20:26,430 [fecam.py] => Learning on 60-70
Processing class: 60
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 61
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1199152917
Epoch:   200  |  train loss: 0.1199152932
Epoch:   300  |  train loss: 0.1199152946
Epoch:   400  |  train loss: 0.1199152902
Epoch:   500  |  train loss: 0.1199152991
Epoch:   600  |  train loss: 0.1199152872
Epoch:   700  |  train loss: 0.1199152887
Epoch:   800  |  train loss: 0.1199152902
Epoch:   900  |  train loss: 0.1199152917
Epoch:  1000  |  train loss: 0.1199152932
Epoch:  1100  |  train loss: 0.1199152946
Epoch:  1200  |  train loss: 0.1199152917
Epoch:  1300  |  train loss: 0.1199152932
Epoch:  1400  |  train loss: 0.1199152946
Epoch:  1500  |  train loss: 0.1199152902
Epoch:  1600  |  train loss: 0.1199152932
Epoch:  1700  |  train loss: 0.1199152872
Epoch:  1800  |  train loss: 0.1199153021
Epoch:  1900  |  train loss: 0.1199152872
Epoch:  2000  |  train loss: 0.1199152917
Processing class: 62
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1271606416
Epoch:   200  |  train loss: 0.1271606356
Epoch:   300  |  train loss: 0.1271606416
Epoch:   400  |  train loss: 0.1271606416
Epoch:   500  |  train loss: 0.1271606416
Epoch:   600  |  train loss: 0.1271606416
Epoch:   700  |  train loss: 0.1271606416
Epoch:   800  |  train loss: 0.1271606445
Epoch:   900  |  train loss: 0.1271606326
Epoch:  1000  |  train loss: 0.1271606341
Epoch:  1100  |  train loss: 0.1271606386
Epoch:  1200  |  train loss: 0.1271606416
Epoch:  1300  |  train loss: 0.1271606386
Epoch:  1400  |  train loss: 0.1271606386
Epoch:  1500  |  train loss: 0.1271606326
Epoch:  1600  |  train loss: 0.1271606445
Epoch:  1700  |  train loss: 0.1271606386
Epoch:  1800  |  train loss: 0.1271606416
Epoch:  1900  |  train loss: 0.1271606386
Epoch:  2000  |  train loss: 0.1271606386
Processing class: 63
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 64
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1241979420
Epoch:   200  |  train loss: 0.1241979450
Epoch:   300  |  train loss: 0.1241979435
Epoch:   400  |  train loss: 0.1241979480
Epoch:   500  |  train loss: 0.1241979405
Epoch:   600  |  train loss: 0.1241979450
Epoch:   700  |  train loss: 0.1241979495
Epoch:   800  |  train loss: 0.1241979435
Epoch:   900  |  train loss: 0.1241979420
Epoch:  1000  |  train loss: 0.1241979405
Epoch:  1100  |  train loss: 0.1241979495
Epoch:  1200  |  train loss: 0.1241979495
Epoch:  1300  |  train loss: 0.1241979495
Epoch:  1400  |  train loss: 0.1241979420
Epoch:  1500  |  train loss: 0.1241979450
Epoch:  1600  |  train loss: 0.1241979465
Epoch:  1700  |  train loss: 0.1241979510
Epoch:  1800  |  train loss: 0.1241979405
Epoch:  1900  |  train loss: 0.1241979420
Epoch:  2000  |  train loss: 0.1241979435
Processing class: 65
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1255335763
Epoch:   200  |  train loss: 0.1255335778
Epoch:   300  |  train loss: 0.1255335793
Epoch:   400  |  train loss: 0.1255335703
Epoch:   500  |  train loss: 0.1255335763
Epoch:   600  |  train loss: 0.1255335733
Epoch:   700  |  train loss: 0.1255335778
Epoch:   800  |  train loss: 0.1255335748
Epoch:   900  |  train loss: 0.1255335733
Epoch:  1000  |  train loss: 0.1255335778
Epoch:  1100  |  train loss: 0.1255335778
Epoch:  1200  |  train loss: 0.1255335718
Epoch:  1300  |  train loss: 0.1255335703
Epoch:  1400  |  train loss: 0.1255335718
Epoch:  1500  |  train loss: 0.1255335733
Epoch:  1600  |  train loss: 0.1255335748
Epoch:  1700  |  train loss: 0.1255335763
Epoch:  1800  |  train loss: 0.1255335748
Epoch:  1900  |  train loss: 0.1255335808
Epoch:  2000  |  train loss: 0.1255335733
Processing class: 66
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1273153573
Epoch:   200  |  train loss: 0.1273153543
Epoch:   300  |  train loss: 0.1273153648
Epoch:   400  |  train loss: 0.1273153588
Epoch:   500  |  train loss: 0.1273153603
Epoch:   600  |  train loss: 0.1273153588
Epoch:   700  |  train loss: 0.1273153543
Epoch:   800  |  train loss: 0.1273153573
Epoch:   900  |  train loss: 0.1273153603
Epoch:  1000  |  train loss: 0.1273153603
Epoch:  1100  |  train loss: 0.1273153603
Epoch:  1200  |  train loss: 0.1273153633
Epoch:  1300  |  train loss: 0.1273153573
Epoch:  1400  |  train loss: 0.1273153603
Epoch:  1500  |  train loss: 0.1273153603
Epoch:  1600  |  train loss: 0.1273153514
Epoch:  1700  |  train loss: 0.1273153663
Epoch:  1800  |  train loss: 0.1273153633
Epoch:  1900  |  train loss: 0.1273153558
Epoch:  2000  |  train loss: 0.1273153573
Processing class: 67
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1251724482
Epoch:   200  |  train loss: 0.1251724482
Epoch:   300  |  train loss: 0.1251724482
Epoch:   400  |  train loss: 0.1251724482
Epoch:   500  |  train loss: 0.1251724407
Epoch:   600  |  train loss: 0.1251724482
Epoch:   700  |  train loss: 0.1251724452
Epoch:   800  |  train loss: 0.1251724422
Epoch:   900  |  train loss: 0.1251724511
Epoch:  1000  |  train loss: 0.1251724496
Epoch:  1100  |  train loss: 0.1251724452
Epoch:  1200  |  train loss: 0.1251724496
Epoch:  1300  |  train loss: 0.1251724496
Epoch:  1400  |  train loss: 0.1251724437
Epoch:  1500  |  train loss: 0.1251724482
Epoch:  1600  |  train loss: 0.1251724482
Epoch:  1700  |  train loss: 0.1251724422
Epoch:  1800  |  train loss: 0.1251724437
Epoch:  1900  |  train loss: 0.1251724467
Epoch:  2000  |  train loss: 0.1251724467
Processing class: 68
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1254008636
Epoch:   200  |  train loss: 0.1254008606
Epoch:   300  |  train loss: 0.1254008561
Epoch:   400  |  train loss: 0.1254008591
Epoch:   500  |  train loss: 0.1254008561
Epoch:   600  |  train loss: 0.1254008621
Epoch:   700  |  train loss: 0.1254008591
Epoch:   800  |  train loss: 0.1254008651
Epoch:   900  |  train loss: 0.1254008636
Epoch:  1000  |  train loss: 0.1254008651
Epoch:  1100  |  train loss: 0.1254008651
Epoch:  1200  |  train loss: 0.1254008606
Epoch:  1300  |  train loss: 0.1254008681
Epoch:  1400  |  train loss: 0.1254008695
Epoch:  1500  |  train loss: 0.1254008621
Epoch:  1600  |  train loss: 0.1254008561
Epoch:  1700  |  train loss: 0.1254008591
Epoch:  1800  |  train loss: 0.1254008621
Epoch:  1900  |  train loss: 0.1254008636
Epoch:  2000  |  train loss: 0.1254008636
Processing class: 69
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1256688535
Epoch:   200  |  train loss: 0.1256688505
Epoch:   300  |  train loss: 0.1256688565
Epoch:   400  |  train loss: 0.1256688520
Epoch:   500  |  train loss: 0.1256688461
Epoch:   600  |  train loss: 0.1256688565
Epoch:   700  |  train loss: 0.1256688476
Epoch:   800  |  train loss: 0.1256688535
Epoch:   900  |  train loss: 0.1256688535
Epoch:  1000  |  train loss: 0.1256688431
Epoch:  1100  |  train loss: 0.1256688461
Epoch:  1200  |  train loss: 0.1256688505
Epoch:  1300  |  train loss: 0.1256688446
Epoch:  1400  |  train loss: 0.1256688565
Epoch:  1500  |  train loss: 0.1256688535
Epoch:  1600  |  train loss: 0.1256688535
Epoch:  1700  |  train loss: 0.1256688446
Epoch:  1800  |  train loss: 0.1256688461
Epoch:  1900  |  train loss: 0.1256688535
Epoch:  2000  |  train loss: 0.1256688505
Clasifying using reconstruction function cost
2024-04-02 07:19:40,561 [trainer.py] => CNN: {'total': 64.66, '00-09': 75.0, '10-19': 70.1, '20-29': 77.1, '30-39': 70.6, '40-49': 64.0, '50-59': 45.8, '60-69': 50.0, 'old': 67.1, 'new': 50.0}
2024-04-02 07:19:40,561 [trainer.py] => No NME accuracy
2024-04-02 07:19:40,561 [trainer.py] => FeCAM: {'total': 47.47, '00-09': 68.1, '10-19': 54.7, '20-29': 65.8, '30-39': 55.7, '40-49': 58.2, '50-59': 12.1, '60-69': 17.7, 'old': 52.43, 'new': 17.7}
2024-04-02 07:19:40,561 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66]
2024-04-02 07:19:40,561 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54]
2024-04-02 07:19:40,561 [trainer.py] => FeCAM top1 curve: [71.08, 58.93, 47.47]
2024-04-02 07:19:40,561 [trainer.py] => FeCAM top5 curve: [86.36, 79.4, 72.59]

2024-04-02 07:19:40,566 [fecam.py] => Learning on 70-80
Processing class: 70
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1236254394
Epoch:   200  |  train loss: 0.1236254439
Epoch:   300  |  train loss: 0.1236254379
Epoch:   400  |  train loss: 0.1236254424
Epoch:   500  |  train loss: 0.1236254424
Epoch:   600  |  train loss: 0.1236254439
Epoch:   700  |  train loss: 0.1236254469
Epoch:   800  |  train loss: 0.1236254379
Epoch:   900  |  train loss: 0.1236254424
Epoch:  1000  |  train loss: 0.1236254379
Epoch:  1100  |  train loss: 0.1236254409
Epoch:  1200  |  train loss: 0.1236254439
Epoch:  1300  |  train loss: 0.1236254439
Epoch:  1400  |  train loss: 0.1236254349
Epoch:  1500  |  train loss: 0.1236254439
Epoch:  1600  |  train loss: 0.1236254424
Epoch:  1700  |  train loss: 0.1236254424
Epoch:  1800  |  train loss: 0.1236254454
Epoch:  1900  |  train loss: 0.1236254394
Epoch:  2000  |  train loss: 0.1236254409
Processing class: 71
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1268056810
Epoch:   200  |  train loss: 0.1268056750
Epoch:   300  |  train loss: 0.1268056840
Epoch:   400  |  train loss: 0.1268056840
Epoch:   500  |  train loss: 0.1268056810
Epoch:   600  |  train loss: 0.1268056870
Epoch:   700  |  train loss: 0.1268056810
Epoch:   800  |  train loss: 0.1268056780
Epoch:   900  |  train loss: 0.1268056780
Epoch:  1000  |  train loss: 0.1268056780
Epoch:  1100  |  train loss: 0.1268056765
Epoch:  1200  |  train loss: 0.1268056780
Epoch:  1300  |  train loss: 0.1268056810
Epoch:  1400  |  train loss: 0.1268056810
Epoch:  1500  |  train loss: 0.1268056810
Epoch:  1600  |  train loss: 0.1268056780
Epoch:  1700  |  train loss: 0.1268056810
Epoch:  1800  |  train loss: 0.1268056840
Epoch:  1900  |  train loss: 0.1268056795
Epoch:  2000  |  train loss: 0.1268056810
Processing class: 72
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1261641070
Epoch:   200  |  train loss: 0.1261641040
Epoch:   300  |  train loss: 0.1261641100
Epoch:   400  |  train loss: 0.1261641085
Epoch:   500  |  train loss: 0.1261641070
Epoch:   600  |  train loss: 0.1261641055
Epoch:   700  |  train loss: 0.1261641070
Epoch:   800  |  train loss: 0.1261641026
Epoch:   900  |  train loss: 0.1261641026
Epoch:  1000  |  train loss: 0.1261641085
Epoch:  1100  |  train loss: 0.1261641070
Epoch:  1200  |  train loss: 0.1261641070
Epoch:  1300  |  train loss: 0.1261640996
Epoch:  1400  |  train loss: 0.1261641055
Epoch:  1500  |  train loss: 0.1261641026
Epoch:  1600  |  train loss: 0.1261641115
Epoch:  1700  |  train loss: 0.1261641026
Epoch:  1800  |  train loss: 0.1261640996
Epoch:  1900  |  train loss: 0.1261641070
Epoch:  2000  |  train loss: 0.1261640996
Processing class: 73
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1268810570
Epoch:   200  |  train loss: 0.1268810675
Epoch:   300  |  train loss: 0.1268810540
Epoch:   400  |  train loss: 0.1268810630
Epoch:   500  |  train loss: 0.1268810630
Epoch:   600  |  train loss: 0.1268810600
Epoch:   700  |  train loss: 0.1268810630
Epoch:   800  |  train loss: 0.1268810630
Epoch:   900  |  train loss: 0.1268810600
Epoch:  1000  |  train loss: 0.1268810630
Epoch:  1100  |  train loss: 0.1268810570
Epoch:  1200  |  train loss: 0.1268810630
Epoch:  1300  |  train loss: 0.1268810570
Epoch:  1400  |  train loss: 0.1268810645
Epoch:  1500  |  train loss: 0.1268810540
Epoch:  1600  |  train loss: 0.1268810660
Epoch:  1700  |  train loss: 0.1268810615
Epoch:  1800  |  train loss: 0.1268810570
Epoch:  1900  |  train loss: 0.1268810585
Epoch:  2000  |  train loss: 0.1268810630
Processing class: 74
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1263926908
Epoch:   200  |  train loss: 0.1263926983
Epoch:   300  |  train loss: 0.1263926893
Epoch:   400  |  train loss: 0.1263926968
Epoch:   500  |  train loss: 0.1263926968
Epoch:   600  |  train loss: 0.1263926923
Epoch:   700  |  train loss: 0.1263926953
Epoch:   800  |  train loss: 0.1263926893
Epoch:   900  |  train loss: 0.1263926893
Epoch:  1000  |  train loss: 0.1263926923
Epoch:  1100  |  train loss: 0.1263926908
Epoch:  1200  |  train loss: 0.1263926923
Epoch:  1300  |  train loss: 0.1263926953
Epoch:  1400  |  train loss: 0.1263927013
Epoch:  1500  |  train loss: 0.1263926968
Epoch:  1600  |  train loss: 0.1263926953
Epoch:  1700  |  train loss: 0.1263926908
Epoch:  1800  |  train loss: 0.1263926923
Epoch:  1900  |  train loss: 0.1263926879
Epoch:  2000  |  train loss: 0.1263926968
Processing class: 75
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 76
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1257172912
Epoch:   200  |  train loss: 0.1257173032
Epoch:   300  |  train loss: 0.1257173002
Epoch:   400  |  train loss: 0.1257173061
Epoch:   500  |  train loss: 0.1257172972
Epoch:   600  |  train loss: 0.1257172972
Epoch:   700  |  train loss: 0.1257172972
Epoch:   800  |  train loss: 0.1257173002
Epoch:   900  |  train loss: 0.1257172987
Epoch:  1000  |  train loss: 0.1257173032
Epoch:  1100  |  train loss: 0.1257172957
Epoch:  1200  |  train loss: 0.1257173046
Epoch:  1300  |  train loss: 0.1257173032
Epoch:  1400  |  train loss: 0.1257173032
Epoch:  1500  |  train loss: 0.1257172972
Epoch:  1600  |  train loss: 0.1257172987
Epoch:  1700  |  train loss: 0.1257172987
Epoch:  1800  |  train loss: 0.1257173046
Epoch:  1900  |  train loss: 0.1257173032
Epoch:  2000  |  train loss: 0.1257172972
Processing class: 77
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 78
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262409419
Epoch:   200  |  train loss: 0.1262409478
Epoch:   300  |  train loss: 0.1262409464
Epoch:   400  |  train loss: 0.1262409478
Epoch:   500  |  train loss: 0.1262409404
Epoch:   600  |  train loss: 0.1262409419
Epoch:   700  |  train loss: 0.1262409449
Epoch:   800  |  train loss: 0.1262409359
Epoch:   900  |  train loss: 0.1262409478
Epoch:  1000  |  train loss: 0.1262409478
Epoch:  1100  |  train loss: 0.1262409449
Epoch:  1200  |  train loss: 0.1262409419
Epoch:  1300  |  train loss: 0.1262409419
Epoch:  1400  |  train loss: 0.1262409478
Epoch:  1500  |  train loss: 0.1262409374
Epoch:  1600  |  train loss: 0.1262409449
Epoch:  1700  |  train loss: 0.1262409389
Epoch:  1800  |  train loss: 0.1262409344
Epoch:  1900  |  train loss: 0.1262409464
Epoch:  2000  |  train loss: 0.1262409419
Processing class: 79
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1266025960
Epoch:   200  |  train loss: 0.1266025990
Epoch:   300  |  train loss: 0.1266026005
Epoch:   400  |  train loss: 0.1266025990
Epoch:   500  |  train loss: 0.1266026005
Epoch:   600  |  train loss: 0.1266025975
Epoch:   700  |  train loss: 0.1266025946
Epoch:   800  |  train loss: 0.1266025960
Epoch:   900  |  train loss: 0.1266025960
Epoch:  1000  |  train loss: 0.1266026020
Epoch:  1100  |  train loss: 0.1266025990
Epoch:  1200  |  train loss: 0.1266025975
Epoch:  1300  |  train loss: 0.1266025946
Epoch:  1400  |  train loss: 0.1266025990
Epoch:  1500  |  train loss: 0.1266026050
Epoch:  1600  |  train loss: 0.1266025856
Epoch:  1700  |  train loss: 0.1266025975
Epoch:  1800  |  train loss: 0.1266025990
Epoch:  1900  |  train loss: 0.1266025975
Epoch:  2000  |  train loss: 0.1266025975
Clasifying using reconstruction function cost
2024-04-02 08:21:12,020 [trainer.py] => CNN: {'total': 59.18, '00-09': 73.6, '10-19': 68.4, '20-29': 76.9, '30-39': 69.1, '40-49': 60.6, '50-59': 37.2, '60-69': 45.7, '70-79': 41.9, 'old': 61.64, 'new': 41.9}
2024-04-02 08:21:12,020 [trainer.py] => No NME accuracy
2024-04-02 08:21:12,020 [trainer.py] => FeCAM: {'total': 40.3, '00-09': 65.4, '10-19': 52.9, '20-29': 62.8, '30-39': 52.7, '40-49': 55.6, '50-59': 9.9, '60-69': 14.5, '70-79': 8.6, 'old': 44.83, 'new': 8.6}
2024-04-02 08:21:12,020 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18]
2024-04-02 08:21:12,020 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09]
2024-04-02 08:21:12,021 [trainer.py] => FeCAM top1 curve: [71.08, 58.93, 47.47, 40.3]
2024-04-02 08:21:12,021 [trainer.py] => FeCAM top5 curve: [86.36, 79.4, 72.59, 66.72]

2024-04-02 08:21:12,025 [fecam.py] => Learning on 80-90
Processing class: 80
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1248104855
Epoch:   200  |  train loss: 0.1248104841
Epoch:   300  |  train loss: 0.1248104855
Epoch:   400  |  train loss: 0.1248104811
Epoch:   500  |  train loss: 0.1248104841
Epoch:   600  |  train loss: 0.1248104841
Epoch:   700  |  train loss: 0.1248104841
Epoch:   800  |  train loss: 0.1248104900
Epoch:   900  |  train loss: 0.1248104885
Epoch:  1000  |  train loss: 0.1248104841
Epoch:  1100  |  train loss: 0.1248104870
Epoch:  1200  |  train loss: 0.1248104811
Epoch:  1300  |  train loss: 0.1248104870
Epoch:  1400  |  train loss: 0.1248104751
Epoch:  1500  |  train loss: 0.1248104796
Epoch:  1600  |  train loss: 0.1248104841
Epoch:  1700  |  train loss: 0.1248104855
Epoch:  1800  |  train loss: 0.1248104885
Epoch:  1900  |  train loss: 0.1248104900
Epoch:  2000  |  train loss: 0.1248104885
Processing class: 81
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1264899105
Epoch:   200  |  train loss: 0.1264899045
Epoch:   300  |  train loss: 0.1264899060
Epoch:   400  |  train loss: 0.1264899060
Epoch:   500  |  train loss: 0.1264899045
Epoch:   600  |  train loss: 0.1264899060
Epoch:   700  |  train loss: 0.1264899090
Epoch:   800  |  train loss: 0.1264899015
Epoch:   900  |  train loss: 0.1264899001
Epoch:  1000  |  train loss: 0.1264899045
Epoch:  1100  |  train loss: 0.1264899045
Epoch:  1200  |  train loss: 0.1264899075
Epoch:  1300  |  train loss: 0.1264899015
Epoch:  1400  |  train loss: 0.1264899030
Epoch:  1500  |  train loss: 0.1264899060
Epoch:  1600  |  train loss: 0.1264899015
Epoch:  1700  |  train loss: 0.1264899001
Epoch:  1800  |  train loss: 0.1264899135
Epoch:  1900  |  train loss: 0.1264899015
Epoch:  2000  |  train loss: 0.1264898956
Processing class: 82
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1252478525
Epoch:   200  |  train loss: 0.1252478436
Epoch:   300  |  train loss: 0.1252478525
Epoch:   400  |  train loss: 0.1252478495
Epoch:   500  |  train loss: 0.1252478525
Epoch:   600  |  train loss: 0.1252478451
Epoch:   700  |  train loss: 0.1252478451
Epoch:   800  |  train loss: 0.1252478451
Epoch:   900  |  train loss: 0.1252478451
Epoch:  1000  |  train loss: 0.1252478510
Epoch:  1100  |  train loss: 0.1252478465
Epoch:  1200  |  train loss: 0.1252478480
Epoch:  1300  |  train loss: 0.1252478465
Epoch:  1400  |  train loss: 0.1252478480
Epoch:  1500  |  train loss: 0.1252478510
Epoch:  1600  |  train loss: 0.1252478510
Epoch:  1700  |  train loss: 0.1252478465
Epoch:  1800  |  train loss: 0.1252478436
Epoch:  1900  |  train loss: 0.1252478480
Epoch:  2000  |  train loss: 0.1252478585
Processing class: 83
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1260831609
Epoch:   200  |  train loss: 0.1260831609
Epoch:   300  |  train loss: 0.1260831639
Epoch:   400  |  train loss: 0.1260831550
Epoch:   500  |  train loss: 0.1260831565
Epoch:   600  |  train loss: 0.1260831609
Epoch:   700  |  train loss: 0.1260831624
Epoch:   800  |  train loss: 0.1260831669
Epoch:   900  |  train loss: 0.1260831639
Epoch:  1000  |  train loss: 0.1260831565
Epoch:  1100  |  train loss: 0.1260831654
Epoch:  1200  |  train loss: 0.1260831639
Epoch:  1300  |  train loss: 0.1260831639
Epoch:  1400  |  train loss: 0.1260831624
Epoch:  1500  |  train loss: 0.1260831609
Epoch:  1600  |  train loss: 0.1260831594
Epoch:  1700  |  train loss: 0.1260831699
Epoch:  1800  |  train loss: 0.1260831624
Epoch:  1900  |  train loss: 0.1260831609
Epoch:  2000  |  train loss: 0.1260831609
Processing class: 84
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1263058230
Epoch:   200  |  train loss: 0.1263058186
Epoch:   300  |  train loss: 0.1263058215
Epoch:   400  |  train loss: 0.1263058245
Epoch:   500  |  train loss: 0.1263058215
Epoch:   600  |  train loss: 0.1263058245
Epoch:   700  |  train loss: 0.1263058245
Epoch:   800  |  train loss: 0.1263058215
Epoch:   900  |  train loss: 0.1263058290
Epoch:  1000  |  train loss: 0.1263058156
Epoch:  1100  |  train loss: 0.1263058171
Epoch:  1200  |  train loss: 0.1263058215
Epoch:  1300  |  train loss: 0.1263058171
Epoch:  1400  |  train loss: 0.1263058171
Epoch:  1500  |  train loss: 0.1263058230
Epoch:  1600  |  train loss: 0.1263058245
Epoch:  1700  |  train loss: 0.1263058186
Epoch:  1800  |  train loss: 0.1263058186
Epoch:  1900  |  train loss: 0.1263058200
Epoch:  2000  |  train loss: 0.1263058141
Processing class: 85
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1244532526
Epoch:   200  |  train loss: 0.1244532540
Epoch:   300  |  train loss: 0.1244532526
Epoch:   400  |  train loss: 0.1244532511
Epoch:   500  |  train loss: 0.1244532555
Epoch:   600  |  train loss: 0.1244532526
Epoch:   700  |  train loss: 0.1244532511
Epoch:   800  |  train loss: 0.1244532540
Epoch:   900  |  train loss: 0.1244532630
Epoch:  1000  |  train loss: 0.1244532585
Epoch:  1100  |  train loss: 0.1244532540
Epoch:  1200  |  train loss: 0.1244532555
Epoch:  1300  |  train loss: 0.1244532555
Epoch:  1400  |  train loss: 0.1244532526
Epoch:  1500  |  train loss: 0.1244532526
Epoch:  1600  |  train loss: 0.1244532570
Epoch:  1700  |  train loss: 0.1244532555
Epoch:  1800  |  train loss: 0.1244532600
Epoch:  1900  |  train loss: 0.1244532570
Epoch:  2000  |  train loss: 0.1244532615
Processing class: 86
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1268656015
Epoch:   200  |  train loss: 0.1268656105
Epoch:   300  |  train loss: 0.1268655986
Epoch:   400  |  train loss: 0.1268656030
Epoch:   500  |  train loss: 0.1268656015
Epoch:   600  |  train loss: 0.1268655986
Epoch:   700  |  train loss: 0.1268656060
Epoch:   800  |  train loss: 0.1268656045
Epoch:   900  |  train loss: 0.1268656015
Epoch:  1000  |  train loss: 0.1268656000
Epoch:  1100  |  train loss: 0.1268656045
Epoch:  1200  |  train loss: 0.1268656090
Epoch:  1300  |  train loss: 0.1268656135
Epoch:  1400  |  train loss: 0.1268656045
Epoch:  1500  |  train loss: 0.1268656015
Epoch:  1600  |  train loss: 0.1268656105
Epoch:  1700  |  train loss: 0.1268656045
Epoch:  1800  |  train loss: 0.1268656105
Epoch:  1900  |  train loss: 0.1268656105
Epoch:  2000  |  train loss: 0.1268655986
Processing class: 87
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1267350391
Epoch:   200  |  train loss: 0.1267350361
Epoch:   300  |  train loss: 0.1267350405
Epoch:   400  |  train loss: 0.1267350331
Epoch:   500  |  train loss: 0.1267350346
Epoch:   600  |  train loss: 0.1267350331
Epoch:   700  |  train loss: 0.1267350435
Epoch:   800  |  train loss: 0.1267350391
Epoch:   900  |  train loss: 0.1267350361
Epoch:  1000  |  train loss: 0.1267350301
Epoch:  1100  |  train loss: 0.1267350316
Epoch:  1200  |  train loss: 0.1267350346
Epoch:  1300  |  train loss: 0.1267350346
Epoch:  1400  |  train loss: 0.1267350376
Epoch:  1500  |  train loss: 0.1267350391
Epoch:  1600  |  train loss: 0.1267350376
Epoch:  1700  |  train loss: 0.1267350346
Epoch:  1800  |  train loss: 0.1267350391
Epoch:  1900  |  train loss: 0.1267350376
Epoch:  2000  |  train loss: 0.1267350391
Processing class: 88
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262269139
Epoch:   200  |  train loss: 0.1262269109
Epoch:   300  |  train loss: 0.1262269095
Epoch:   400  |  train loss: 0.1262269109
Epoch:   500  |  train loss: 0.1262269095
Epoch:   600  |  train loss: 0.1262269139
Epoch:   700  |  train loss: 0.1262269080
Epoch:   800  |  train loss: 0.1262269139
Epoch:   900  |  train loss: 0.1262269139
Epoch:  1000  |  train loss: 0.1262269109
Epoch:  1100  |  train loss: 0.1262269139
Epoch:  1200  |  train loss: 0.1262269095
Epoch:  1300  |  train loss: 0.1262269109
Epoch:  1400  |  train loss: 0.1262269080
Epoch:  1500  |  train loss: 0.1262269184
Epoch:  1600  |  train loss: 0.1262269050
Epoch:  1700  |  train loss: 0.1262269139
Epoch:  1800  |  train loss: 0.1262269124
Epoch:  1900  |  train loss: 0.1262269169
Epoch:  2000  |  train loss: 0.1262269124
Processing class: 89
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1269439951
Epoch:   200  |  train loss: 0.1269440055
Epoch:   300  |  train loss: 0.1269440055
Epoch:   400  |  train loss: 0.1269440025
Epoch:   500  |  train loss: 0.1269439995
Epoch:   600  |  train loss: 0.1269439921
Epoch:   700  |  train loss: 0.1269439965
Epoch:   800  |  train loss: 0.1269439965
Epoch:   900  |  train loss: 0.1269439965
Epoch:  1000  |  train loss: 0.1269439995
Epoch:  1100  |  train loss: 0.1269439965
Epoch:  1200  |  train loss: 0.1269439965
Epoch:  1300  |  train loss: 0.1269439965
Epoch:  1400  |  train loss: 0.1269439936
Epoch:  1500  |  train loss: 0.1269440010
Epoch:  1600  |  train loss: 0.1269439936
Epoch:  1700  |  train loss: 0.1269439995
Epoch:  1800  |  train loss: 0.1269439936
Epoch:  1900  |  train loss: 0.1269439995
Epoch:  2000  |  train loss: 0.1269439951
Clasifying using reconstruction function cost
2024-04-02 09:25:01,519 [trainer.py] => CNN: {'total': 54.08, '00-09': 67.9, '10-19': 63.6, '20-29': 73.2, '30-39': 68.8, '40-49': 57.2, '50-59': 32.6, '60-69': 40.9, '70-79': 38.1, '80-89': 44.4, 'old': 55.29, 'new': 44.4}
2024-04-02 09:25:01,520 [trainer.py] => No NME accuracy
2024-04-02 09:25:01,520 [trainer.py] => FeCAM: {'total': 36.14, '00-09': 64.7, '10-19': 50.9, '20-29': 61.7, '30-39': 52.6, '40-49': 54.7, '50-59': 9.5, '60-69': 13.4, '70-79': 8.3, '80-89': 9.5, 'old': 39.48, 'new': 9.5}
2024-04-02 09:25:01,520 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08]
2024-04-02 09:25:01,520 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74]
2024-04-02 09:25:01,520 [trainer.py] => FeCAM top1 curve: [71.08, 58.93, 47.47, 40.3, 36.14]
2024-04-02 09:25:01,520 [trainer.py] => FeCAM top5 curve: [86.36, 79.4, 72.59, 66.72, 62.81]

2024-04-02 09:25:01,524 [fecam.py] => Learning on 90-100
Processing class: 90
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1258028284
Epoch:   200  |  train loss: 0.1258028179
Epoch:   300  |  train loss: 0.1258028194
Epoch:   400  |  train loss: 0.1258028254
Epoch:   500  |  train loss: 0.1258028239
Epoch:   600  |  train loss: 0.1258028239
Epoch:   700  |  train loss: 0.1258028165
Epoch:   800  |  train loss: 0.1258028239
Epoch:   900  |  train loss: 0.1258028194
Epoch:  1000  |  train loss: 0.1258028194
Epoch:  1100  |  train loss: 0.1258028239
Epoch:  1200  |  train loss: 0.1258028194
Epoch:  1300  |  train loss: 0.1258028194
Epoch:  1400  |  train loss: 0.1258028165
Epoch:  1500  |  train loss: 0.1258028224
Epoch:  1600  |  train loss: 0.1258028239
Epoch:  1700  |  train loss: 0.1258028194
Epoch:  1800  |  train loss: 0.1258028239
Epoch:  1900  |  train loss: 0.1258028179
Epoch:  2000  |  train loss: 0.1258028194
Processing class: 91
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1260998428
Epoch:   200  |  train loss: 0.1260998428
Epoch:   300  |  train loss: 0.1260998383
Epoch:   400  |  train loss: 0.1260998413
Epoch:   500  |  train loss: 0.1260998398
Epoch:   600  |  train loss: 0.1260998398
Epoch:   700  |  train loss: 0.1260998428
Epoch:   800  |  train loss: 0.1260998443
Epoch:   900  |  train loss: 0.1260998398
Epoch:  1000  |  train loss: 0.1260998458
Epoch:  1100  |  train loss: 0.1260998368
Epoch:  1200  |  train loss: 0.1260998428
Epoch:  1300  |  train loss: 0.1260998428
Epoch:  1400  |  train loss: 0.1260998383
Epoch:  1500  |  train loss: 0.1260998398
Epoch:  1600  |  train loss: 0.1260998383
Epoch:  1700  |  train loss: 0.1260998383
Epoch:  1800  |  train loss: 0.1260998443
Epoch:  1900  |  train loss: 0.1260998398
Epoch:  2000  |  train loss: 0.1260998324
Processing class: 92
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1260010138
Epoch:   200  |  train loss: 0.1260010198
Epoch:   300  |  train loss: 0.1260010108
Epoch:   400  |  train loss: 0.1260010153
Epoch:   500  |  train loss: 0.1260010198
Epoch:   600  |  train loss: 0.1260010153
Epoch:   700  |  train loss: 0.1260010138
Epoch:   800  |  train loss: 0.1260010228
Epoch:   900  |  train loss: 0.1260010198
Epoch:  1000  |  train loss: 0.1260010228
Epoch:  1100  |  train loss: 0.1260010123
Epoch:  1200  |  train loss: 0.1260010153
Epoch:  1300  |  train loss: 0.1260010228
Epoch:  1400  |  train loss: 0.1260010168
Epoch:  1500  |  train loss: 0.1260010168
Epoch:  1600  |  train loss: 0.1260010138
Epoch:  1700  |  train loss: 0.1260010153
Epoch:  1800  |  train loss: 0.1260010183
Epoch:  1900  |  train loss: 0.1260010153
Epoch:  2000  |  train loss: 0.1260010138
Processing class: 93
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1265956253
Epoch:   200  |  train loss: 0.1265956223
Epoch:   300  |  train loss: 0.1265956253
Epoch:   400  |  train loss: 0.1265956238
Epoch:   500  |  train loss: 0.1265956223
Epoch:   600  |  train loss: 0.1265956268
Epoch:   700  |  train loss: 0.1265956163
Epoch:   800  |  train loss: 0.1265956238
Epoch:   900  |  train loss: 0.1265956223
Epoch:  1000  |  train loss: 0.1265956253
Epoch:  1100  |  train loss: 0.1265956253
Epoch:  1200  |  train loss: 0.1265956149
Epoch:  1300  |  train loss: 0.1265956238
Epoch:  1400  |  train loss: 0.1265956223
Epoch:  1500  |  train loss: 0.1265956193
Epoch:  1600  |  train loss: 0.1265956134
Epoch:  1700  |  train loss: 0.1265956253
Epoch:  1800  |  train loss: 0.1265956298
Epoch:  1900  |  train loss: 0.1265956223
Epoch:  2000  |  train loss: 0.1265956163
Processing class: 94
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1248155639
Epoch:   200  |  train loss: 0.1248155519
Epoch:   300  |  train loss: 0.1248155624
Epoch:   400  |  train loss: 0.1248155549
Epoch:   500  |  train loss: 0.1248155549
Epoch:   600  |  train loss: 0.1248155624
Epoch:   700  |  train loss: 0.1248155609
Epoch:   800  |  train loss: 0.1248155609
Epoch:   900  |  train loss: 0.1248155594
Epoch:  1000  |  train loss: 0.1248155609
Epoch:  1100  |  train loss: 0.1248155624
Epoch:  1200  |  train loss: 0.1248155579
Epoch:  1300  |  train loss: 0.1248155653
Epoch:  1400  |  train loss: 0.1248155609
Epoch:  1500  |  train loss: 0.1248155609
Epoch:  1600  |  train loss: 0.1248155624
Epoch:  1700  |  train loss: 0.1248155579
Epoch:  1800  |  train loss: 0.1248155639
Epoch:  1900  |  train loss: 0.1248155653
Epoch:  2000  |  train loss: 0.1248155639
Processing class: 95
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1265277341
Epoch:   200  |  train loss: 0.1265277445
Epoch:   300  |  train loss: 0.1265277475
Epoch:   400  |  train loss: 0.1265277490
Epoch:   500  |  train loss: 0.1265277460
Epoch:   600  |  train loss: 0.1265277445
Epoch:   700  |  train loss: 0.1265277430
Epoch:   800  |  train loss: 0.1265277430
Epoch:   900  |  train loss: 0.1265277445
Epoch:  1000  |  train loss: 0.1265277475
Epoch:  1100  |  train loss: 0.1265277565
Epoch:  1200  |  train loss: 0.1265277490
Epoch:  1300  |  train loss: 0.1265277490
Epoch:  1400  |  train loss: 0.1265277460
Epoch:  1500  |  train loss: 0.1265277475
Epoch:  1600  |  train loss: 0.1265277445
Epoch:  1700  |  train loss: 0.1265277505
Epoch:  1800  |  train loss: 0.1265277460
Epoch:  1900  |  train loss: 0.1265277490
Epoch:  2000  |  train loss: 0.1265277401
Processing class: 96
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1264995784
Epoch:   200  |  train loss: 0.1264995724
Epoch:   300  |  train loss: 0.1264995784
Epoch:   400  |  train loss: 0.1264995724
Epoch:   500  |  train loss: 0.1264995784
Epoch:   600  |  train loss: 0.1264995739
Epoch:   700  |  train loss: 0.1264995754
Epoch:   800  |  train loss: 0.1264995769
Epoch:   900  |  train loss: 0.1264995813
Epoch:  1000  |  train loss: 0.1264995784
Epoch:  1100  |  train loss: 0.1264995784
Epoch:  1200  |  train loss: 0.1264995784
Epoch:  1300  |  train loss: 0.1264995784
Epoch:  1400  |  train loss: 0.1264995784
Epoch:  1500  |  train loss: 0.1264995769
Epoch:  1600  |  train loss: 0.1264995784
Epoch:  1700  |  train loss: 0.1264995754
Epoch:  1800  |  train loss: 0.1264995813
Epoch:  1900  |  train loss: 0.1264995769
Epoch:  2000  |  train loss: 0.1264995754
Processing class: 97
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1242710367
Epoch:   200  |  train loss: 0.1242710263
Epoch:   300  |  train loss: 0.1242710292
Epoch:   400  |  train loss: 0.1242710263
Epoch:   500  |  train loss: 0.1242710277
Epoch:   600  |  train loss: 0.1242710307
Epoch:   700  |  train loss: 0.1242710292
Epoch:   800  |  train loss: 0.1242710367
Epoch:   900  |  train loss: 0.1242710322
Epoch:  1000  |  train loss: 0.1242710248
Epoch:  1100  |  train loss: 0.1242710292
Epoch:  1200  |  train loss: 0.1242710322
Epoch:  1300  |  train loss: 0.1242710352
Epoch:  1400  |  train loss: 0.1242710337
Epoch:  1500  |  train loss: 0.1242710292
Epoch:  1600  |  train loss: 0.1242710263
Epoch:  1700  |  train loss: 0.1242710307
Epoch:  1800  |  train loss: 0.1242710292
Epoch:  1900  |  train loss: 0.1242710322
Epoch:  2000  |  train loss: 0.1242710292
Processing class: 98
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 99
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1262188494
Epoch:   200  |  train loss: 0.1262188464
Epoch:   300  |  train loss: 0.1262188494
Epoch:   400  |  train loss: 0.1262188524
Epoch:   500  |  train loss: 0.1262188479
Epoch:   600  |  train loss: 0.1262188479
Epoch:   700  |  train loss: 0.1262188494
Epoch:   800  |  train loss: 0.1262188569
Epoch:   900  |  train loss: 0.1262188524
Epoch:  1000  |  train loss: 0.1262188524
Epoch:  1100  |  train loss: 0.1262188539
Epoch:  1200  |  train loss: 0.1262188524
Epoch:  1300  |  train loss: 0.1262188479
Epoch:  1400  |  train loss: 0.1262188464
Epoch:  1500  |  train loss: 0.1262188539
Epoch:  1600  |  train loss: 0.1262188494
Epoch:  1700  |  train loss: 0.1262188524
Epoch:  1800  |  train loss: 0.1262188479
Epoch:  1900  |  train loss: 0.1262188435
Epoch:  2000  |  train loss: 0.1262188479
Clasifying using reconstruction function cost
2024-04-02 10:31:42,639 [trainer.py] => CNN: {'total': 50.36, '00-09': 57.7, '10-19': 63.6, '20-29': 71.4, '30-39': 68.5, '40-49': 56.8, '50-59': 29.6, '60-69': 38.9, '70-79': 36.6, '80-89': 42.7, '90-99': 37.8, 'old': 51.76, 'new': 37.8}
2024-04-02 10:31:42,640 [trainer.py] => No NME accuracy
2024-04-02 10:31:42,640 [trainer.py] => FeCAM: {'total': 31.71, '00-09': 62.0, '10-19': 48.5, '20-29': 59.8, '30-39': 50.0, '40-49': 53.5, '50-59': 8.5, '60-69': 11.8, '70-79': 6.9, '80-89': 8.6, '90-99': 7.5, 'old': 34.4, 'new': 7.5}
2024-04-02 10:31:42,640 [trainer.py] => CNN top1 curve: [83.44, 71.75, 64.66, 59.18, 54.08, 50.36]
2024-04-02 10:31:42,640 [trainer.py] => CNN top5 curve: [96.5, 89.6, 86.54, 84.09, 81.74, 79.63]
2024-04-02 10:31:42,640 [trainer.py] => FeCAM top1 curve: [71.08, 58.93, 47.47, 40.3, 36.14, 31.71]
2024-04-02 10:31:42,640 [trainer.py] => FeCAM top5 curve: [86.36, 79.4, 72.59, 66.72, 62.81, 58.71]

=========================================
2024-04-02 10:31:55,260 [trainer.py] => config: ./exps/FeCAM_cifar100.json
2024-04-02 10:31:55,260 [trainer.py] => prefix: train
2024-04-02 10:31:55,260 [trainer.py] => dataset: cifar100
2024-04-02 10:31:55,261 [trainer.py] => memory_size: 0
2024-04-02 10:31:55,261 [trainer.py] => shuffle: True
2024-04-02 10:31:55,261 [trainer.py] => init_cls: 50
2024-04-02 10:31:55,261 [trainer.py] => increment: 10
2024-04-02 10:31:55,261 [trainer.py] => model_name: fecam
2024-04-02 10:31:55,261 [trainer.py] => convnet_type: resnet18
2024-04-02 10:31:55,261 [trainer.py] => device: [device(type='cuda', index=0)]
2024-04-02 10:31:55,261 [trainer.py] => seed: 1993
2024-04-02 10:31:55,261 [trainer.py] => init_epochs: 200
2024-04-02 10:31:55,261 [trainer.py] => init_lr: 0.1
2024-04-02 10:31:55,261 [trainer.py] => init_weight_decay: 0.0005
2024-04-02 10:31:55,261 [trainer.py] => batch_size: 128
2024-04-02 10:31:55,261 [trainer.py] => num_workers: 8
2024-04-02 10:31:55,261 [trainer.py] => T: 5
2024-04-02 10:31:55,261 [trainer.py] => beta: 0.5
2024-04-02 10:31:55,261 [trainer.py] => alpha1: 1
2024-04-02 10:31:55,261 [trainer.py] => alpha2: 1
2024-04-02 10:31:55,261 [trainer.py] => ncm: False
2024-04-02 10:31:55,261 [trainer.py] => tukey: False
2024-04-02 10:31:55,261 [trainer.py] => diagonal: False
2024-04-02 10:31:55,261 [trainer.py] => per_class: True
2024-04-02 10:31:55,261 [trainer.py] => full_cov: True
2024-04-02 10:31:55,261 [trainer.py] => shrink: True
2024-04-02 10:31:55,261 [trainer.py] => norm_cov: False
2024-04-02 10:31:55,261 [trainer.py] => epochs: 2000
2024-04-02 10:31:55,261 [trainer.py] => vecnorm: False
2024-04-02 10:31:55,261 [trainer.py] => ae_type: ae
2024-04-02 10:31:55,261 [trainer.py] => ae_latent_dim: 32
2024-04-02 10:31:55,261 [trainer.py] => ae_n: 1
2024-04-02 10:31:55,261 [trainer.py] => wae_sigma: 10
2024-04-02 10:31:55,261 [trainer.py] => wae_C: 0.1
2024-04-02 10:31:55,261 [trainer.py] => ae_standarization: False
2024-04-02 10:31:55,261 [trainer.py] => ae_pca: False
2024-04-02 10:31:55,261 [trainer.py] => ae_pca_components: 500
2024-04-02 10:31:55,261 [trainer.py] => ae_clsf: maha-recon-cost
2024-04-02 10:31:55,261 [trainer.py] => maha_alpha: 0.01
2024-04-02 10:31:55,261 [trainer.py] => maha_beta: 0.5
Files already downloaded and verified
Files already downloaded and verified
2024-04-02 10:31:56,955 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-04-02 10:31:57,223 [fecam.py] => Learning on 0-50
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/z1165703/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Processing class: 0
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1740467012
Epoch:   200  |  train loss: 0.1740466982
Epoch:   300  |  train loss: 0.1740467012
Epoch:   400  |  train loss: 0.1740467072
Epoch:   500  |  train loss: 0.1740467012
Epoch:   600  |  train loss: 0.1740467161
Epoch:   700  |  train loss: 0.1740467042
Epoch:   800  |  train loss: 0.1740467042
Epoch:   900  |  train loss: 0.1740467101
Epoch:  1000  |  train loss: 0.1740467072
Epoch:  1100  |  train loss: 0.1740467101
Epoch:  1200  |  train loss: 0.1740466982
Epoch:  1300  |  train loss: 0.1740467012
Epoch:  1400  |  train loss: 0.1740467012
Epoch:  1500  |  train loss: 0.1740467072
Epoch:  1600  |  train loss: 0.1740467042
Epoch:  1700  |  train loss: 0.1740467012
Epoch:  1800  |  train loss: 0.1740467072
Epoch:  1900  |  train loss: 0.1740467012
Epoch:  2000  |  train loss: 0.1740467012
Processing class: 1
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1736063927
Epoch:   200  |  train loss: 0.1736063957
Epoch:   300  |  train loss: 0.1736063987
Epoch:   400  |  train loss: 0.1736064017
Epoch:   500  |  train loss: 0.1736063898
Epoch:   600  |  train loss: 0.1736064017
Epoch:   700  |  train loss: 0.1736064076
Epoch:   800  |  train loss: 0.1736063987
Epoch:   900  |  train loss: 0.1736063987
Epoch:  1000  |  train loss: 0.1736063987
Epoch:  1100  |  train loss: 0.1736063927
Epoch:  1200  |  train loss: 0.1736064017
Epoch:  1300  |  train loss: 0.1736064017
Epoch:  1400  |  train loss: 0.1736063957
Epoch:  1500  |  train loss: 0.1736063957
Epoch:  1600  |  train loss: 0.1736063987
Epoch:  1700  |  train loss: 0.1736064017
Epoch:  1800  |  train loss: 0.1736063987
Epoch:  1900  |  train loss: 0.1736063987
Epoch:  2000  |  train loss: 0.1736063898
Processing class: 2
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1708364546
Epoch:   200  |  train loss: 0.1708364546
Epoch:   300  |  train loss: 0.1708364576
Epoch:   400  |  train loss: 0.1708364606
Epoch:   500  |  train loss: 0.1708364576
Epoch:   600  |  train loss: 0.1708364636
Epoch:   700  |  train loss: 0.1708364546
Epoch:   800  |  train loss: 0.1708364576
Epoch:   900  |  train loss: 0.1708364516
Epoch:  1000  |  train loss: 0.1708364606
Epoch:  1100  |  train loss: 0.1708364546
Epoch:  1200  |  train loss: 0.1708364576
Epoch:  1300  |  train loss: 0.1708364516
Epoch:  1400  |  train loss: 0.1708364546
Epoch:  1500  |  train loss: 0.1708364606
Epoch:  1600  |  train loss: 0.1708364606
Epoch:  1700  |  train loss: 0.1708364606
Epoch:  1800  |  train loss: 0.1708364636
Epoch:  1900  |  train loss: 0.1708364606
Epoch:  2000  |  train loss: 0.1708364606
Processing class: 3
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1722085267
Epoch:   200  |  train loss: 0.1722085238
Epoch:   300  |  train loss: 0.1722085238
Epoch:   400  |  train loss: 0.1722085238
Epoch:   500  |  train loss: 0.1722085208
Epoch:   600  |  train loss: 0.1722085208
Epoch:   700  |  train loss: 0.1722085208
Epoch:   800  |  train loss: 0.1722085327
Epoch:   900  |  train loss: 0.1722085297
Epoch:  1000  |  train loss: 0.1722085297
Epoch:  1100  |  train loss: 0.1722085148
Epoch:  1200  |  train loss: 0.1722085208
Epoch:  1300  |  train loss: 0.1722085238
Epoch:  1400  |  train loss: 0.1722085208
Epoch:  1500  |  train loss: 0.1722085238
Epoch:  1600  |  train loss: 0.1722085267
Epoch:  1700  |  train loss: 0.1722085118
Epoch:  1800  |  train loss: 0.1722085267
Epoch:  1900  |  train loss: 0.1722085267
Epoch:  2000  |  train loss: 0.1722085238
Processing class: 4
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1736689657
Epoch:   200  |  train loss: 0.1736689687
Epoch:   300  |  train loss: 0.1736689687
Epoch:   400  |  train loss: 0.1736689657
Epoch:   500  |  train loss: 0.1736689746
Epoch:   600  |  train loss: 0.1736689627
Epoch:   700  |  train loss: 0.1736689687
Epoch:   800  |  train loss: 0.1736689627
Epoch:   900  |  train loss: 0.1736689597
Epoch:  1000  |  train loss: 0.1736689657
Epoch:  1100  |  train loss: 0.1736689597
Epoch:  1200  |  train loss: 0.1736689627
Epoch:  1300  |  train loss: 0.1736689568
Epoch:  1400  |  train loss: 0.1736689657
Epoch:  1500  |  train loss: 0.1736689627
Epoch:  1600  |  train loss: 0.1736689597
Epoch:  1700  |  train loss: 0.1736689597
Epoch:  1800  |  train loss: 0.1736689776
Epoch:  1900  |  train loss: 0.1736689687
Epoch:  2000  |  train loss: 0.1736689597
Processing class: 5
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 6
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1740626007
Epoch:   200  |  train loss: 0.1740626007
Epoch:   300  |  train loss: 0.1740626007
Epoch:   400  |  train loss: 0.1740625948
Epoch:   500  |  train loss: 0.1740626037
Epoch:   600  |  train loss: 0.1740625948
Epoch:   700  |  train loss: 0.1740625978
Epoch:   800  |  train loss: 0.1740625948
Epoch:   900  |  train loss: 0.1740625918
Epoch:  1000  |  train loss: 0.1740625918
Epoch:  1100  |  train loss: 0.1740625948
Epoch:  1200  |  train loss: 0.1740625888
Epoch:  1300  |  train loss: 0.1740625888
Epoch:  1400  |  train loss: 0.1740625948
Epoch:  1500  |  train loss: 0.1740625888
Epoch:  1600  |  train loss: 0.1740625948
Epoch:  1700  |  train loss: 0.1740625858
Epoch:  1800  |  train loss: 0.1740625948
Epoch:  1900  |  train loss: 0.1740625918
Epoch:  2000  |  train loss: 0.1740625918
Processing class: 7
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1736494958
Epoch:   200  |  train loss: 0.1736494899
Epoch:   300  |  train loss: 0.1736494899
Epoch:   400  |  train loss: 0.1736494988
Epoch:   500  |  train loss: 0.1736494869
Epoch:   600  |  train loss: 0.1736494869
Epoch:   700  |  train loss: 0.1736494869
Epoch:   800  |  train loss: 0.1736494869
Epoch:   900  |  train loss: 0.1736494929
Epoch:  1000  |  train loss: 0.1736494929
Epoch:  1100  |  train loss: 0.1736494839
Epoch:  1200  |  train loss: 0.1736494869
Epoch:  1300  |  train loss: 0.1736494958
Epoch:  1400  |  train loss: 0.1736494899
Epoch:  1500  |  train loss: 0.1736494869
Epoch:  1600  |  train loss: 0.1736494869
Epoch:  1700  |  train loss: 0.1736494780
Epoch:  1800  |  train loss: 0.1736494869
Epoch:  1900  |  train loss: 0.1736494929
Epoch:  2000  |  train loss: 0.1736494899
Processing class: 8
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1731565177
Epoch:   200  |  train loss: 0.1731565028
Epoch:   300  |  train loss: 0.1731565058
Epoch:   400  |  train loss: 0.1731565148
Epoch:   500  |  train loss: 0.1731565028
Epoch:   600  |  train loss: 0.1731564999
Epoch:   700  |  train loss: 0.1731565148
Epoch:   800  |  train loss: 0.1731565118
Epoch:   900  |  train loss: 0.1731565058
Epoch:  1000  |  train loss: 0.1731565028
Epoch:  1100  |  train loss: 0.1731565088
Epoch:  1200  |  train loss: 0.1731565088
Epoch:  1300  |  train loss: 0.1731565088
Epoch:  1400  |  train loss: 0.1731565088
Epoch:  1500  |  train loss: 0.1731564969
Epoch:  1600  |  train loss: 0.1731565088
Epoch:  1700  |  train loss: 0.1731565118
Epoch:  1800  |  train loss: 0.1731565088
Epoch:  1900  |  train loss: 0.1731565058
Epoch:  2000  |  train loss: 0.1731564999
Processing class: 9
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1725556523
Epoch:   200  |  train loss: 0.1725556582
Epoch:   300  |  train loss: 0.1725556612
Epoch:   400  |  train loss: 0.1725556612
Epoch:   500  |  train loss: 0.1725556582
Epoch:   600  |  train loss: 0.1725556523
Epoch:   700  |  train loss: 0.1725556523
Epoch:   800  |  train loss: 0.1725556523
Epoch:   900  |  train loss: 0.1725556493
Epoch:  1000  |  train loss: 0.1725556433
Epoch:  1100  |  train loss: 0.1725556463
Epoch:  1200  |  train loss: 0.1725556612
Epoch:  1300  |  train loss: 0.1725556582
Epoch:  1400  |  train loss: 0.1725556612
Epoch:  1500  |  train loss: 0.1725556523
Epoch:  1600  |  train loss: 0.1725556552
Epoch:  1700  |  train loss: 0.1725556463
Epoch:  1800  |  train loss: 0.1725556523
Epoch:  1900  |  train loss: 0.1725556463
Epoch:  2000  |  train loss: 0.1725556463
Processing class: 10
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1747385651
Epoch:   200  |  train loss: 0.1747385681
Epoch:   300  |  train loss: 0.1747385651
Epoch:   400  |  train loss: 0.1747385740
Epoch:   500  |  train loss: 0.1747385681
Epoch:   600  |  train loss: 0.1747385681
Epoch:   700  |  train loss: 0.1747385710
Epoch:   800  |  train loss: 0.1747385651
Epoch:   900  |  train loss: 0.1747385710
Epoch:  1000  |  train loss: 0.1747385681
Epoch:  1100  |  train loss: 0.1747385710
Epoch:  1200  |  train loss: 0.1747385591
Epoch:  1300  |  train loss: 0.1747385681
Epoch:  1400  |  train loss: 0.1747385710
Epoch:  1500  |  train loss: 0.1747385651
Epoch:  1600  |  train loss: 0.1747385651
Epoch:  1700  |  train loss: 0.1747385710
Epoch:  1800  |  train loss: 0.1747385651
Epoch:  1900  |  train loss: 0.1747385770
Epoch:  2000  |  train loss: 0.1747385621
Processing class: 11
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1724178970
Epoch:   200  |  train loss: 0.1724178940
Epoch:   300  |  train loss: 0.1724178970
Epoch:   400  |  train loss: 0.1724178910
Epoch:   500  |  train loss: 0.1724178880
Epoch:   600  |  train loss: 0.1724178910
Epoch:   700  |  train loss: 0.1724178880
Epoch:   800  |  train loss: 0.1724178940
Epoch:   900  |  train loss: 0.1724179029
Epoch:  1000  |  train loss: 0.1724178970
Epoch:  1100  |  train loss: 0.1724178880
Epoch:  1200  |  train loss: 0.1724179000
Epoch:  1300  |  train loss: 0.1724178940
Epoch:  1400  |  train loss: 0.1724178940
Epoch:  1500  |  train loss: 0.1724178970
Epoch:  1600  |  train loss: 0.1724178940
Epoch:  1700  |  train loss: 0.1724178970
Epoch:  1800  |  train loss: 0.1724178851
Epoch:  1900  |  train loss: 0.1724178970
Epoch:  2000  |  train loss: 0.1724179000
Processing class: 12
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1738783062
Epoch:   200  |  train loss: 0.1738783002
Epoch:   300  |  train loss: 0.1738782972
Epoch:   400  |  train loss: 0.1738783062
Epoch:   500  |  train loss: 0.1738783032
Epoch:   600  |  train loss: 0.1738782972
Epoch:   700  |  train loss: 0.1738783002
Epoch:   800  |  train loss: 0.1738783062
Epoch:   900  |  train loss: 0.1738783062
Epoch:  1000  |  train loss: 0.1738783062
Epoch:  1100  |  train loss: 0.1738783062
Epoch:  1200  |  train loss: 0.1738783062
Epoch:  1300  |  train loss: 0.1738783121
Epoch:  1400  |  train loss: 0.1738782972
Epoch:  1500  |  train loss: 0.1738782942
Epoch:  1600  |  train loss: 0.1738783002
Epoch:  1700  |  train loss: 0.1738783091
Epoch:  1800  |  train loss: 0.1738783062
Epoch:  1900  |  train loss: 0.1738783002
Epoch:  2000  |  train loss: 0.1738783091
Processing class: 13
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1725321054
Epoch:   200  |  train loss: 0.1725321114
Epoch:   300  |  train loss: 0.1725321025
Epoch:   400  |  train loss: 0.1725321025
Epoch:   500  |  train loss: 0.1725321054
Epoch:   600  |  train loss: 0.1725321054
Epoch:   700  |  train loss: 0.1725320935
Epoch:   800  |  train loss: 0.1725321144
Epoch:   900  |  train loss: 0.1725321054
Epoch:  1000  |  train loss: 0.1725321054
Epoch:  1100  |  train loss: 0.1725321084
Epoch:  1200  |  train loss: 0.1725321144
Epoch:  1300  |  train loss: 0.1725321054
Epoch:  1400  |  train loss: 0.1725321084
Epoch:  1500  |  train loss: 0.1725320995
Epoch:  1600  |  train loss: 0.1725320995
Epoch:  1700  |  train loss: 0.1725320995
Epoch:  1800  |  train loss: 0.1725320995
Epoch:  1900  |  train loss: 0.1725321025
Epoch:  2000  |  train loss: 0.1725321114
Processing class: 14
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1744643480
Epoch:   200  |  train loss: 0.1744643599
Epoch:   300  |  train loss: 0.1744643480
Epoch:   400  |  train loss: 0.1744643539
Epoch:   500  |  train loss: 0.1744643509
Epoch:   600  |  train loss: 0.1744643539
Epoch:   700  |  train loss: 0.1744643450
Epoch:   800  |  train loss: 0.1744643509
Epoch:   900  |  train loss: 0.1744643509
Epoch:  1000  |  train loss: 0.1744643569
Epoch:  1100  |  train loss: 0.1744643450
Epoch:  1200  |  train loss: 0.1744643539
Epoch:  1300  |  train loss: 0.1744643450
Epoch:  1400  |  train loss: 0.1744643509
Epoch:  1500  |  train loss: 0.1744643539
Epoch:  1600  |  train loss: 0.1744643629
Epoch:  1700  |  train loss: 0.1744643569
Epoch:  1800  |  train loss: 0.1744643539
Epoch:  1900  |  train loss: 0.1744643509
Epoch:  2000  |  train loss: 0.1744643539
Processing class: 15
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1725023001
Epoch:   200  |  train loss: 0.1725023091
Epoch:   300  |  train loss: 0.1725023150
Epoch:   400  |  train loss: 0.1725023091
Epoch:   500  |  train loss: 0.1725023061
Epoch:   600  |  train loss: 0.1725023061
Epoch:   700  |  train loss: 0.1725023121
Epoch:   800  |  train loss: 0.1725023091
Epoch:   900  |  train loss: 0.1725023121
Epoch:  1000  |  train loss: 0.1725023061
Epoch:  1100  |  train loss: 0.1725023031
Epoch:  1200  |  train loss: 0.1725023031
Epoch:  1300  |  train loss: 0.1725023091
Epoch:  1400  |  train loss: 0.1725023091
Epoch:  1500  |  train loss: 0.1725023121
Epoch:  1600  |  train loss: 0.1725023061
Epoch:  1700  |  train loss: 0.1725023121
Epoch:  1800  |  train loss: 0.1725023210
Epoch:  1900  |  train loss: 0.1725023061
Epoch:  2000  |  train loss: 0.1725023001
Processing class: 16
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1733912081
Epoch:   200  |  train loss: 0.1733912051
Epoch:   300  |  train loss: 0.1733912140
Epoch:   400  |  train loss: 0.1733912051
Epoch:   500  |  train loss: 0.1733912051
Epoch:   600  |  train loss: 0.1733912110
Epoch:   700  |  train loss: 0.1733912021
Epoch:   800  |  train loss: 0.1733912081
Epoch:   900  |  train loss: 0.1733912081
Epoch:  1000  |  train loss: 0.1733911932
Epoch:  1100  |  train loss: 0.1733911961
Epoch:  1200  |  train loss: 0.1733912081
Epoch:  1300  |  train loss: 0.1733912140
Epoch:  1400  |  train loss: 0.1733911961
Epoch:  1500  |  train loss: 0.1733912051
Epoch:  1600  |  train loss: 0.1733912081
Epoch:  1700  |  train loss: 0.1733912110
Epoch:  1800  |  train loss: 0.1733912051
Epoch:  1900  |  train loss: 0.1733912081
Epoch:  2000  |  train loss: 0.1733912081
Processing class: 17
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 18
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1722094357
Epoch:   200  |  train loss: 0.1722094446
Epoch:   300  |  train loss: 0.1722094446
Epoch:   400  |  train loss: 0.1722094446
Epoch:   500  |  train loss: 0.1722094476
Epoch:   600  |  train loss: 0.1722094446
Epoch:   700  |  train loss: 0.1722094446
Epoch:   800  |  train loss: 0.1722094506
Epoch:   900  |  train loss: 0.1722094417
Epoch:  1000  |  train loss: 0.1722094387
Epoch:  1100  |  train loss: 0.1722094417
Epoch:  1200  |  train loss: 0.1722094357
Epoch:  1300  |  train loss: 0.1722094417
Epoch:  1400  |  train loss: 0.1722094417
Epoch:  1500  |  train loss: 0.1722094387
Epoch:  1600  |  train loss: 0.1722094476
Epoch:  1700  |  train loss: 0.1722094417
Epoch:  1800  |  train loss: 0.1722094446
Epoch:  1900  |  train loss: 0.1722094446
Epoch:  2000  |  train loss: 0.1722094476
Processing class: 19
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1695783317
Epoch:   200  |  train loss: 0.1695783377
Epoch:   300  |  train loss: 0.1695783466
Epoch:   400  |  train loss: 0.1695783436
Epoch:   500  |  train loss: 0.1695783406
Epoch:   600  |  train loss: 0.1695783347
Epoch:   700  |  train loss: 0.1695783406
Epoch:   800  |  train loss: 0.1695783436
Epoch:   900  |  train loss: 0.1695783287
Epoch:  1000  |  train loss: 0.1695783377
Epoch:  1100  |  train loss: 0.1695783436
Epoch:  1200  |  train loss: 0.1695783526
Epoch:  1300  |  train loss: 0.1695783377
Epoch:  1400  |  train loss: 0.1695783347
Epoch:  1500  |  train loss: 0.1695783406
Epoch:  1600  |  train loss: 0.1695783317
Epoch:  1700  |  train loss: 0.1695783377
Epoch:  1800  |  train loss: 0.1695783466
Epoch:  1900  |  train loss: 0.1695783406
Epoch:  2000  |  train loss: 0.1695783377
Processing class: 20
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1717581600
Epoch:   200  |  train loss: 0.1717581600
Epoch:   300  |  train loss: 0.1717581570
Epoch:   400  |  train loss: 0.1717581540
Epoch:   500  |  train loss: 0.1717581660
Epoch:   600  |  train loss: 0.1717581570
Epoch:   700  |  train loss: 0.1717581570
Epoch:   800  |  train loss: 0.1717581481
Epoch:   900  |  train loss: 0.1717581600
Epoch:  1000  |  train loss: 0.1717581630
Epoch:  1100  |  train loss: 0.1717581570
Epoch:  1200  |  train loss: 0.1717581570
Epoch:  1300  |  train loss: 0.1717581600
Epoch:  1400  |  train loss: 0.1717581600
Epoch:  1500  |  train loss: 0.1717581540
Epoch:  1600  |  train loss: 0.1717581481
Epoch:  1700  |  train loss: 0.1717581570
Epoch:  1800  |  train loss: 0.1717581570
Epoch:  1900  |  train loss: 0.1717581600
Epoch:  2000  |  train loss: 0.1717581451
Processing class: 21
Training regular Auto Encoder
Epoch:   100  |  train loss: nan
Epoch:   200  |  train loss: nan
Epoch:   300  |  train loss: nan
Epoch:   400  |  train loss: nan
Epoch:   500  |  train loss: nan
Epoch:   600  |  train loss: nan
Epoch:   700  |  train loss: nan
Epoch:   800  |  train loss: nan
Epoch:   900  |  train loss: nan
Epoch:  1000  |  train loss: nan
Epoch:  1100  |  train loss: nan
Epoch:  1200  |  train loss: nan
Epoch:  1300  |  train loss: nan
Epoch:  1400  |  train loss: nan
Epoch:  1500  |  train loss: nan
Epoch:  1600  |  train loss: nan
Epoch:  1700  |  train loss: nan
Epoch:  1800  |  train loss: nan
Epoch:  1900  |  train loss: nan
Epoch:  2000  |  train loss: nan
Processing class: 22
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1746349782
Epoch:   200  |  train loss: 0.1746349871
Epoch:   300  |  train loss: 0.1746349961
Epoch:   400  |  train loss: 0.1746349782
Epoch:   500  |  train loss: 0.1746349901
Epoch:   600  |  train loss: 0.1746349812
Epoch:   700  |  train loss: 0.1746349841
Epoch:   800  |  train loss: 0.1746349901
Epoch:   900  |  train loss: 0.1746349961
Epoch:  1000  |  train loss: 0.1746349871
Epoch:  1100  |  train loss: 0.1746349841
Epoch:  1200  |  train loss: 0.1746349871
Epoch:  1300  |  train loss: 0.1746349871
Epoch:  1400  |  train loss: 0.1746349841
Epoch:  1500  |  train loss: 0.1746349871
Epoch:  1600  |  train loss: 0.1746349871
Epoch:  1700  |  train loss: 0.1746349812
Epoch:  1800  |  train loss: 0.1746349901
Epoch:  1900  |  train loss: 0.1746349752
Epoch:  2000  |  train loss: 0.1746349812
Processing class: 23
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1725553215
Epoch:   200  |  train loss: 0.1725553274
Epoch:   300  |  train loss: 0.1725553244
Epoch:   400  |  train loss: 0.1725553185
Epoch:   500  |  train loss: 0.1725553185
Epoch:   600  |  train loss: 0.1725553304
Epoch:   700  |  train loss: 0.1725553155
Epoch:   800  |  train loss: 0.1725553274
Epoch:   900  |  train loss: 0.1725553185
Epoch:  1000  |  train loss: 0.1725553334
Epoch:  1100  |  train loss: 0.1725553185
Epoch:  1200  |  train loss: 0.1725553215
Epoch:  1300  |  train loss: 0.1725553185
Epoch:  1400  |  train loss: 0.1725553185
Epoch:  1500  |  train loss: 0.1725553274
Epoch:  1600  |  train loss: 0.1725553244
Epoch:  1700  |  train loss: 0.1725553155
Epoch:  1800  |  train loss: 0.1725553244
Epoch:  1900  |  train loss: 0.1725553215
Epoch:  2000  |  train loss: 0.1725553274
Processing class: 24
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1735941887
Epoch:   200  |  train loss: 0.1735941887
Epoch:   300  |  train loss: 0.1735941857
Epoch:   400  |  train loss: 0.1735941827
Epoch:   500  |  train loss: 0.1735941857
Epoch:   600  |  train loss: 0.1735941887
Epoch:   700  |  train loss: 0.1735941887
Epoch:   800  |  train loss: 0.1735941827
Epoch:   900  |  train loss: 0.1735941887
Epoch:  1000  |  train loss: 0.1735941947
Epoch:  1100  |  train loss: 0.1735941947
Epoch:  1200  |  train loss: 0.1735941887
Epoch:  1300  |  train loss: 0.1735941917
Epoch:  1400  |  train loss: 0.1735941857
Epoch:  1500  |  train loss: 0.1735941857
Epoch:  1600  |  train loss: 0.1735941887
Epoch:  1700  |  train loss: 0.1735941857
Epoch:  1800  |  train loss: 0.1735941917
Epoch:  1900  |  train loss: 0.1735941857
Epoch:  2000  |  train loss: 0.1735941917
Processing class: 25
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1733448654
Epoch:   200  |  train loss: 0.1733448744
Epoch:   300  |  train loss: 0.1733448625
Epoch:   400  |  train loss: 0.1733448684
Epoch:   500  |  train loss: 0.1733448684
Epoch:   600  |  train loss: 0.1733448684
Epoch:   700  |  train loss: 0.1733448714
Epoch:   800  |  train loss: 0.1733448684
Epoch:   900  |  train loss: 0.1733448654
Epoch:  1000  |  train loss: 0.1733448565
Epoch:  1100  |  train loss: 0.1733448684
Epoch:  1200  |  train loss: 0.1733448595
Epoch:  1300  |  train loss: 0.1733448684
Epoch:  1400  |  train loss: 0.1733448714
Epoch:  1500  |  train loss: 0.1733448714
Epoch:  1600  |  train loss: 0.1733448684
Epoch:  1700  |  train loss: 0.1733448595
Epoch:  1800  |  train loss: 0.1733448714
Epoch:  1900  |  train loss: 0.1733448714
Epoch:  2000  |  train loss: 0.1733448595
Processing class: 26
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1744893014
Epoch:   200  |  train loss: 0.1744892985
Epoch:   300  |  train loss: 0.1744892925
Epoch:   400  |  train loss: 0.1744892985
Epoch:   500  |  train loss: 0.1744893044
Epoch:   600  |  train loss: 0.1744893044
Epoch:   700  |  train loss: 0.1744892985
Epoch:   800  |  train loss: 0.1744893074
Epoch:   900  |  train loss: 0.1744893044
Epoch:  1000  |  train loss: 0.1744893014
Epoch:  1100  |  train loss: 0.1744892985
Epoch:  1200  |  train loss: 0.1744893014
Epoch:  1300  |  train loss: 0.1744892955
Epoch:  1400  |  train loss: 0.1744892955
Epoch:  1500  |  train loss: 0.1744892985
Epoch:  1600  |  train loss: 0.1744892985
Epoch:  1700  |  train loss: 0.1744892985
Epoch:  1800  |  train loss: 0.1744892985
Epoch:  1900  |  train loss: 0.1744893044
Epoch:  2000  |  train loss: 0.1744892955
Processing class: 27
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1718874514
Epoch:   200  |  train loss: 0.1718874454
Epoch:   300  |  train loss: 0.1718874454
Epoch:   400  |  train loss: 0.1718874544
Epoch:   500  |  train loss: 0.1718874574
Epoch:   600  |  train loss: 0.1718874514
Epoch:   700  |  train loss: 0.1718874574
Epoch:   800  |  train loss: 0.1718874484
Epoch:   900  |  train loss: 0.1718874604
Epoch:  1000  |  train loss: 0.1718874544
Epoch:  1100  |  train loss: 0.1718874425
Epoch:  1200  |  train loss: 0.1718874574
Epoch:  1300  |  train loss: 0.1718874454
Epoch:  1400  |  train loss: 0.1718874604
Epoch:  1500  |  train loss: 0.1718874484
Epoch:  1600  |  train loss: 0.1718874514
Epoch:  1700  |  train loss: 0.1718874454
Epoch:  1800  |  train loss: 0.1718874484
Epoch:  1900  |  train loss: 0.1718874514
Epoch:  2000  |  train loss: 0.1718874544
Processing class: 28
Training regular Auto Encoder
Epoch:   100  |  train loss: 0.1736941844
Epoch:   200  |  train loss: 0.1736941963
